[
  {
    "objectID": "win_ratio.html",
    "href": "win_ratio.html",
    "title": "Defining estimand for the win ratio",
    "section": "",
    "text": "This is a talk I give at the FDA/AdvaMed Medical Device Statistical Issues (MDSI) Conference on April 3rd, 2024 in Washington, DC.\nTalk slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "test.html#slide-1",
    "href": "test.html#slide-1",
    "title": "Test presentations",
    "section": "Slide 1",
    "text": "Slide 1"
  },
  {
    "objectID": "test.html#slide-2",
    "href": "test.html#slide-2",
    "title": "Test presentations",
    "section": "Slide 2",
    "text": "Slide 2\n\nTopic 1"
  },
  {
    "objectID": "test.html#slide-3",
    "href": "test.html#slide-3",
    "title": "Test presentations",
    "section": "Slide 3",
    "text": "Slide 3\n\nPlay with some graphics"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to BMI/STAT 741",
    "section": "",
    "text": "This site will post additional study materials for BMI/STAT 741 in Spring 2025. These include slides, extra data/code examples or mathematical results.\nPlease check updated syllabus for course schedule and other information."
  },
  {
    "objectID": "HW1_solution.html",
    "href": "HW1_solution.html",
    "title": "HW1 sample solution",
    "section": "",
    "text": "\\(\\newcommand{\\indep}{\\perp \\!\\!\\! \\perp}\\) \\(\\newcommand{\\pr}{{\\rm pr}}\\)"
  },
  {
    "objectID": "HW1_solution.html#problem-1.1",
    "href": "HW1_solution.html#problem-1.1",
    "title": "HW1 sample solution",
    "section": "Problem 1.1",
    "text": "Problem 1.1\n\n\n\n\n\n\nQuestion\n\n\n\nSuppose that patient enrollment (and randomization) is uniform in calendar time \\([0, \\tau_b]\\) and that the study is terminated at calendar time \\(\\tau_c\\) \\((\\tau_c&gt;\\tau_b)\\). What is the distribution of the administrative censoring time? (Hint: see Fig. 1.1) Further suppose that patients are subject to a random LTFU following an exponential distribution with hazard \\(\\lambda_L\\) (whose survival function is \\(\\exp(-\\lambda_L t)\\)). Write out the survival function for the censoring time \\(C\\) (i.e., the earlier of administrative censoring and LTFU times).\n\n\nThe administrative censoring time \\(C_A\\) is defined as the duration between time of enrollment, \\(R\\sim \\mbox{Unif}[0, \\tau_b]\\), and time of study termination \\(\\tau_c\\) (see Fig. 1.1). So \\[C_A = (\\tau_c - R) \\sim \\mbox{Unif}[\\tau_c - \\tau_b, \\tau_c].\\] As a result, \\[{\\rm pr}(C_A &gt; t) = \\left(\\frac{\\tau_c - t}{\\tau_b}\\wedge 1\\right)_+\n=\\left\\{\n\\begin{array}{lr}\n1&  0\\leq t \\leq \\tau_c - \\tau_b\\\\\n\\frac{\\tau_c - t}{\\tau_b}& \\tau_c - \\tau_b &lt; t \\leq \\tau_c\\\\\n0 & t\\geq \\tau_c\n\\end{array}\n\\right.,\n\\] where \\(x_+=\\max(x, 0)\\).\nOn the other hand, the survival function for LTFU \\(C_L\\) is \\({\\rm pr}(C_L &gt; t) = \\exp(-\\lambda_L t)\\). Assuming \\(C_A\\indep C_L\\), the survival function for the overall censoring time \\(C\\) is \\[\\begin{align}\n{\\rm pr}(C &gt; t)&={\\rm pr}(C_A\\wedge C_L &gt; t)\\\\\n&={\\rm pr}(C_A &gt; t){\\rm pr}(C_L &gt; t)\\\\\n&=\\left(\\frac{\\tau_c - t}{\\tau_b}\\wedge 1\\right)_+\\exp(-\\lambda_L t)\n\\end{align}\\]"
  },
  {
    "objectID": "HW1_solution.html#problem-1.2",
    "href": "HW1_solution.html#problem-1.2",
    "title": "HW1 sample solution",
    "section": "Problem 1.2",
    "text": "Problem 1.2\n\n\n\n\n\n\nQuestion\n\n\n\nShow that \\(S_{\\rm imp}(t)\\leq S(t)\\) for all \\(t\\) whether censoring is independent or not. Give a simple sufficient condition for strict inequality under \\(C\\indep T\\).\n\n\nBecause \\(X=\\min(T,C)\\), we have that \\(X\\leq T\\) always. Therefore, \\(X&gt;t\\) implies \\(T&gt;t\\). Hence \\(\\pr(X&gt;t)\\leq \\pr(T&gt;t)\\). Under independence, we have that \\[\nS_{\\rm imp}(t)=\\pr(X&gt;t)=\\pr(T&gt;t)\\pr(C&gt;t)=S(t)\\pr(C&gt;t),\n\\] which is strictly less than \\(S(t)\\) if \\(\\pr(C&gt;t)&lt;1\\) and \\(S(t)&gt;0\\). That is, if there is a positive probability of censoring before \\(t\\) and a positive probability of failure after it."
  },
  {
    "objectID": "HW1_solution.html#problem-1.3-extra-credit",
    "href": "HW1_solution.html#problem-1.3-extra-credit",
    "title": "HW1 sample solution",
    "section": "Problem 1.3 (extra credit)",
    "text": "Problem 1.3 (extra credit)\n\n\n\n\n\n\nQuestion\n\n\n\nFormulate a survival function estimator under the “nonevent-imputation” approach described in Section 1.2.2 and show that it overestimates \\(S(t)\\) whether censoring is independent or not. Give a simple sufficient condition for strict overestimation under \\(C\\indep T\\).\n\n\nNon-event imputation means imputing event time to \\(\\infty\\) whenever censored, i.e., \\[\n\\hat T_i = \\left\\{\n\\begin{array}{cc}\nT_i, &\\delta_i =1\\\\\n\\infty,&\\delta_i =0\n\\end{array}\n\\right.\n\\] So the empirical survival function based on the \\(\\hat T_i\\) is \\[\\begin{align}\nn^{-1}\\sum_{i=1}^n I(\\hat T_i &gt;t) &= n^{-1}\\sum_{i=1}^n\\left\\{\\delta_iI(T_i &gt; t) + (1-\\delta_i)\\right\\}\\\\\n&= 1 - n^{-1}\\sum_{i=1}^n\\delta_i I(T_i\\leq t)\\\\\n&\\to 1- \\pr(T\\leq t\\wedge C)\\\\\n&= \\pr(T &gt; t\\wedge C)\\\\\n&\\geq \\pr(T &gt; t)\\\\\n& = S(t).\n\\end{align}\\] This shows that the estimator overestimates \\(S(t)\\) regardless of whether censoring is independent. Under \\(C\\indep T\\), \\[\n\\pr(T &gt; t\\wedge C) = E\\{S(C\\wedge t)\\}.\n\\] It turns out that there is no “simple” condition for the right hand side to be strictly greater than \\(S(t)\\). But the following condition works: (1) there exists \\(t_0 &lt; t\\) such that \\(S(t_0)&gt; S(t)\\); and (2) \\(\\pr(C\\leq t_0)&gt;0\\). That is, there is a positive probability of censoring before a point to the left of \\(t\\) where the survival rate is strictly greater than \\(S(t)\\). The proof is left as an exercise."
  },
  {
    "objectID": "HW1_solution.html#problem-1.8",
    "href": "HW1_solution.html#problem-1.8",
    "title": "HW1 sample solution",
    "section": "Problem 1.8",
    "text": "Problem 1.8\n\n\n\n\n\n\nQuestion\n\n\n\nSummarize the CGD (chronic granulomatous disease) study data described in Example 1.3 by the randomized treatment group in terms of patient baseline characteristics and event rates. Comment on the balance of baseline characteristics between the treatment arms. Also be sure to include the event rates for both\n\nthe first infection;\nrecurrent infections (including the first).\n\nOrganize your results in a table suitable for inclusion as “Table 1” in a medical research paper. (The study dataset is in cgd.txt.)\n\n\nThe baseline patient characteristics and events rates for the CGD study are summarized by treatment arm in Table 1 below. Most of the baseline characteristics are well balanced between the randomized arms, except that the proportion of X-linked inheritance is slightly higher in the treatment arm (71.4%) than in the control arm (63.1%). The event rates for both first and recurrent infections are substantially lower in the treatment arm.\n\n\n\n\n\n\n\nShow the code\n## Read in the CGD  data\n\ndata &lt;- read.table(\"Chronic Granulomatous Disease Study//cgd.txt\")\nhead(data)\n\n\n###########################################################\n# Table 1 Patient characteristics for the CGD study\n###########################################################\n\n\n##A function calculating median (IQR) by \n## binary group\n## Input: y=quantitative variable\n##        trt=binary group variable\n##        decp=number of decimal points\n## Output: a row vector containing median (IQR)\n##    by the two levels of trt and overall \n\nMean.IQR.by.trt=function(y,trt,decp=1){\n  groups=sort(unique(trt))\n  all=quantile(y)\n  g1=quantile(y[trt==groups[1]])\n  g2=quantile(y[trt==groups[2]])\n  \n  result=matrix(NA,1,3)\n  colnames(result)=c(groups,\"Overall\")\n  result[1,1]=paste0(round(g1[3],decp),\" (\",round(g1[2],decp),\", \",round(g1[4],decp),\")\")\n  result[1,2]=paste0(round(g2[3],decp),\" (\",round(g2[2],decp),\", \",round(g2[4],decp),\")\")\n  result[1,3]=paste0(round(all[3],decp),\" (\",round(all[2],decp),\", \",round(all[4],decp),\")\")\n  return(result)\n}\n\n\n##A function calculating N (%) by \n## binary group\n## Input: x=categorical variable with p levels\n##        trt=binary group variable\n##        decp=number of decimal points of %\n## Output: a px3 matrix containing N (%) for each level of x\n##    by the two levels of trt and overall \n\nN.prct.by.trt=function(x,trt,decp=1){\n  groups=sort(unique(trt))\n  x.levels=sort(unique(x))\n  p=length(x.levels)\n  n=length(x)\n  n1=length(x[trt==groups[1]])\n  n2=length(x[trt==groups[2]])\n  \n  result=matrix(NA,p,3)\n  colnames(result)=c(groups,\"Overall\")\n  rownames(result)=x.levels\n  \n  for (i in 1:p){\n    n1i=sum(x[trt==groups[1]]==x.levels[i])\n    n2i=sum(x[trt==groups[2]]==x.levels[i])\n    ni=sum(x==x.levels[i])\n    \n    \n  result[i,1]=paste0(n1i,\" (\",round(n1i/n1*100,decp),\"%)\")\n  result[i,2]=paste0(n2i,\" (\",round(n2i/n2*100,decp),\"%)\")\n  result[i,3]=paste0(ni,\" (\",round(ni/n*100,decp),\"%)\")\n  }\n  \n  \n  return(result)\n}\n\n\n##Baseline characteristics by treatment arm:\n# sex\n# Sex of each patient(male, female)\n# \n# age\n# Age of each patient at study entry, in years\n# \n# height\n# Height of each patient at study entry, in cm\n# \n# weight\n# Weight of each patient at study entry, in kg\n# \n# inherit\n# Pattern of inheritance (autosomal recessive, X-linked)\n# \n# steroids\n# Using corticosteroids at times of study centry(1=Yes, 0=No)\n# \n# propylac\n# Using prophylactic antibiotics at time of study entry(1=Yes, 0=No)\n\n\n####################################################\n# To calculate the baseline characteristics,\n# first subset to one record per patient.\n# We do this by getting the first record \n#####################################################\n\no &lt;- order(data$id,data$time)\ndata &lt;- data[o,]\ndat &lt;- data[!duplicated(data$id),]\nn &lt;- nrow(dat)\n#n=128: number of subjects\n\ntable1 &lt;- rbind(\n  N.prct.by.trt(x=dat$sex,trt=dat$trt),\n  Mean.IQR.by.trt(y=dat$age,trt=dat$trt),\n  Mean.IQR.by.trt(y=dat$hght,trt=dat$trt),\n  Mean.IQR.by.trt(y=dat$wght,trt=dat$trt),\n  N.prct.by.trt(x=dat$inherit,trt=dat$trt),\n  N.prct.by.trt(x=dat$stero,trt=dat$trt),\n  N.prct.by.trt(x=dat$proph,trt=dat$trt)\n)\n\n\nnoquote(table1)\n\n#############################################\n##Calculate the *first event* rates (per year)\n# use the dataset \"dat\", since it contains\n# the first record for each patient\n############################################\n\n\n#Numerator: total # of events\n# note that event is coded as status=2\nnum.FE &lt;- c(sum(dat$status[dat$trt==\"placebo\"]&gt;0), \n        sum(dat$status[dat$trt==\"rIFN-g\"]&gt;0), \n        sum(dat$status&gt;0))\n\n#Demoninator: total length of follow-up (year)\ndenom.FE &lt;- c(sum(dat$time[dat$trt==\"placebo\"]), \n        sum(dat$time[dat$trt==\"rIFN-g\"]), \n        sum(dat$time))/12\n\n#death rate\nround(num.FE/denom.FE,3)\n\n#############################\n#Recurrent event rate       #\n#############################\n\n# the numerator is easy: simply the numbers of records\n# with non-zero status\nnum.rec &lt;- c(sum(data$status[data$trt==\"placebo\"]&gt;0), \n         sum(data$status[data$trt==\"rIFN-g\"]&gt;0), \n         sum(data$status&gt;0))\n\n# Denominator should be the sum of the longest\n# follow-up for each patient\n\n#sort the data by descending order of time\no &lt;- order(data$id,data$time,decreasing = TRUE)\ndata &lt;- data[o,]\n# get the first record, which contains\n# the overall length of follow-up\n# for each patient\ndat.last &lt;- data[!duplicated(data$id),]\n\ndenom.rec &lt;- c(sum(dat.last$time[dat.last$trt==\"placebo\"]), \n            sum(dat.last$time[dat.last$trt==\"rIFN-g\"]), \n            sum(dat.last$time))/12\n\n#recurrent event rate\nround(num.rec/denom.rec,3)"
  },
  {
    "objectID": "chapter9_tmp.html",
    "href": "chapter9_tmp.html",
    "title": "Chapter 9 - Recurrent Events",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter9_tmp.html#slides",
    "href": "chapter9_tmp.html#slides",
    "title": "Chapter 9 - Recurrent Events",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter9_tmp.html#base-r-code",
    "href": "chapter9_tmp.html#base-r-code",
    "title": "Chapter 9 - Recurrent Events",
    "section": "Base R Code",
    "text": "Base R Code\n\n\nShow the code\n##################################################################\n# This code generates all numerical results in chapter 9.       ##\n##################################################################\n\n\n\nlibrary(survival)\n\n# read in the cgd dataset in counting process format\ncgd &lt;- read.table(\"Data\\\\Chronic Granulomatous Disease Study\\\\cgd_counting.txt\")\nhead(cgd)\n\n\n# Andersen-Gill model\nobj.AG &lt;- coxph(Surv(tstart, tstop, status) ~ treat + sex + age + inherit + steroids +\n                 propylac, data = cgd)\nsummary(obj.AG)\n\n# Frailty model\nobj.frail &lt;- coxph(Surv(tstart, tstop, status) ~ treat + sex + age + inherit + steroids +\n                    propylac + frailty(id, distribution = \"gamma\"), data = cgd)\n\nsummary(obj.frail)\n\n\n# proportional mean model (LWYY)\nobj.pm &lt;- coxph(Surv(tstart, tstop, status) ~ treat + sex + age + inherit + steroids +\n                 propylac + cluster(id), data = cgd)\n\nsummary(obj.pm)\n\n\n# extract the beta's from the three models\ncoeff.AG &lt;- summary(obj.AG)$coeff\ncoeff.frail &lt;- summary(obj.frail)$coeff\ncoeff.pm &lt;- summary(obj.pm)$coeff\n\n\n#########################################\n# Table 9.1. beta, se(beta), and p-vaues\n# from the three models\n#########################################\n\n## Andersen-Gill model\nc1 &lt;- coeff.AG[,1]\nc2 &lt;- coeff.AG[,3]\nc3 &lt;- coeff.AG[,5]\n\n# Frailty model\nc4 &lt;- coeff.frail[1:6,1]\nc5 &lt;- coeff.frail[1:6,2]\nc6 &lt;- coeff.frail[1:6,6]\n\n# Proportional means model\nc7 &lt;- coeff.pm[1:6,1]\nc8 &lt;- coeff.pm[1:6,4]\nc9 &lt;- coeff.pm[1:6,6]\n\n#print out Table 9.1\nnoquote(round(cbind(c1,c2,c3,c4,c5,c6,c7,c8,c9),3))\n\n\n### Figure 9.2 #############################################\n# predicted  mean functions by treatment\n# for a female/male patient of 12 years old with X-linked \n# inheritance pattern and use of both steroids and \n#  prophylactic antibiotics\n############################################################\n\n# get beta\nbeta &lt;- obj.pm$coeff\n\n# get baseline mean function mu_0(t)\n# and t\nLt &lt;- basehaz(obj.pm,centered = F)\nt &lt;- Lt$time\nmu0 &lt;- Lt$hazard\n\n# covariate vector (besides treatement) for female patient\nzf &lt;- c(0,12,1,1,1)\n# covariate vector (besides treatement) for male patient\nzm &lt;- c(1,12,1,1,1)\n\n# female in treatment and control\nmu.f.trt &lt;- exp(sum(c(1,zf)*beta))*mu0\nmu.f.contr &lt;- exp(sum(c(0,zf)*beta))*mu0\n\n# male in treatment and control\nmu.m.trt &lt;- exp(sum(c(1,zm)*beta))*mu0\nmu.m.contr &lt;- exp(sum(c(0,zm)*beta))*mu0\n\n# Plot the figure\npar(mfrow=c(1,2))\n\n# for female (left panel)\nplot(t/30.5, mu.f.trt, type=\"s\",xlim=c(0, 12), ylim=c(0,6),frame.plot =F,lty=1, main=\"Female\",\n     xlab=\"Time (months)\",ylab = \"Mean number of infections\", lwd=2)\nlines(t/30.5,mu.f.contr,lty=3,lwd=2)\n\n#for male (right panel)\nplot(t/30.5, mu.m.trt, type=\"s\", xlim=c(0, 12), ylim=c(0,6),frame.plot =F,lty=1,main=\"Male\",\n     xlab=\"Time (months)\",ylab = \"Mean number of infections\",lwd=2)\nlines(t/30.5,mu.m.contr,lty=3,lwd=2)"
  },
  {
    "objectID": "chapter9_tmp.html#graphics-for-cgd-study",
    "href": "chapter9_tmp.html#graphics-for-cgd-study",
    "title": "Chapter 9 - Recurrent Events",
    "section": "Graphics for CGD Study",
    "text": "Graphics for CGD Study\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n# read in the cgd dataset in counting process format\ncgd &lt;- read.table(\"Data\\\\Chronic Granulomatous Disease Study\\\\cgd_counting.txt\")\nhead(cgd)\n\n  id tstart tstop status   treat    sex age height weight   inherit steroids\n1  1      0   219      1  rIFN-g female  12    147   62.0 autosomal        0\n2  1    219   373      1  rIFN-g female  12    147   62.0 autosomal        0\n3  1    373   414      0  rIFN-g female  12    147   62.0 autosomal        0\n4  2      0     8      1 placebo   male  15    159   47.5 autosomal        0\n5  2      8    26      1 placebo   male  15    159   47.5 autosomal        0\n6  2     26   152      1 placebo   male  15    159   47.5 autosomal        0\n  propylac\n1        0\n2        0\n3        0\n4        1\n5        1\n6        1\n\n# number of patients by sex\nsex_n &lt;- cgd |&gt; count(sex)\n\n# panel labeller by sex\nsex_labeller &lt;- str_c(c(\"Female\", \"Male\"),\n                      \" (N = \", sex_n$n, \")\"\n                      )\nnames(sex_labeller) &lt;- c(\"female\", \"male\")\n\n\nrec_cgd_hist &lt;- cgd |&gt; \n  group_by(treat, sex, id) |&gt; \n  summarize(\n    N = sum(status)\n  ) |&gt; \n  ggplot(aes(x = N)) +\n  geom_bar(aes(fill = treat), \n           position = position_dodge(0.8, preserve = \"single\"), \n           width = 0.8) +\n  facet_wrap( ~ sex, labeller = labeller(sex = sex_labeller)) +\n  scale_x_continuous(\"Infection count per patient\", \n                   breaks = 0:7, labels = 0:7) +\n  scale_y_continuous(\"Number of patients\", expand = c(0, 1)) + \n  scale_fill_manual(values = c(\"gray80\", \"gray20\"), labels = c(\"Placebo\", \"rIFN-g\")) +\n  theme_bw() +\n  theme(\n    panel.grid.major.x = element_blank(),\n    panel.grid.minor.x = element_blank(),\n    legend.position = \"top\",\n    legend.title = element_blank()\n  )\n\n`summarise()` has grouped output by 'treat', 'sex'. You can override using the\n`.groups` argument.\n\nggsave(\"rec_cgd_hist.pdf\", rec_cgd_hist, width = 8, height = 4.5)\nggsave(\"rec_cgd_hist.eps\", rec_cgd_hist, width = 8, height = 4.5)\n\n\nrec_cgd_fu &lt;- cgd |&gt; \n  left_join(\n    cgd |&gt; group_by(id) |&gt; summarize(max_fu = max(tstop)),\n    join_by(id)\n  ) |&gt; \n    mutate(\n    id = factor(id),\n    status = factor(status),\n    tstart = tstart / 30.5,\n    tstop = tstop / 30.5,\n    max_fu = max_fu / 30.5,\n    treat = if_else(treat == \"placebo\", \"Placebo\", treat)\n  ) |&gt; \n  ggplot(aes(y = reorder(id, max_fu))) +\n  geom_linerange(aes(xmin = tstart, xmax = tstop)) +\n  geom_point(aes(x = tstop, shape = status), size = 2, fill = \"white\") +\n  geom_vline(xintercept = 0, linewidth = 1) +\n  scale_shape_manual(values = c(23, 15), labels = c(\"Censoring\", \"Infection\")) + \n  scale_x_continuous(\"Time (months)\", limits = c(0, 15), breaks = seq(0, 15, by = 3),\n                     expand= c(0, 0.5)) +\n  scale_y_discrete(\"Patients\") +\n  facet_wrap( ~ treat, scales = \"free\") +\n  theme_minimal() +\n  theme(\n    legend.position = \"top\",\n    legend.title = element_blank(),\n    panel.grid.minor.x = element_blank(),\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.grid.major.y = element_blank()\n  )\n  \nggsave(\"rec_cgd_fu.pdf\", rec_cgd_fu, width = 8, height = 8.5)\nggsave(\"rec_cgd_fu.eps\", rec_cgd_fu, width = 8, height = 8.5)"
  },
  {
    "objectID": "chapter8_tmp.html",
    "href": "chapter8_tmp.html",
    "title": "Chapter 8 - Multivariate Failure Times",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter8_tmp.html#slides",
    "href": "chapter8_tmp.html#slides",
    "title": "Chapter 8 - Multivariate Failure Times",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter8_tmp.html#base-r-code",
    "href": "chapter8_tmp.html#base-r-code",
    "title": "Chapter 8 - Multivariate Failure Times",
    "section": "Base R Code",
    "text": "Base R Code\n\n\nShow the code\n##################################################################\n# This code generates all numerical results in chapter 8.      ##\n##################################################################\n\nlibrary(\"survival\")\n\n################################\n# NCCTG lung cancer study      #\n################################\n\n## read in the NCCTG lung cancer study\n## (clustered data by institution)\ndata &lt;- read.table(\"Data//NCCTG//lung.txt\")\nhead(data)\n\n\n\n\n## Follow up plot\nlibrary(tidyverse)\nlibrary(patchwork)\n\n# function to plot follow-up by\n# institution and sex\ninst_by_sex_fu_plot &lt;- function(df){\n  \n  df |&gt; \n  ggplot(aes(y = reorder(id, time), x = time, color = factor(2 - sex))) +\n  geom_linerange(aes(xmin = 0, xmax = time)) +\n  geom_point(aes(shape = factor(status)), size = 2, fill = \"white\") +\n  geom_vline(xintercept = 0, linewidth = 1) +\n  facet_grid(inst ~ ., scales = \"free\", space = \"free\", switch = \"y\")   +\n  theme_minimal() +\n  scale_x_continuous(\"Time (months)\", limits = c(0, 36), breaks = seq(0, 36, by = 12),\n                     expand = c(0, 0.25)) +\n  scale_y_discrete(\"Patients (by institution)\") +\n  scale_shape_manual(values = c(23, 19), labels = c(\"Censoring\", \"Death\")) +\n  scale_color_brewer(palette = \"Set1\", labels = c(\"Female\", \"Male\"))+\n  theme(\n    strip.background =  element_rect(fill = \"gray90\", color = \"gray90\"),\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    axis.line.y = element_blank(),\n    panel.grid.major.y = element_blank(),\n    legend.title = element_blank()\n  )\n  \n}\n\np1 &lt;- inst_by_sex_fu_plot(data |&gt; filter(inst &lt;= 11))\n\np2 &lt;- inst_by_sex_fu_plot(data |&gt; filter(inst &gt; 11))\n\nmul_lung_fu &lt;- p1 + p2 + plot_layout(ncol = 2, guides = \"collect\") & theme(legend.position = \"top\")\n\n# ggsave(\"mul_lung_fu.pdf\", mul_lung_fu, width = 8, height = 10)\n# ggsave(\"mul_lung_fu.eps\", mul_lung_fu, width = 8, height = 10)\n\n\n# Fit a Cox model with institution-specific frailty\n# to account for correlation within institution\nobj &lt;- coxph(Surv(time, status) ~ age+ factor(sex) + phec + phkn + ptkn +\n        wl + frailty(inst, distribution=\"gamma\"), data = data)\n\nsummary(obj)\n\n# fit a naive Cox model without institution-specific frailty\nobj.naive &lt;- coxph(Surv(time,status)~age+factor(sex)+phec+phkn+ptkn +\n                           wl,data=data)\n\nsummary(obj.naive)\n\n\n####################################################\n#  Prediction of subject-specific survival curves\n#  \n################################################\n\n# Median age\nmed_age &lt;- median(data$age)\n# Median ph.karno\nmed_phkn &lt;- median(data$phkn,na.rm=T)\n# Median pat.karno\nmed_ptkn &lt;- median(data$ptkn,na.rm=T)\n# Median wt.loss\nmed_wl &lt;- median(data$wl,na.rm=T)\n\n# Extract the regression coefficients\nbeta &lt;- obj$coefficients\n# Extract the (only) baseline function\nbase_obj &lt;- basehaz(obj,centered=F)\neta &lt;- base_obj$hazard\nt &lt;- base_obj$time\n\n\n# Figure 8.2 Prediction of survival probabilities for a typical patient \n# of median age (63 years), with median physician-\n#         and patient-rated Karnofsky scores (each 80), and with median\n# weighted loss (7 pounds) by sex and ECOG score.\n\n# Obtain the covariate profiles.\n## Female\nzf0 &lt;- c(med_age,1,0,med_phkn,med_ptkn,med_wl)\nzf1 &lt;- c(med_age,1,1,med_phkn,med_ptkn,med_wl)                              \nzf2 &lt;- c(med_age,1,2,med_phkn,med_ptkn,med_wl) \nzf3 &lt;- c(med_age,1,3,med_phkn,med_ptkn,med_wl) \n\n## Male\nzm0 &lt;- c(med_age,0,0,med_phkn,med_ptkn,med_wl)\nzm1 &lt;- c(med_age,0,1,med_phkn,med_ptkn,med_wl)                              \nzm2 &lt;- c(med_age,0,2,med_phkn,med_ptkn,med_wl) \nzm3 &lt;- c(med_age,0,3,med_phkn,med_ptkn,med_wl) \n\n# Plot the preducted survival curves\npar(mfrow=c(1,2))\nplot(t,exp(-exp(sum(beta*zf0))*eta),type=\"s\",xlim=c(0,35),\n     ylim=c(0,1),frame=F,lty=1,main=\"Female\",\n     xlab=\"Time (months)\",ylab=\"Survival probabilities\",lwd=2,cex.lab=1.3,\n     cex.axis=1.3,cex.main=1.3)\nlines(t,exp(-exp(sum(beta*zf1))*eta),lty=2,lwd=2)\nlines(t,exp(-exp(sum(beta*zf2))*eta),lty=3,lwd=2)\nlines(t,exp(-exp(sum(beta*zf3))*eta),lty=4,lwd=2)\nlegend(\"topright\",lty=1:4,lwd=2,cex=1.2,paste(\"ECOG\",0:3))\n\nplot(t,exp(-exp(sum(beta*zm0))*eta),type=\"s\",xlim=c(0,35),\n     ylim=c(0,1),frame=F,lty=1,main=\"Male\",\n     xlab=\"Time (months)\",ylab=\"Survival probabilities\",lwd=2,cex.lab=1.3,\n     cex.axis=1.3,cex.main=1.3)\nlines(t,exp(-exp(sum(beta*zm1))*eta),lty=2,lwd=2)\nlines(t,exp(-exp(sum(beta*zm2))*eta),lty=3,lwd=2)\nlines(t,exp(-exp(sum(beta*zm3))*eta),lty=4,lwd=2)\nlegend(\"topright\",lty=1:4,lwd=2,cex=1.2,paste(\"ECOG\",0:3))\n\n\n\n################################\n# Diabetic retinopathy study   #\n################################\n\n# read in the data\ndata &lt;- read.table(\"Data//Diabetic Retinopathy Study//drs.txt\")\nhead(data)\n\n# fit a bivariate marginal Cox model\n# with treatment, diabetic type\n# risk score, and treatment*type interaction\n# as covariates\nobj &lt;- coxph(Surv(time, status) ~ trt + type + trt * type + risk\n             + cluster(id), data = data)\n\nsummary(obj)\n\n# Table 8.1 Marginal Cox model analysis of the Diabetic Retinopathy Study\n# output table\ncoeff &lt;- summary(obj)$coeff\n# beta estimate\nc1 &lt;- coeff[,1]\n# robust se and p-value\nc2 &lt;- coeff[,4]\nc3 &lt;- coeff[,6]\n# naive se and p-value\nc4 &lt;- coeff[,3]\nc5 &lt;- 1-pchisq((c1/c4)^2,1)\n\n#output the table\nnoquote(round(cbind(c1,c2,c3,c4,c5),3))\n\n\n\n# Fig. 8.4 Prediction of vision-retention probabilities \n# for patients with a median risk\n# score (10) by treatment for each diabetic type.\n\n# Lambda_0(t) and t\nLt &lt;- basehaz(obj,centered = F)\nt &lt;- Lt$time\nL &lt;- Lt$hazard\n\n# beta\nbeta &lt;- coeff[,1]\n\n# plot the predicted survival functions\n\npar(mfrow=c(1,2))\n# Compute the survival function for \n# adult and juvenile patients in control and treatment\nadult.contr &lt;- exp(-exp(sum(beta*c(0,0,10,0)))*L)\nadult.trt &lt;- exp(-exp(sum(beta*c(1,0,10,0)))*L)\njuv.contr &lt;- exp(-exp(sum(beta*c(0,1,10,0)))*L)\njuv.trt &lt;- exp(-exp(sum(beta*c(1,1,10,1)))*L)\n\n# Plot the predicted survival curves\nplot(t,adult.contr,type=\"s\",xlim=c(0,80),ylim=c(0,1),frame.plot=F,lty=3,main=\"Adult\",\n     xlab=\"Time (months)\",ylab=\"Vision-retention probabilities\",lwd=2, cex.lab=1.2,\n     cex.axis=1.2,cex.main=1.2)\nlines(t,adult.trt,lty=1,lwd=2)\n\nplot(t,juv.contr,type=\"s\",xlim=c(0,80),ylim=c(0,1),frame.plot=F,lty=3,main=\"Juvenile\",\n     xlab=\"Time (months)\",ylab=\"Vision-retention probabilities\",lwd=2,cex.lab=1.2,\n     cex.axis=1.2,cex.main=1.2)\nlines(t,juv.trt,lty=1,lwd=2)\n\n\n\n################################\n# NCCTG lung cancer study      #\n################################\n\n## read in the NCCTG lung cancer study\n## (clustered data by institution)\ndata &lt;- read.table(\"Data//NCCTG//lung.txt\")\n# head(data)\n\n\n\n\n## Follow up plot\nlibrary(tidyverse)\nlibrary(patchwork)\n\n# function to plot follow-up by\n# institution and sex\ninst_by_sex_fu_plot &lt;- function(df){\n  \n  df |&gt; \n  ggplot(aes(y = reorder(id, time), x = time, color = factor(2 - sex))) +\n  geom_linerange(aes(xmin = 0, xmax = time)) +\n  geom_point(aes(shape = factor(status)), size = 2, fill = \"white\") +\n  geom_vline(xintercept = 0, linewidth = 1) +\n  facet_grid(inst ~ ., scales = \"free\", space = \"free\", switch = \"y\")   +\n  theme_minimal() +\n  scale_x_continuous(\"Time (months)\", limits = c(0, 36), breaks = seq(0, 36, by = 12),\n                     expand = c(0, 0.25)) +\n  scale_y_discrete(\"Patients (by institution)\") +\n  scale_shape_manual(values = c(23, 19), labels = c(\"Censoring\", \"Death\")) +\n  scale_color_brewer(palette = \"Set1\", labels = c(\"Female\", \"Male\"))+\n  theme(\n    strip.background =  element_rect(fill = \"gray90\", color = \"gray90\"),\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    axis.line.y = element_blank(),\n    panel.grid.major.y = element_blank(),\n    legend.title = element_blank()\n  )\n  \n}\n\np1 &lt;- inst_by_sex_fu_plot(data |&gt; filter(inst &lt;= 11))\n\np2 &lt;- inst_by_sex_fu_plot(data |&gt; filter(inst &gt; 11))\n\nmul_lung_fu &lt;- p1 + p2 + plot_layout(ncol = 2, guides = \"collect\") & theme(legend.position = \"top\")\n\n\nmul_lung_fu\n\n\n\n\n\n\n\nFigure 1: Follow-up of lung cancer patients by institution and by patient sex. Death rate appears to be higher in males than in females. Clustering of outcomes within institutions is not obvious.\n\n\n\n\n\n\n################################\n# Diabetic retinopathy study   #\n################################\n\n# read in the data\ndata &lt;- read.table(\"Data//Diabetic Retinopathy Study//drs.txt\")\n\n\n# widen the data\ndrs_wide &lt;- data |&gt; \n  pivot_wider(\n    id_cols = c(id, type),\n    values_from = c(time, status),\n    names_from = trt\n  ) |&gt; \n  mutate(\n    xmin = pmin(time_0, time_1),\n    xmax = pmax(time_0, time_1),\n    fav = time_1 &gt;= time_0\n  )\n\nmul_drs_fu &lt;- drs_wide |&gt; \n  ggplot(aes(y = reorder(factor(id), xmax))) +\n  geom_linerange(aes(xmin = 0, xmax = xmin), color = \"gray50\", linewidth = 1) +\n  geom_linerange(aes(xmin = xmin, xmax = xmax, color = fav), linewidth = 1.2, show.legend = FALSE) +\n  geom_point(aes(x = time_1, shape = factor(status_1), color =  FALSE), fill = \"white\", size = 2) +\n  geom_point(aes(x = time_0, shape = factor(status_0), color =  TRUE), fill = \"white\", size = 2) +\n  geom_vline(xintercept = 0, linewidth = 1) +\n  scale_x_continuous(\"Time (months)\", limits = c(0, 76), breaks = seq(0, 72, by = 12), expand = c(0, 0.05)) +\n  scale_y_discrete(\"Patients\") +\n  scale_color_manual(values = c(\"#F8766D\", \"#00BFC4\"), labels = c(\"Treated eye\", \"Control eye\")) + \n  scale_shape_manual(values = c(23, 19, 19), labels = c(\"Censoring\", \"Vision loss\")) + \n  facet_wrap( . ~ str_to_title(type), scales = \"free\") +\n  theme_minimal() +\n  theme(\n    legend.position = \"top\",\n    legend.title = element_blank(),\n    axis.text.y = element_blank(),\n    panel.grid.major.y = element_blank(),\n    strip.text = element_text(size = 11)\n  )\n\nmul_drs_fu\n\n\n\n\n\n\n\nFigure 2: Follow-up of diabetic retinopathy study patients by disease type. Photocoagulation treatment appears to delay onset of blindness in both types, but to a greater degree in adult diabetes."
  },
  {
    "objectID": "chapter7.html",
    "href": "chapter7.html",
    "title": "Chapter 7 - Left Truncation and Interval Censoring",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter7.html#slides",
    "href": "chapter7.html#slides",
    "title": "Chapter 7 - Left Truncation and Interval Censoring",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter7.html#base-r-code",
    "href": "chapter7.html#base-r-code",
    "title": "Chapter 7 - Left Truncation and Interval Censoring",
    "section": "Base R Code",
    "text": "Base R Code\n\n\nShow the code\n##################################################################\n# This code generates all numerical results in chapter 7.      ##\n##################################################################\n\nlibrary(survival)\n\n# read in the Channing study data\nchanning &lt;- read.table(\"Data\\\\Channing House Study\\\\channing.txt\")\n\nhead(channing)\n\n# fit a Cox model to the Channing study data\n# with entry age as left-truncation time\nobj &lt;- coxph(Surv(Entry.Age, End.Age, status) ~ factor(gender), data=channing)\n\nsummary(obj)\n\n### proportionality of gender ####\n# Schoenfeld residuals\nobj_zph &lt;- cox.zph(obj)\n# test result\nobj_zph\n# plot the rescaled residuals\nplot(obj_zph, ylab = \"Gender\", xlab = \"Age (years)\", lwd = 2)\n\n### prediction of (conditional survival) ##\n\nlibrary(tidyverse)\n## numbers at risk\nt &lt;- seq(60, 100, by = 1)\n\n## function to compute number at risk\n## at each t based on entry (T_L) and end (X)\nn_risk_t &lt;- function(entry, end){\n  m &lt;- length(t)\n  n_j &lt;- rep(NA, m)\n  for (j in 1:m){\n    n_j[j] &lt;- sum(entry &lt;= t[j] & t[j] &lt;= end)\n  }\n  return(n_j)\n}\n\n## compute n at risk by gender\nnrisk&lt;- channing |&gt; \n  group_by(gender) |&gt; \n  reframe(\n    n_j = n_risk_t(Entry.Age, End.Age)\n  ) |&gt; \n  add_column(\n    t = rep(t, 2),\n    .before = 1\n  ) |&gt; \n  mutate(\n    gender = if_else(gender == 1, \"Male\", \"Female\")\n  )\n\n# plot n at risk by gender\nnrisk_fig &lt;- nrisk |&gt; \n  ggplot(aes(x = t, y = n_j)) +\n  geom_step(aes(linetype = gender)) +\n  theme_bw() +\n labs(\n   x = \"Age (years)\",\n   y = \"Number at risk\"\n ) +\n theme(\n    legend.title = element_blank(),\n    legend.position = \"top\"\n  )\n\n# set cut-off 70 yo\nt0 &lt;- 70\n# get model-based parameter estimates\nbeta &lt;- obj$coefficients\nLambda0 &lt;- basehaz(obj, centered = FALSE)\nLambda0t0 &lt;- Lambda0[Lambda0$time &gt;= t0,]\nLambda0t0$hazard &lt;- Lambda0t0$hazard - Lambda0t0$hazard[1] ## conditional cum hazard after t0\n\n\n# predicted gender-specific conditional \n# survival functions given 70 yo\nsurv_t0 &lt;- Lambda0t0 |&gt; \n  mutate(\n    St = exp(- hazard),\n    gender = \"Male\"\n  ) |&gt; \n  add_row(\n    Lambda0t0 |&gt; \n      mutate(\n        St = exp(- hazard * exp(beta)),\n        gender = \"Female\"\n      )\n  )\n\n# plot conditional survival functions\nsurv_fig &lt;- surv_t0 |&gt; \n  ggplot(aes(x = time, y = St)) +\n  geom_step(aes(linetype = gender)) +\n  theme_bw() +\n  labs(\n    x = \"Age (years)\",\n    y = \"Conditional survival probabilities\"\n  ) +\n  theme(\n    legend.title = element_blank(),\n    legend.position = \"top\"\n  ) +\n  scale_x_continuous(expand = expansion(c(0, 0.05)))\n\n## package to combine plots\nlibrary(patchwork)\n# combine n-at-risk and conditional-survival plots\nchan_model &lt;- nrisk_fig + surv_fig + plot_layout(ncol = 2, guides = \"collect\") & \n  theme(legend.position = 'top')\n\n# ggsave(\"trunc_chan_model.pdf\", chan_model, width = 8, height = 4)\n# ggsave(\"trunc_chan_model.eps\", chan_model, width = 8, height = 4)\n\n\n\n## BMA HIV study\n## Bangkok Metropolitan Administration HIV Study\ndata &lt;- read.table(\"Data//Bangkok Metropolitan Administration HIV_AIDS Study//bam.txt\")\n\n\n# install the IntCens package from local file\ninstall.packages(\"IntCens_0.1.0.tar.gz\",\n                 repos = NULL,\n                 type = \"source\")\nlibrary(IntCens)\n\n## BMA data\nhead(data)\n\n# get the response data for ICSurvICM()\ndelta &lt;- data$delta\ngamma &lt;- data$gamma\nn &lt;- nrow(data)\nU &lt;- data$U\nV &lt;- data$V\n\n\n# Fit a proportional hazards model\nobj.PH &lt;- ICSurvICM(delta,gamma,U,V,Z = data[,5:9],model=\"PH\")\nprint.ICSurv(obj.PH)\n\n\n# obj.PO &lt;- ICSurvICM(delta,gamma,U,V,Z=data[,5:9],model=\"PO\")\n\n\n# Table 7.3\n# construct a table for hazard ratio and\n# 95% confidence intervals\n\n#regression parameter\nbeta &lt;- obj.PH$beta\nse &lt;- sqrt(diag(obj.PH$var))\nc1 &lt;- round(exp(beta),2)\nc2 &lt;- paste0(\"(\",round(exp(beta-1.96*se),2),\", \",\n   round(exp(beta+1.96*se),2),\")\")\nnoquote(cbind(c1,c2))\n\n\n\n# Prediction of HIV sero-negative probabilities for a median-aged male IDU\n# without histories of needle sharing or drug injection in jail by prior imprisonment\n# status.\npar(mfrow=c(1,1))\nage.med &lt;- median(data[,\"age\"])\nplot.ICSurv(obj.PH, z=c(age.med,1,0,0,0),xlim=c(0,50), lty = 2,\n     xlab=\"Time (months)\",ylab=\"HIV sero-negative probabilities\",\n     lwd=2, main = \"\")\nplot.ICSurv(obj.PH, z=c(age.med,1,0,1,0), xlim=c(0,50), add=T,\n     lwd=2)\nlegend(0, 0.3, lty=c(2, 1), c(\"Not jailed before\",\"Jailed before\"), lwd=2)"
  },
  {
    "objectID": "chapter7.html#follow-up-plots",
    "href": "chapter7.html#follow-up-plots",
    "title": "Chapter 7 - Left Truncation and Interval Censoring",
    "section": "Follow-up Plots",
    "text": "Follow-up Plots\nVisualization of subject-level follow-up under left truncation or interval censoring must account for the nonzero entry time or the imprecise location of the endpoint. This makes it different from right-censored data. To show the additional information, we need additional features on the plot.\n\nUnder left truncation\nFor each subject, we use a line segment to represent the period \\([T_{Li}, X_i]\\) on study, at the end of which the outcome event is distinguished from censoring by point shape.\nThe following is an example using the Channing House study.\n\nlibrary(tidyverse)\n# read in the Channing study data\nchanning &lt;- read.table(\"Data\\\\Channing House Study\\\\channing.txt\")\n\n# head(channing)\n# take a random sample of 100 females\nset.seed(2024)\nchanning_f_sub &lt;- channing |&gt; \n  filter(gender == 2) |&gt; \n  sample_n(100)\n# take all males\nchanning_m_sub &lt;- channing |&gt; \n  filter(gender == 1) \n\n# combine the sub-samples\nchanning_sub &lt;- channing_f_sub |&gt; add_row(channing_m_sub)\nn &lt;- nrow(channing_sub) # number of subjects in the sub-sample\n\n# panel labeller\ngender_labeller &lt;- c(\"1\" = \"Males\", \"2\" = \"Females\")\n\n# follow -up plot\nchan_fig &lt;- channing_sub |&gt; \n  add_column(ID = 1 : n) |&gt; # add an ID column as y-axis\n  ggplot(aes(y = reorder(ID, End.Age))) + # order subject ID shown on y-axis by end time\n  geom_linerange(aes(xmin = Entry.Age, xmax = End.Age)) + # line range (T_L, X)\n  geom_point(aes(x = Entry.Age, shape = \"2\"), fill = \"white\", size = 2) + # entry point (2)\n  geom_point(aes(x = End.Age, shape = factor(status)), fill = \"white\", size = 2)  + \n  # endpoint (1: event; 0: censoring)\n  geom_vline(xintercept = 60, linewidth = 1) + # start line at age 60\n  facet_wrap(~ gender, ncol = 2, scales = \"free\", # by gender\n             labeller = labeller(gender = gender_labeller)) +\n  theme_minimal() +\n  scale_y_discrete(name = \"Subjects\") +\n  scale_x_continuous(name = \"Age (years)\", limits = c(60, 100), \n                     breaks = seq(60, 100, by = 10), \n                     expand = expansion(c(0, 0.05)))  +\n  scale_shape_manual(limits = c(\"2\", \"0\", \"1\"),  values = c(22, 23, 19), \n                      labels = c(\"Admission\", \"Censoring\", \"Death\")) + # set the point shapes\n  theme( # theme formatting\n    legend.position = \"top\",\n    legend.title = element_blank(),\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.grid.major.y = element_blank(),\n    legend.text = element_text(size = 11),\n    axis.title = element_text(size = 11),\n    axis.text = element_text(size = 10),\n    strip.text = element_text(size = 10)\n  )\n\nchan_fig\n# ggsave(\"trunc_chan_fig.pdf\", chan_fig, width = 8, height = 9)\n# ggsave(\"trunc_chan_fig.eps\", chan_fig, width = 8, height = 9)\n\n\n\n\n\n\n\nFigure 1: Follow-up plots for a random sample of 100 residents for each gender in the Channing House study. Males appear to suffer more deaths than females.\n\n\n\n\n\n\n\nUnder interval censoring\nFor each subject, we use a gray line to represent the follow-up period. The check-up times can be marked on it by dots if such data are available. The event-containing interval \\([L_i, R_i]\\) (\\(R_i&lt;\\infty\\)) is highlighted from the rest of the follow-up period using a black line segment.\nThe following is an example using the Bangkok Metropolitan Administration HIV study.\n\nlibrary(IntCens)\n## BMA HIV study\n## Bangkok Metropolitan Administration HIV Study\nbma &lt;- read.table(\"Data//Bangkok Metropolitan Administration HIV_AIDS Study//bam.txt\")\n\n# sample size\nn &lt;- nrow(bma)\n\n# create L and R\nbma_lr &lt;- bma |&gt; \n  mutate(\n    ID = 1 : n, \n    L = case_when(\n      delta == 1 ~ 0,\n      gamma == 1 ~ U,\n      delta + gamma == 0 ~ V\n    ),\n    R = case_when(\n      delta == 1 ~ U,\n      gamma == 1 ~ V,\n      delta + gamma == 0 ~ Inf\n    ),\n    .before = 1\n  )\n\n# take a random sample of 150 subjects per imprisonment status\nset.seed(2024229)\nbma_lr_jail_sub &lt;- bma_lr |&gt; \n  filter(jail == 1) |&gt; \n  sample_n(150) \n  \nbma_lr_nojail_sub &lt;- bma_lr |&gt; \n  filter(jail == 0) |&gt; \n  sample_n(150) \n\n## combine the sub-samples\nbma_lr_sub &lt;- bma_lr_jail_sub |&gt; \n  add_row(bma_lr_nojail_sub) |&gt; \n  mutate(\n    end = ifelse(R == Inf, L, R),\n    status = (R &lt; Inf) + 0 # an indicator of event occurence vs right censoring\n  )\n\n\n# panel labeller\njail_labeller &lt;- c(\"0\" = \"No imprisonment\", \"1\" = \"Imprisonment\")\n\n# follow -up plot\nbma_fig &lt;- bma_lr_sub |&gt; \n  ggplot(aes(y = reorder(factor(ID), end))) + # order subjects by R or last check-up\n  geom_linerange(aes(xmin = 0, xmax = L), alpha = 0.3) + # gray line for non-event-containing period\n  geom_linerange(data = bma_lr_sub |&gt; filter(status == 1), \n    aes(xmin = L, xmax = R), linetype = 1) + # black line for event-containing interval\n  geom_point(data = bma_lr_sub |&gt; filter(status == 1), aes(x = L, shape = \"1\"), size = 2) +\n  geom_point(data = bma_lr_sub |&gt; filter(status == 1), aes(x = R, shape = \"1\"), size = 2) +\n  geom_point(data = bma_lr_sub |&gt; filter(status == 0), aes(x = L, shape = \"0\"), \n             fill = \"white\", size = 2) + # different point shapes\n  geom_vline(xintercept = 0) +\n  facet_wrap(~ jail, scales = \"free\", labeller = labeller(jail = jail_labeller)) + \n  # by imprisonment status\n  theme_minimal() +\n  scale_y_discrete(name = \"Subjects\") +\n  scale_x_continuous(name = \"Time (months)\", \n                     breaks = seq(0, 48, by = 6), \n                     expand = expansion(c(0, 0.05))) +\n  scale_shape_manual(limits = c(\"0\", \"1\"),  values = c(23, 19), \n                      labels = c(\"Right censoring\", \"L-R containing seroconversion\")) +\n  # set point shapes\n theme( # theme formatting\n    legend.position = \"top\",\n    legend.title = element_blank(),\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.grid.major.y = element_blank(),\n    legend.text = element_text(size = 11),\n    axis.title = element_text(size = 11),\n    axis.text = element_text(size = 10),\n    strip.text = element_text(size = 10)\n  )\n\nbma_fig\n# ggsave(\"trunc_bma_fig.pdf\", bma_fig, width = 8, height = 12)\n# ggsave(\"trunc_bma_fig.eps\", bma_fig, width = 8, height = 12, device = cairo_pdf)\n\n\n\n\n\n\n\nFigure 2: Follow-up plots for a random sample of 150 intravenous drug users by imprisonment history in the Bangkok Metropolitan Administration study. Those who have been imprisoned before appear more likely to experience sero-conversion."
  },
  {
    "objectID": "chapter5.html",
    "href": "chapter5.html",
    "title": "Chapter 5 - Other Non- and Semi-parametric Methods",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter5.html#slides",
    "href": "chapter5.html#slides",
    "title": "Chapter 5 - Other Non- and Semi-parametric Methods",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter5.html#base-r-code",
    "href": "chapter5.html#base-r-code",
    "title": "Chapter 5 - Other Non- and Semi-parametric Methods",
    "section": "Base R Code",
    "text": "Base R Code\n\n\nShow the code\n##################################################################\n# This code generates all numerical results in chapter 5.      ##\n##################################################################\n\n\nlibrary(survival)\n\n##############################################\n# GBC study\n#############################################\n#read in the complete data\ngbc &lt;- read.table(\"Data//German Breast Cancer Study//gbc.txt\")\n\n#subset to first event data\n#Sort the data by time within each id\no &lt;- order(gbc$id,gbc$time)\ngbc &lt;- gbc[o,]\n#get the first row for each id\ndata.CE &lt;- gbc[!duplicated(gbc$id),]\n\n#set status=1 if status==2 or 1\ndata.CE$status &lt;- (data.CE$status&gt;0)+0\n\n\n\n############################################\n# Restricted mean surval time (RMST) analysis\n# with the \"survRM2\" package\n##########################################\n\n#install the package\ninstall.packages(\"survRM2\")\nlibrary(survRM2)\n\n\n# Two-sample testing between hormonal and non-hormonal\n# groups on 5-year RMST\nobj &lt;- rmst2(time = data.CE$time/12, status = data.CE$status, \n            arm = data.CE$hormone - 1, tau=5)\n\n# print out results\nobj\n# more compact results\nobj$unadjusted.result\n\n\n# Graphical display of the group-specific RMST \n# as area under the KM curves\nplot(obj, xlab=\"Time (years)\", ylab = \"Relapse-free survival\",\n     col.RMST = \"gray\", col.RMTL = \"white\", cex.lab=1.2,\n     cex.axis=1.2, col=\"black\", xlim=c(0,5))\n\n\n# Regression with all the other covariate\nobj.reg &lt;- rmst2(time = data.CE$time / 12, status = data.CE$status, \n            arm = data.CE$hormone-1, covariates = data.CE[, 5:11], tau = 5)\n\n#overall results\nobj.reg\n\n# additive model on RMST\nround(obj.reg$RMST.difference.adjusted, 3)\n\n# multiplicative model on RMST\nround(obj.reg$RMST.ratio.adjusted, 3)\n\n# multiplicative model on RMTL\nround(obj.reg$RMTL.ratio.adjusted, 3)\n\n# for hormone treatment only \nobj.reg$adjusted.result\n\n\n####################################\n### Additive hazards analysis\n## using the \"addhazard\" package\n####################################\n\ninstall.packages(\"addhazard\")\nlibrary(addhazard)\n \n # Fit additive hazards model\n \n## preparation\ndata.CE$hormone &lt;- factor(data.CE$hormone)\ndata.CE$meno &lt;- factor(data.CE$meno) \n\n# Add an infinitesimal random number to time\n # to get rid of ties\ndata.CE$time.dties &lt;- data.CE$time/12 + runif(nrow(data.CE),0, 1e-12) \n\n\n# fit an additive hazard model\nobj &lt;- ah(Surv(time.dties,status) ~ hormone + meno\n       + age + size + grade + prog + estrg,\n       data = data.CE, ties = FALSE)\n\n# print out the summary\n summary(obj)\n \n ## Aalen's model\n # \n # library(timereg)\n # \n # obj_aalen &lt;- aalen(Surv(time.dties,status) ~ factor(hormone), data = data.CE)\n # \n # obj_aalen$cum\n # obj_aalen$var.cum\n # summary(obj_aalen)\n \n \n \n ####################################\n ### Proportional odds analysis\n ## using the \"timereg\" package\n ####################################\n \n install.packages(\"timereg\")\n library(timereg)\n \n # Fit a proportional odds model\n ## need to convert hormone and meno from numeric to factor\n obj &lt;- prop.odds(Event(time, status) ~ hormone + meno\n        + age + size + grade + prog + estrg,\n        data = data.CE)\n\n summary(obj)\n \n # Baseline cumulative odds function\n t &lt;- obj$cum[,1]\n base_odds &lt;- obj$cum[,2]\n \n # Plot baseline cumulative odds\n par(mfrow = c(1, 1))\n plot(stepfun(t, c(0, base_odds)), do.points = FALSE, lwd = 2,\n      xlim=c(0,80), ylim=c(0,1.4), frame.plot = FALSE,\n      ylab=\"Baseline cumulative odds\", xlab=\"Time (months)\", main =\"\")\n \n\n \n ###########################################\n ### Accelerated failure time (AFT) analysis\n ## using the \"aftgee\" package\n ##########################################\n \n install.packages(\"aftgee\")\n library(aftgee)\n \n # fit an AFT model\n ## need to convert hormone and meno from numeric to factor\n ## (will take a little longer than usual...)\n obj &lt;- aftgee(Surv(time, status) ~ hormone + meno\n               + age + size + grade + prog + estrg,\n               data = data.CE)\n  # print out summary\n  summary(obj)\n \n exp(obj$coef.res) ## acceleration factors exp(beta)"
  },
  {
    "objectID": "chapter3_tmp.html",
    "href": "chapter3_tmp.html",
    "title": "Chapter 3 - Nonparametric Estimation and Testing",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter3_tmp.html#slides",
    "href": "chapter3_tmp.html#slides",
    "title": "Chapter 3 - Nonparametric Estimation and Testing",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter3_tmp.html#base-r-code",
    "href": "chapter3_tmp.html#base-r-code",
    "title": "Chapter 3 - Nonparametric Estimation and Testing",
    "section": "Base R Code",
    "text": "Base R Code\n\n\nCode\n##################################################################\n# This code generates all numerical results in  chapter 3.      ##\n##################################################################\n\n###################################################\n# Figure 3.2  and Table 3.1                 \n# Nelsen-Aalen estimator of cumulative hazard function\n# for the rat study\n###################################################\n\nlibrary(survival)\n# ##################################################\n# Description of \"rats\" dataset\n# \n# Rat treatment data from Mantel et al. Three rats were chosen from each of 100 litters, \n# one of which was treated with a drug, and then all followed for tumor incidence.\n# \n# \n# \n# \n# Format\n# litter:   litter number from 1 to 100\n# rx:   treatment,(1=drug, 0=control)\n# time: time to tumor or last follow-up\n# status:   event status, 1=tumor and 0=censored\n# sex:  male or female\n# \n# N. Mantel, N. R. Bohidar and J. L. Ciminera. Mantel-Haenszel analyses of litter-matched \n# time to response data, with modifications for recovery of interlitter information. \n# Cancer Research, 37:3863-3868, 1977.\n##############################################################\n\nrats &lt;- read.table(\"Data//Rat Tumorigenicity Study//rats.txt\", header = T)\n\nhead(rats)\n\n#subset to treatment arm\nrats.rx &lt;- rats[rats$rx==1,]\n\n\n\n\n\n#X and delta\ntime &lt;- rats.rx$time\nstatus &lt;- rats.rx$status\n\n#ordered unique  event times\nts &lt;- unique(sort(time[status==1]))\nm &lt;- length(ts)\nts\n#numbers of failures at each point in ts\nds &lt;- table(time[status==1])\n##numbers at risk at each point in ts\nns &lt;- rep(NA,m)\n##Nelsen-Aalen estimator\n## for dLambda \ndL &lt;- rep(NA,m)\n## and Lambda\nL &lt;- rep(NA,m)\nfor (j in 1:m){\n  ns[j] &lt;- sum(time&gt;=ts[j])\n  dL[j] &lt;- ds[j]/ns[j]\n  L[j] &lt;- sum(dL[1:j])\n}\n\nresults &lt;- cbind(ts,ds,ns,dL,L)\n#print the table\nround(results,3)\n\n#plot the estimated cumulative hazard function\npar(mfrow=c(1,1))\nplot(stepfun(ts,c(0,L)),do.points = F,ylim=c(0,0.4),xlim=c(0,120),lwd=2,frame=F,\n     xlab=\"Time (days)\",ylab=\"Cumulative hazard function\",main=\"\",\n     cex.lab=1.5,cex.axis=1.5)\n\n\n\n###################################################\n# Table 3.2                 \n# Kaplan-Meier (KM) estimator of survival function\n# for the rat study\n###################################################\n\n#csurv (conditional survival): 1-d_j/n_j\ncsurv &lt;- 1 - dL\n#variance of csurv by Greenwoods's formula\nvar.csurv &lt;- ds/(ns*(ns-ds))\n\n#KM estimates of survival function\nKMsurv &lt;- rep(NA,m)\n##Greenwoods formula for se\nse &lt;- rep(NA,m)\n\n# Compute the KM estimates and Greenwood's se\nfor (j in 1:m){\n  KMsurv[j] &lt;- prod(csurv[1:j])\n  se[j] &lt;- KMsurv[j]*sqrt(sum(var.csurv[1:j]))\n}\n\nresults2 &lt;- cbind(ts,ds,ns,csurv,KMsurv,se)\n#print the table\nround(results2,3)\n  \n\n\n\n###################################################\n# Figure 3.3                 \n# Kaplan-Meier (KM) estimator of survival function\n# for the rat study\n###################################################\n\nobj &lt;- survfit(Surv(time,status)~1,data=rats.rx,conf.type=\"log-log\")\n\nsummary(obj)\n\n#plot the estimated cumulative hazard function\npar(mfrow=c(1,1))\nplot(obj,ylim=c(0,1),xlim=c(0,100),lwd=2,frame=F,\n     xlab=\"Time (days)\",ylab=\"Survival probabilities\",main=\"\",\n     cex.lab=1.5,cex.axis=1.5)\nlegend(1,0.2,lty=1:2,c(\"Kaplan-Meier curve\",\"95% Confidence limits\"),\n       lwd=2,cex=1.5)\n\n\n\n#################################################\n#   log-rank test for rat study\n#   combing treatment and control\n#################################################\n#dataset\nhead(rats)\n\n# log-rank test on treatment difference\nsurvdiff(Surv(time,status)~rx+ strata(sex),\n         data=rats,rho=0)\n\n##############################################\n# GBC study: igure 3.5 and related test results \n#############################################\n#read in the complete data\ngbc &lt;- read.table(\"German Breast Cancer Study//gbc.txt\")\n\n#subset to first event data\n#Sort the data by time within each id\no &lt;- order(gbc$id,gbc$time)\ngbc &lt;- gbc[o,]\n#get the first row for each id\ndata.CE &lt;- gbc[!duplicated(gbc$id),]\n\n#set status=1 if status==2 or 1\ndata.CE$status &lt;- (data.CE$status&gt;0)+0\n\n\n\n################################################\n# Figure 3.5  Plot the KM curves by hormonal group \n# stratified by menopausal status for GBC study\n################################################\n\npar(mfrow=c(1,3))\n## overall\nobj &lt;- survfit(Surv(time,status)~hormone,data=data.CE)\nplot(obj, xlim=c(0,80),lwd=2,frame=F, lty=c(2,1),\n     xlab=\"Time (months)\",ylab=\"Relaspe-free survival probabilities\",main=\"Overall\",\n     cex.lab=1.5,cex.axis=1.5,cex.main=1.5)\nlegend(1,0.2,lty=2:1,c(\"No Hormone\",\"Hormone\"),\n       lwd=2,cex=1.5)\n\n## pre-menopausal\nobj.pre &lt;- survfit(Surv(time,status)~hormone,data=data.CE[data.CE$meno==1,])\nplot(obj.pre, xlim=c(0,80),lwd=2,frame=F, lty=c(2,1),\n     xlab=\"Time (months)\",ylab=\"Relaspe-free survival probabilities\",main=\"Pre-Menopausal\",\n     cex.lab=1.5,cex.axis=1.5,cex.main=1.5)\nlegend(1,0.2,lty=2:1,c(\"No Hormone\",\"Hormone\"),\n       lwd=2,cex=1.5)\n\n## post-menopausal\nobj.post&lt;- survfit(Surv(time,status)~hormone,data=data.CE[data.CE$meno==2,])\nplot(obj.post, xlim=c(0,80),lwd=2,frame=F, lty=c(2,1),\n     xlab=\"Time (months)\",ylab=\"Relaspe-free survival probabilities\",main=\"Post-Menopausal\",\n     cex.lab=1.5,cex.axis=1.5,cex.main=1.5)\nlegend(1,0.2,lty=2:1,c(\"No Hormone\",\"Hormone\"),\n       lwd=2,cex=1.5)\n\n\n\n## Stratified log-rank test (by menopausal status)\nsurvdiff(Surv(time,status)~hormone+ strata(meno),\n         data=data.CE)\n## Unstratified log-rank test\nsurvdiff(Surv(time,status)~hormone,\n         data=data.CE)"
  },
  {
    "objectID": "chapter3_tmp.html#tidyverse-solutions",
    "href": "chapter3_tmp.html#tidyverse-solutions",
    "title": "Chapter 3 - Nonparametric Estimation and Testing",
    "section": "Tidyverse Solutions",
    "text": "Tidyverse Solutions\n\nlibrary(\"survminer\")\n\nWarning: package 'survminer' was built under R version 4.4.1\n\n\nLoading required package: ggplot2\n\n\nLoading required package: ggpubr\n\n\nWarning: package 'ggpubr' was built under R version 4.4.1\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.3     ✔ tibble    3.2.1\n✔ purrr     1.0.2     ✔ tidyr     1.3.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(\"survival\")\n\nWarning: package 'survival' was built under R version 4.4.1\n\n\n\nAttaching package: 'survival'\n\nThe following object is masked from 'package:survminer':\n\n    myeloma\n\nfit&lt;- survfit(Surv(time, status) ~ sex, data = lung)\n\n# Drawing survival curves\nggsurvplot(fit, data = lung, risk.table = TRUE)\n\n\n\n\n\n\n\ntab3_1 &lt;- tribble(\n  ~time, ~status,\n     101,     0, \n      55,     0,\n    67,      1, \n    23,      0, \n  45,    1, \n   98,     0, \n  34,      1,  \n   77,      0, \n   91,     0, \n  104,     0,  \n   88,     1\n) |&gt; \n  mutate(\n    id = row_number(),\n    .before = 1\n  )\n\n\n\nfig3_2 &lt;- tab3_1 |&gt; \n  ggplot(aes(x = time, y = reorder(id, time))) +\n  geom_linerange(aes(xmin = 0, xmax = time)) +\n  geom_point(aes(shape = factor(status)), size = 2.5, fill = \"white\") +\n  geom_vline(xintercept = 0, linewidth = 1) +\n  theme_minimal() +\n  scale_y_discrete(name = \"Rats\") +\n  scale_x_continuous(name = \"Time (days)\", breaks = seq(0, 100, by = 20), \n                     expand = expansion(c(0, 0.05))) +\n  scale_shape_manual(values = c(23, 19), labels = c(\"Censoring\", \"Tumor development\")) +\n  theme(\n    legend.position = \"top\",\n    legend.title = element_blank(),\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.grid.major.y = element_blank(),\n    legend.text = element_text(size = 11)\n    \n  )\n  \n\nggsave(\"km_rats.pdf\", fig3_2, width = 8, height = 3.2)\nggsave(\"km_rats.eps\", fig3_2, width = 8, height = 3.2)\n\n\n#read in the complete data\ngbc &lt;- read.table(\"Data//German Breast Cancer Study//gbc.txt\")\n\ngbc_ce &lt;- gbc |&gt; \n  group_by(id) |&gt; \n  slice_min(time) |&gt; \n  slice_max(status) \n\n\n# gbc_ce |&gt; \n#   count(id) |&gt; \n#   filter(n&gt;1)\n# \n# gbc |&gt; \n#   filter(\n#     status == 1\n#   )\n\nn &lt;- nrow(gbc)\n\nset.seed(2024)\ngbc_ce_sub &lt;- gbc_ce |&gt; \n  filter(id %in% sample(n, 200)) \n\n# create a vector to label the panels\nhormone_labeller &lt;- c(\"1\" = \"No Hormone\", \"2\" = \"Hormone\")\n\nfig3_5 &lt;- gbc_ce_sub |&gt; \n  ggplot(aes(x = time, y = reorder(factor(id), time))) +\n  geom_linerange(aes(xmin = 0, xmax = time)) +\n  geom_point(aes(shape = factor(status), fill = factor(status)), size = 2.5) +\n  geom_vline(xintercept = 0, linewidth = 1) +\n  theme_minimal() +\n  scale_y_discrete(name = \"Patients\") +\n  scale_x_continuous(name = \"Time (months)\", breaks = seq(0, 84, by = 12), \n                     expand = expansion(c(0, 0.05))) +\n  scale_shape_manual(values = c(23, 22, 19), \n                     labels = c(\"Censoring\", \"Relapse\", \"Death\")) +\n  \n  scale_fill_manual(values = c(\"white\", \"black\", \"black\"), \n                     labels = c(\"Censoring\", \"Relapse\", \"Death\")) +\n  facet_wrap(~ hormone, scales = \"free\", \n             labeller = labeller(hormone = hormone_labeller)) +\n  theme(\n    legend.position = \"top\",\n    legend.title = element_blank(),\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.grid.major.y = element_blank(),\n    legend.text = element_text(size = 11)\n    \n  )\n\n\nggsave(\"km_gbc_fu.pdf\", fig3_5, width = 8, height = 9)\nggsave(\"km_gbc_fu.eps\", fig3_5, width = 8, height = 9)\n\n\nfit &lt;- survfit(Surv(time, status &gt; 0) ~ hormone, data = gbc_ce)\nggsurvplot(fit, gbc_ce, risk.table = TRUE,\n                palette = \"jco\", pval = TRUE,\n           risk.table.height = 0.2)"
  },
  {
    "objectID": "chapter2.html",
    "href": "chapter2.html",
    "title": "Chapter 2 - Mathematical Foundations",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)",
    "crumbs": [
      "Home",
      "Part I - Univariate Events",
      "Chapter 2 - Mathematical Foundations"
    ]
  },
  {
    "objectID": "chapter2.html#slides",
    "href": "chapter2.html#slides",
    "title": "Chapter 2 - Mathematical Foundations",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)",
    "crumbs": [
      "Home",
      "Part I - Univariate Events",
      "Chapter 2 - Mathematical Foundations"
    ]
  },
  {
    "objectID": "chapter2.html#chapter-summary",
    "href": "chapter2.html#chapter-summary",
    "title": "Chapter 2 - Mathematical Foundations",
    "section": "Chapter Summary",
    "text": "Chapter Summary\nTime-to-event data require specialized techniques for analysis. These tend to focus on the survival function \\(S(t)\\) and the hazard function \\(\\lambda(t)\\) of the latent (uncensored) event time \\(T\\). Some methods rely on parametric models, while others leverage counting processes and martingales for robust inference.\n\nNotation and basic quantities\nAn outcome event time can be represented either as a random variable \\(T\\) or as a counting process \\(N^*(t) = I(T \\le t)\\). The survival function is defined as \\[\nS(t) = \\mathrm{pr}(T &gt; t),\n\\] while the hazard function \\(\\lambda(t)\\) quantifies the instantaneous risk of experiencing the event at time \\(t\\), conditional on survival up to that point. The cumulative hazard function is obtained by integrating \\(\\lambda(t)\\) over \\([0, t]\\): \\(\\Lambda(t) = \\int_0^t \\lambda(u)\\,\\mathrm{d}u\\), and relates to \\(S(t)\\) via \\[\n\\Lambda(t) = -\\log\\bigl\\{S(t)\\bigr\\} \\quad\\Longleftrightarrow\\quad S(t) = \\exp\\bigl\\{-\\Lambda(t)\\bigr\\}.\n\\] This relationship is central in survival analysis.\nSimple parametric models for \\(T\\) include the exponential, Weibull, Gamma, and log-normal distributions, each with distinct hazard functions. The exponential model assumes constant hazard, while the Weibull model allows for time-varying (but still monotone) hazards.\n\n\nObserved data and likelihood\nIn practice, the event time is subject to censoring by time \\(C\\). As a result, we only observe \\(X = \\min(T, C)\\), along with the event indicator \\(\\delta = I(T \\le C)\\). Under independent censoring, the likelihood function for the observed data \\((X, \\delta)\\) is given by \\[\np\\bigl(X,\\delta\\bigr)\n\\;=\\;\n\\lambda\\bigl(X\\bigr)^{\\delta}\\,S\\bigl(X\\bigr).\n\\] This means that, for a sample of size \\(n\\), the log-likelihood is \\[\n\\ell_n(\\theta) =  \nn^{-1}\\sum_{i=1}^n\n\\Bigl\\{\n  \\delta_i\\,\\log \\lambda\\bigl(X_i;\\theta\\bigr)\n  \\;-\\;\n  \\int_{0}^{\\infty}\n    I\\bigl(X_i \\ge t\\bigr)\\,\\lambda\\bigl(t;\\theta\\bigr)\\,\\mathrm{d}t.\n\\Bigr\\}\n\\] where \\(\\lambda(t;\\theta)\\) is the hazard function parametrized by \\(\\theta\\). We can use this general expression for the log-likelihood to derive maximum likelihood estimator for any parametric models.\n\n\nStochastic integrals and martingales\nTo count the observed event under censoring, define \\(N(t) = N^*(t\\wedge C)\\), where \\(x\\wedge y = \\min(x, y)\\). The step function \\(N(t)\\) takes a jump of size 1, i.e., \\(\\mathrm{d}N(t)=1\\), at \\(t = X\\) if \\(\\delta = 1\\); it stays flat if \\(\\delta = 0\\). Hence, any function of the form \\(\\delta h(X)\\) can be re-written as a stochastic integral \\(\\int_0^\\infty h(t)\\mathrm{d}N(t)\\).\nIf we consider \\(\\mathrm{d}N(t)\\) as the Bernoulli response of event occurrence at time \\(t\\), then we can decompose it into \\(\\mathrm{d}N(t) = I(X\\ge t)\\lambda(t)\\mathrm{d} t + \\mathrm{d}M(t)\\), where \\[\n\\mathrm{d}M(t)\n\\;=\\;\n\\underbrace{\\mathrm{d}N(t)}_{\\text{Observed}}\n\\;-\\;\n\\underbrace{I\\bigl(X \\ge t\\bigr)\\,\\lambda(t)\\,\\mathrm{d}t}_{\\text{Expectation given data\nprior to $t$}}.\n\\] is the martingale increment.\nThe martingale property of \\(M(t)\\) implies that the expectation of \\(\\mathrm{d}M(t)\\), given the event history up to time \\(t\\), is zero. It also implies that the increments at different times are uncorrelated. This property of uncorrelated increments simplifies the variance calculation for martingale integrals of the form: \\[\n\\int_0^t h(u)\\,\\mathrm{d}M(u)\n\\] Many test statistics, estimators, and score functions can be expressed in the above form, and the martingale properties facilitate their asymptotic analysis.\n\n\nConclusion\nAlthough \\(T\\) may not be directly observed, the partial information in \\((X, \\delta)\\) still supports principled inferences about its distribution. Parametric models describe \\(\\lambda(t)\\) or \\(S(t)\\) via a likelihood-based approach, while a martingale-based framework captures event processes through residuals and their properties. The latter approach will be utilized extensively in the non- and semi-parametric analysis presented in later chapters.",
    "crumbs": [
      "Home",
      "Part I - Univariate Events",
      "Chapter 2 - Mathematical Foundations"
    ]
  },
  {
    "objectID": "chapter14.html",
    "href": "chapter14.html",
    "title": "Chapter 14 - Causal Inference in Survival Analysis",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter14.html#slides",
    "href": "chapter14.html#slides",
    "title": "Chapter 14 - Causal Inference in Survival Analysis",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter14.html#base-r-code",
    "href": "chapter14.html#base-r-code",
    "title": "Chapter 14 - Causal Inference in Survival Analysis",
    "section": "Base R Code",
    "text": "Base R Code\n\n\nShow the code\n##################################################################\n# This code generates all numerical results in chapter 14.     ##\n##################################################################\n\n\nlibrary(survival)\n##############################################\n# GBC study\n#############################################\n#read in the complete data\ngbc &lt;- read.table(\"Data//German Breast Cancer Study//gbc.txt\")\n\n#subset to first event data\n#Sort the data by time within each id\no &lt;- order(gbc$id,gbc$time)\ngbc &lt;- gbc[o,]\n#get the first row for each id\ndata.CE &lt;- gbc[!duplicated(gbc$id),]\n\n#set status=1 if status==2 or 1\ndata.CE$status &lt;- (data.CE$status&gt;0)+0\n\nhead(data.CE)\n\n\n######################\n# Section 14.2.3\n######################\n\n# create treatment variable A\n# A=1: hormone treatment\n# A=0: non-treatment\ndata.CE$A &lt;- data.CE$hormone - 1\n\n\n\n# Load the ipw package for propensity score calculation\nlibrary(ipw)\n\n# compute propensity score for A against\n# menopausal status, tumor size, grade, nodes,\n# progesterone and estrogen receptor levels\ntmp &lt;- ipwpoint(exposure=A,family=\"binomial\",link=\"logit\",\n              denominator=~ meno+size+factor(grade)+nodes+\n                  prog+estrg, data=data.CE)\n\n# naive version (unweighted)\nobj.naive &lt;- survfit(Surv(time,status)~A,data=data.CE)\n# IPTW version (weighted by temp$ipw.weights computed from the\n#   ipwpoint() function)\nobj &lt;- survfit(Surv(time,status) ~ A,weights = tmp$ipw.weights, data = data.CE)\n\n\n# IPTW Cox model (essentially a marginal structural Cox model)\ncoxph(Surv(time,status)~A,weights=tmp$ipw.weights,data=data.CE)\n\ncoxph(Surv(time,status)~A,data=data.CE)\n\n\n#########################################################\n# Figure 15.3 Naive and IPTW-adjusted Kaplan--Meier \n# curves for the German Breast Cancer study by treatment\n#########################################################\nplot(obj.naive, xlim=c(0,80),lwd=2,frame=F, lty=c(2,1),\n     xlab=\"Time (months)\",ylab=\"Relaspe-free survival probabilities\",\n     cex.lab=1.5,cex.axis=1.5)\n\nlines(obj,col='red',lty=c(2,1), cex.lab=1.5,cex.axis=1.5)\nlegend(1,0.3,lty=c(2:1,2:1), col=rep(c(\"black\",\"red\"),each=2),\n       c(\"No Hormone (naive)\",\"Hormone (naive)\",\n         \"No Hormone (IPTW)\",\"Hormone (IPTW)\"),\n       lwd=2,cex=1.5)\n\n\n\n################################\n# Section 14.3.3 HIV/AIDS study \n################################\n\n# need the ipw package\ndata(\"haartdat\")\ncolnames(haartdat)[8] &lt;- \"cd4\"\n\nhead(haartdat)\n\n\n\n# Compute the IPTW weights\niptw &lt;- ipwtm(exposure = haartind, family = \"survival\",\n          numerator = ~ sex + age, denominator = ~ cd4 + sex + age,\n          id = patient, tstart = tstart, timevar = fuptime, type = \"first\",\n          data = haartdat)\n\n# Compute the IPCW weights\nipcw &lt;- ipwtm(exposure = dropout, family = \"survival\",\n              numerator = ~ sex + age, denominator = ~ cd4 + sex + age,\n              id = patient, tstart = tstart, timevar = fuptime, type = \"first\",\n              data = haartdat)\n\n# Fit IPTW/IPCW marginal structural Cox model\nobj &lt;- coxph(Surv(tstart, fuptime, event) ~ haartind + sex + age+ \n               cluster(patient), data = haartdat, \n             weights = iptw$ipw.weights*ipcw$ipw.weights)\nsummary(obj)\n\n\n# Naive Cox model with time-varying treatment\nobj_naive &lt;- coxph(Surv(tstart, fuptime, event) ~ haartind + sex + age+ \n               cluster(patient), data = haartdat)\nsummary(obj_naive)"
  },
  {
    "objectID": "chapter12.html",
    "href": "chapter12.html",
    "title": "Chapter 12 - Multistate Modeling of Life History",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter12.html#slides",
    "href": "chapter12.html#slides",
    "title": "Chapter 12 - Multistate Modeling of Life History",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter12.html#base-r-code",
    "href": "chapter12.html#base-r-code",
    "title": "Chapter 12 - Multistate Modeling of Life History",
    "section": "Base R Code",
    "text": "Base R Code\n\n\nShow the code\n##################################################################\n# This code generates all numerical results in chapter 12.      ##\n##################################################################\n\n\n############################################################\n# Table 12.1\n# Multi-state analysis of the GBC Study\n############################################################\n\nlibrary(\"survival\")\n\n # read data\ngbc_ms &lt;- read.table(\"Data//German Breast Cancer Study//gbc_ms.txt\")\n\n# categorize age into three groups\n# &lt;=40, &gt;40 & &lt;=60, &gt;60\ngbc_ms$agec &lt;- (gbc_ms$age&lt;=40) + 2*(gbc_ms$age&gt;40&gbc_ms$age&lt;=60) +\n        3*(gbc_ms$age&gt;60)\n\n# B(t): time spent in current state\ngbc_ms$Bt &lt;- gbc_ms$stop - gbc_ms$start\n\n# change unit to 10 fmol/mg\ngbc_ms$prog &lt;- gbc_ms$prog/10\ngbc_ms$estrg &lt;- gbc_ms$estrg/10\n\n# convert variables to factors\ngbc_ms$hormone &lt;- factor(gbc_ms$hormone)\ngbc_ms$meno &lt;- factor(gbc_ms$meno)\ngbc_ms$agec &lt;- factor(gbc_ms$agec)\n\n###############################\n#Fit the transition models\n#############################\n\n### 0-&gt;1: remission to relapse\nobj01 &lt;- coxph(Surv(start, stop, status) ~ hormone + meno\n                     + agec + size + prog + estrg + strata(grade), data = gbc_ms,\n               subset = ((from==0) & (to == 1)))\n\n### 0-&gt;2: remission to death\nobj02 &lt;- coxph(Surv(start, stop, status) ~ hormone + meno\n            + size + prog + estrg + strata(grade), data = gbc_ms,\n            subset = ((from == 0) & (to == 2)))\n\n### 1-&gt;2: relapse to death\nobj12 &lt;- coxph(Surv(start, stop, status) ~ Bt + hormone + meno\n            + agec + size + prog + estrg + strata(grade), data = gbc_ms,\n            subset = ((from == 1) & (to == 2)))\n\n##########################################\n### Tabulate the results \n##########################################\n\n### 0-&gt;1: remission to relapse\nbeta01 &lt;- obj01$coefficients\nse01 &lt;- sqrt(diag(obj01$var))\np01 &lt;- 1-pchisq((beta01/se01)^2,1)\n\nc1 &lt;- round(exp(beta01),3)\nc2 &lt;- paste0(\"(\",round(exp(beta01-1.96*se01),3),\", \",\n          round(exp(beta01+1.96*se01),3),\")\")\nc3 &lt;- round(p01,3)\n# print out the sub-table\nnoquote(cbind(c1,c2,c3))\n\n\n\n### 0-&gt;2: remission to death\nbeta02 &lt;- obj02$coefficients\nse02 &lt;- sqrt(diag(obj02$var))\np02 &lt;- 1-pchisq((beta02/se02)^2,1)\n\nc1 &lt;- round(exp(beta02),3)\nc2 &lt;- paste0(\"(\",round(exp(beta02-1.96*se02),3),\", \",\n          round(exp(beta02+1.96*se02),3),\")\")\nc3 &lt;- round(p02,3)\n# print out the sub-table\nnoquote(cbind(c1,c2,c3))\n\n\n### 1-&gt;2: relapse to death\nbeta12 &lt;- obj12$coefficients\nse12 &lt;- sqrt(diag(obj12$var))\np12 &lt;- 1-pchisq((beta12/se12)^2,1)\n\nc1 &lt;- round(exp(beta12),3)\nc2 &lt;- paste0(\"(\",round(exp(beta12-1.96*se12),3),\", \",\n          round(exp(beta12+1.96*se12),3),\")\")\nc3 &lt;- round(p12,3)\n# print out the sub-table\nnoquote(cbind(c1,c2,c3))"
  },
  {
    "objectID": "chapter10.html",
    "href": "chapter10.html",
    "title": "Chapter 10 - Competing and Semi-Competing Risks",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter10.html#slides",
    "href": "chapter10.html#slides",
    "title": "Chapter 10 - Competing and Semi-Competing Risks",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter10.html#base-r-code",
    "href": "chapter10.html#base-r-code",
    "title": "Chapter 10 - Competing and Semi-Competing Risks",
    "section": "Base R Code",
    "text": "Base R Code\n\n\nShow the code\n##################################################################\n# This code generates all numerical results in chapter 10.      ##\n##################################################################\n\n\n############################################################\n# Analysis of the Bone Marrow Transplantation Study\n############################################################\n\nlibrary(\"survival\")\n\n# read in the study dataset\ncibmtr &lt;- read.table(\"Data//Bone Marrow Transplantation Study//cibmtr.txt\")\nhead(cibmtr)\n\n#load the cmprsk package\nlibrary(cmprsk)\n\n# Gray's (unweighted) log-rank-type test\nobj &lt;- cuminc(cibmtr$time, cibmtr$status, cibmtr$donor, rho = 0)\n\n# test results\nobj$Tests\n\n# a naive plot: everything in one plot\n# plot(obj)\n\n\n##################################\n# obj$`a k`: kth risk in group a #\n##################################\n\n# Obtain the estimated cumulative incidence functions\n# for kth (k=1, 2) risk in group a (a=1, 0)\n# k=1: relapse; k=2: TRM\nobj.rlp.sib &lt;- obj$`0 1`\nobj.rlp.nonsib &lt;- obj$`1 1`\nobj.trm.sib &lt;- obj$`0 2`\nobj.trm.nonsib &lt;- obj$`1 2`\n\n#############################################\n# Figure 10.2\n# plot the cumulative incidence functions\n##############################################\npar(mfrow=c(1,2))\n\nplot(obj.rlp.sib$time,obj.rlp.sib$est,type='s', frame.plot = F,\n     main=\"Relapse\",xlim=c(0,120),ylim=c(0,0.6),\n     xlab=\"Time (months)\", ylab=\"Cumulative incidence\", lwd=2)\nlines(obj.rlp.nonsib$time,obj.rlp.nonsib$est,lty=3,lwd=2)\n\nplot(obj.trm.sib$time,obj.trm.sib$est,type='s', frame.plot = F,\n     main=\"Treatment-related mortality\",xlim=c(0,120),ylim=c(0,0.6),\n     xlab=\"Time (months)\", ylab=\"Cumulative incidence\", lwd=2)\nlines(obj.trm.nonsib$time,obj.trm.nonsib$est,lty=3,lwd=2)\n\n\n\n###########################\n# Table 10.2              #\n###########################\n\n######################################################\n# Fine-Gray proportional sub-distribution hazard model\n# and cause-specific hazard model\n######################################################\n\n#change k\nk &lt;- 1\n\n#### proportional cause-specific hazards\nobj.cs &lt;- coxph(Surv(time, status == k) ~ cohort + donor + hist + wait,\n                data = cibmtr)\n\n#### Fine and Gray #################\nobj.fg &lt;- crr(cibmtr$time, cibmtr$status, cibmtr[,3:6], failcode = k)\n\n# beta estimates and se's\nbeta.fg &lt;- obj.fg$coef\nse.fg &lt;- sqrt(diag(obj.fg$var))\n\n# construct HR, 95% CI, and p-values\nc1 &lt;- round(exp(beta.fg),2)\nc2 &lt;- paste0(\"(\",round(exp(beta.fg-1.96*se.fg),2),\"-\",round(exp(beta.fg+1.96*se.fg),2),\")\")\nc3 &lt;- round(1-pchisq((beta.fg/se.fg)^2,1),3)\n\n### Cause-specific hazard ############\nobj.csh &lt;- coxph(Surv(time,status==k)~cohort+donor+hist+wait,data=cibmtr)\n\n# beta estimates and se's\nbeta.csh &lt;- obj.csh$coef\nse.csh &lt;- sqrt(diag(obj.csh$var))\n\n# construct HR, 95% CI, and p-values\nc4 &lt;- round(exp(beta.csh),2)\nc5 &lt;- paste0(\"(\",round(exp(beta.csh-1.96*se.csh),2),\"-\",round(exp(beta.csh+1.96*se.csh),2),\")\")\nc6 &lt;- round(1-pchisq((beta.csh/se.csh)^2,1),3)\n\n# print the results\nnoquote(cbind(c1,c2,c3,c4,c5,c6))\n\n#######################################\n## prediction of covariate-specific CIF\n# example \n#######################################\nz &lt;- c(1, 0, 1, 0)\n\n# Method 1\n# --- Method 1: use predict.crr() \nobj_pred1 &lt;- predict(obj.fg, z)\n# --- Method 2: manual calculation\nbeta &lt;- obj.fg$coef\nLambda &lt;- cumsum(obj.fg$bfitj)\ntime &lt;- obj.fg$uftime\n## calculate CIF based on FG model\ncif &lt;- 1- exp(- exp(sum(beta * z)) * Lambda)\n## Same as obj_pred from Method 1\nobj_pred2 &lt;- cbind(time, cif)\n\n## same results\ncbind(obj_pred1, obj_pred2)"
  },
  {
    "objectID": "chap2.html#outline",
    "href": "chap2.html#outline",
    "title": "Applied Survival Analysis",
    "section": "Outline",
    "text": "Outline\n\nRandom variable and counting process notations\nLikelihood and score functions\nMartingale residuals and integrals \\[\\newcommand{\\d}{{\\rm d}}\\] \\[\\newcommand{\\dd}{{\\rm d}}\\] \\[\\newcommand{\\pr}{{\\rm pr}}\\] \\[\\newcommand{\\indep}{\\perp \\!\\!\\! \\perp}\\]"
  },
  {
    "objectID": "chap2.html#outcome-event-notation",
    "href": "chap2.html#outcome-event-notation",
    "title": "Applied Survival Analysis",
    "section": "Outcome Event: Notation",
    "text": "Outcome Event: Notation\n\nTime to outcome event (latent, w.o. censoring): \\(T\\)\n\nCumulative distribution function (cdf): \\(F(t)={\\rm pr}(T\\leq t)\\)\nSurvival function: \\(S(t) = 1- F(t) = {\\rm pr}(T &gt; t)\\)\nDensity function: \\(f(t) = \\d F(t)/\\d t = - \\d S(t)/ \\d t\\)\n\nLeibniz notation\n\n\\(\\d F(t) = f(t)\\d t = \\pr(t \\leq T &lt; t + \\d t)\\): infinitesimal (marginal) event rate (i.e., incidence) over \\([t, t + \\d t)\\)"
  },
  {
    "objectID": "chap2.html#outcome-event-hazard-function",
    "href": "chap2.html#outcome-event-hazard-function",
    "title": "Applied Survival Analysis",
    "section": "Outcome Event: Hazard Function",
    "text": "Outcome Event: Hazard Function\n\nHazard rate: conditional incidence given at risk \\[\\lambda(t)\\dd t=\\pr(t\\leq T&lt;t+\\dd t\\mid T\\geq t)=\\frac{\\dd F(t)}{S(t-)}\\]\n\nSo \\(\\lambda(t) = f(t)/S(t-)\\)\n\nDensity vs hazard functions"
  },
  {
    "objectID": "chap2.html#outcome-event-distributions",
    "href": "chap2.html#outcome-event-distributions",
    "title": "Applied Survival Analysis",
    "section": "Outcome Event: Distributions",
    "text": "Outcome Event: Distributions\n\nRelationship\n\n\\(\\lambda(t)\\d t = - \\d S(t)/S(t -) = -\\d\\log S(t)\\)\n\\(S(t) = \\exp\\{-\\Lambda(t)\\}\\), where \\(\\Lambda(t)=\\int_0^t \\lambda(u)\\d u\\) (cumulative hazard)\n\nExamples\n\nExponential distribution: \\(\\lambda(t)\\equiv \\lambda &gt; 0\\), \\(S(t)=\\exp(-\\lambda t)\\)\n\nConstant risk, also “memoryless”: \\(\\pr(T &gt; t + u\\mid T &gt; t) = \\pr(T &gt; u)\\)\n\nWeibull distribution: \\(\\lambda(t;\\alpha,\\gamma)=\\alpha\\gamma^{-\\alpha} t^{\\alpha-1}\\) with \\(\\gamma, \\alpha&gt;0\\)\n\n\\(0 &lt; \\alpha &lt; 1\\): risk \\(\\downarrow\\) (infant mortality)\n\\(\\alpha &gt; 1\\): risk \\(\\uparrow\\) (aging effect)\n\\(\\alpha = 1\\): Exponential (constant risk)\n\\(\\gamma\\): scale parameter such that \\(E(T)\\propto \\gamma\\)"
  },
  {
    "objectID": "chap2.html#outcome-event-the-weibull",
    "href": "chap2.html#outcome-event-the-weibull",
    "title": "Applied Survival Analysis",
    "section": "Outcome Event: The Weibull",
    "text": "Outcome Event: The Weibull\n\nWeibull\\((\\alpha, \\gamma)\\)"
  },
  {
    "objectID": "chap2.html#outcome-event-counting-process",
    "href": "chap2.html#outcome-event-counting-process",
    "title": "Applied Survival Analysis",
    "section": "Outcome Event: Counting Process",
    "text": "Outcome Event: Counting Process\n\nDefinition\n\n\\(N^*(t)=I(T\\leq t)\\): number of event (0 or 1) by \\(t\\) (cumulative)\n\\(\\d N^*(t)=N^*(t) - N^*(t-) = I (T=t)\\): number of event at \\(t\\) (incident)  \\[E\\{N^*(t)\\} = F(t),\\,\\,\\, E\\{\\d N^*(t)\\} = \\d F(t)\\] \\[E\\{\\d N^*(t)\\mid N^*(t -) = 0\\} = E\\{\\d N^*(t)\\mid T\\geq t\\}=\\d\\Lambda(t)\\]"
  },
  {
    "objectID": "chap2.html#observed-data",
    "href": "chap2.html#observed-data",
    "title": "Applied Survival Analysis",
    "section": "Observed Data",
    "text": "Observed Data\n\nObserved data: \\((X, \\delta)\\)\n\n\\(X = T\\wedge C\\): duration of follow-up (time variable) \\((a\\wedge b = \\min(a, b))\\)\n\\(\\delta = I(T\\leq C)\\): event indicator (status variable)\n\\(C\\): (right) censoring time\n\nObserved counting process\n\n\\(N(t) = I(X\\leq t, \\delta = 1)\\)\nSo \\(\\d N(t) = \\d N^*(t)I(C\\geq t)\\)\n\nIndependent censoring assumption\n\n\\[C\\indep T\\]"
  },
  {
    "objectID": "chap2.html#likelihood-function",
    "href": "chap2.html#likelihood-function",
    "title": "Applied Survival Analysis",
    "section": "Likelihood Function",
    "text": "Likelihood Function\n\nLikelihood on a single subject \\[p(X, \\delta)\\propto f(X)^\\delta S(X)^{1-\\delta}=\\lambda(X)^\\delta S(X)\\]\nLog-likelihood on a random \\(n\\)-sample\n\nUnder a model with parameter \\(\\theta\\): \\(\\lambda(t) = \\lambda(t; \\theta)\\), \\(\\Lambda(t) = \\Lambda(t; \\theta)\\) \\[\\begin{align}\nl_n(\\theta)&= n^{-1}\\sum_{i=1}^n\\log p(X_i, \\delta_i)\\\\\n&=n^{-1}\\sum_{i=1}^n\\left\\{\\delta_i\\log\\lambda(X_i;\\theta) -\\Lambda(X_i;\\theta)\\right\\}\\\\\n&= n^{-1}\\sum_{i=1}^n\\left\\{\\delta_i\\log\\lambda(X_i;\\theta)-\\int_0^\\infty I(X_i\\geq t) \\lambda(t;\\theta)\\dd t\\right\\}\n\\end{align}\\]"
  },
  {
    "objectID": "chap2.html#score-function",
    "href": "chap2.html#score-function",
    "title": "Applied Survival Analysis",
    "section": "Score Function",
    "text": "Score Function\n\nScore function \\[\\frac{\\partial}{\\partial\\theta} l_n(\\theta)=n^{-1}\\sum_{i=1}^n \\left\\{\\delta_ih(X_i;\\theta)-\\int_0^\\infty h(t;\\theta) I(X_i\\geq t)\\lambda(t;\\theta)\\dd t\\right\\}\\]\n\nwhere \\(h(t;\\theta)=\\frac{\\partial}{\\partial\\theta}\\log\\lambda(t;\\theta)\\) (hazard score function)\nSolve \\(\\frac{\\partial}{\\partial\\theta} l_n(\\hat\\theta)=0\\) to obtain maximum likelihood estimator (MLE) \\(\\hat\\theta\\)\n\nExample: exponential distribution \\(\\lambda(t; \\theta) = \\lambda\\)\n\n\\(h(t;\\theta) =\\lambda^{-1}\\)\nClosed-form solution (Newton-Raphson algorithm in general) \\[\\hat\\lambda=\\frac{\\sum_{i=1}^n\\delta_i}{\\sum_{i=1}^n X_i}\\]"
  },
  {
    "objectID": "chap2.html#stochastic-integration",
    "href": "chap2.html#stochastic-integration",
    "title": "Applied Survival Analysis",
    "section": "Stochastic Integration",
    "text": "Stochastic Integration\n\nTransformation of \\(T\\) by some \\(h(\\cdot)\\)\n\n\\(h(T)\\) if \\(T\\) is observed to lie in \\([0, t]\\)\n0 otherwise\nI.e., \\(\\delta I(X\\leq t) h(X)\\)\n\nCompact notation \\[\\delta I(X\\leq t) h(X) = \\int_0^t h(u)\\dd N(u)\\]\n\n\\(\\dd N(u) = 1\\) only if \\(\\delta = 1\\) and \\(T= u\\in[0, t]\\)\n\\(\\dd N(u) \\equiv 0\\) otherwise"
  },
  {
    "objectID": "chap2.html#stochastic-integration-examples",
    "href": "chap2.html#stochastic-integration-examples",
    "title": "Applied Survival Analysis",
    "section": "Stochastic Integration: Examples",
    "text": "Stochastic Integration: Examples\n\nLog-likelihood \\[\nl_n(\\theta)=n^{-1}\\sum_{i=1}^n\\left\\{\\int_0^\\infty \\log\\lambda(t;\\theta)\\dd N_i(t)-\\int_0^\\infty I(X_i\\geq t)\\lambda(t;\\theta)\\dd t\\right\\}\n\\]\n\n\\(N_i(t)= I(X_i\\leq t, \\delta_i =1)\\), i.e., \\(N(t)\\) on subject \\(i\\)\n\nScore (subject-level) \\[\n\\begin{align}\n\\dot l(\\theta)&=\\int_0^\\infty h(t;\\theta)\\dd N(t)-\\int_0^\\infty h(t;\\theta) I(X\\geq t)\\dd\\Lambda(t;\\theta)\\\\\n&=\\int_0^\\infty h(t;\\theta)\\left\\{\\dd N(t)-I(X\\geq t)\\dd\\Lambda(t;\\theta)\\right\\}\n\\end{align}\n\\]"
  },
  {
    "objectID": "chap2.html#martingale-definition",
    "href": "chap2.html#martingale-definition",
    "title": "Applied Survival Analysis",
    "section": "Martingale: Definition",
    "text": "Martingale: Definition\n\nScore re-expression \\[\\dot l(\\theta) = \\int_0^\\infty h(t;\\theta)\\dd M(t;\\ \\theta)\\]\n\n\\(\\dd M(t;\\theta)=\\dd N(t) - I(X\\geq t)\\dd\\Lambda(t;\\theta)\\)\n\nGeneral martingale residual \\[\n\\begin{align}\n  \\dd M(t)&=\\dd N(t) - I(X\\geq t)\\dd\\Lambda(t)\\\\\n      &= \\dd N(t) - E\\{\\dd N(t)\\mid\\mbox{Data prior to }t\\}\n\\end{align}\n\\]\n\nSo \\(E\\{\\dd M(t)\\mid\\mbox{Data prior to }t\\}=0\\)"
  },
  {
    "objectID": "chap2.html#martingale-construction",
    "href": "chap2.html#martingale-construction",
    "title": "Applied Survival Analysis",
    "section": "Martingale: Construction",
    "text": "Martingale: Construction\n\nData observed up to \\(t\\) \\[\n\\mathcal H(t) =\\{N(u), N_C(u):0\\leq u\\leq t\\}\n\\]\n\n\\(N_C(u) = I(X\\leq u, delta = 0)\\): censoring process\n\n\\(\\mathcal H(t-) =\\) Data prior to \\(t\\)\n\nShow \\[E\\{\\dd N(t)\\mid\\mathcal H(t-)\\} = I(X\\geq t)\\dd\\Lambda(t)\\]\n\nHow can the past influence the current incidence (risk)?\nOnly through the at-risk status \\({X\\geq t}\\)"
  },
  {
    "objectID": "chap2.html#martingale-derivation",
    "href": "chap2.html#martingale-derivation",
    "title": "Applied Survival Analysis",
    "section": "Martingale: Derivation",
    "text": "Martingale: Derivation\n\nTwo scenarios: not-at-risk \\((X &lt; t)\\) vs at-risk \\((X\\geq t)\\) \\[\n\\begin{align}\nE\\{\\dd N(t)\\mid\\mathcal H(t-)\\}&=I(X&lt;t)E\\{\\dd N(t)\\mid X&lt;t, \\mathcal H(t-)\\}\\notag\\\\\n&\\hspace{15mm}+I(X\\geq t)E\\{\\dd N(t)\\mid X\\geq t, \\mathcal H(t-)\\}\\notag\\\\\n& = 0 + I(X\\geq t)E\\{\\dd N(t)\\mid X\\geq t\\}\\notag\\\\\n&=I(X\\geq t)\\frac{\\pr\\{\\dd N^*(t)=1, C\\geq t\\}}{\\pr(T\\geq t, C\\geq t)}\n\\notag\\\\\n&=I(X\\geq t)E\\{\\dd N^*(t)\\mid T\\geq t\\}\\notag\\\\\n&=I(X\\geq t)\\dd\\Lambda(t),\n\\end{align}\n\\]\n\nQuestion: why is the 4th equality true?"
  },
  {
    "objectID": "chap2.html#martingale-properties",
    "href": "chap2.html#martingale-properties",
    "title": "Applied Survival Analysis",
    "section": "Martingale: Properties",
    "text": "Martingale: Properties\n\nInterpretation \\[\\underbrace{\\dd M(t)}_{\\mbox{residual}}\n=\\underbrace{\\dd N(t)}_{\\mbox{observed response}} - \\underbrace{I(X\\geq t)\\dd\\Lambda(t)}_{\\mbox{systematic part}}\\]\nConditional mean & variance \\[\nE\\{\\dd M(t)\\mid\\mathcal H(t-)\\}=0,\\,\\,\\,\nE\\{\\dd M(t)^2\\mid\\mathcal H(t-)\\}=I(X\\geq t)\\dd\\Lambda(t)\n\\]\nUncorrelated increments (UCI) (for \\(t&lt;s\\)) \\[\nE\\{\\dd M(t)\\dd M(s)\\}=E\\left[\\dd M(t)E\\{\\dd M(s)\\mid\\mathcal H(s-)\\}\\right]\n=0\n\\]"
  },
  {
    "objectID": "chap2.html#martingale-integral",
    "href": "chap2.html#martingale-integral",
    "title": "Applied Survival Analysis",
    "section": "Martingale Integral",
    "text": "Martingale Integral\n\nCentered statistics take the form \\[\n\\sum_{i=1}^n\\int_0^t h(u)\\dd M_i(u)\n\\]\n\nWeighted sum of the \\(\\dd M_i(u)\\)\n\n\n\n\n\n\n\n\nMean and variance of martingale integral\n\n\n\\[E\\left\\{\\int_0^t h(u)\\dd M(u)\\right\\}=\\int_0^t h(u)E\\left\\{\\dd M(u)\\right\\}=0\\]\n\\[\n\\begin{align}\nE\\left\\{\\int_0^t h(u)\\dd M(u)\\right\\}^2 \\stackrel{\\mbox{UCI}}{=}\\int_0^t h(u)^2E\\left\\{\\dd M(u)^2\\right\\}\n=\\int_0^t h(u)^2\\pr(X\\geq u)\\dd\\Lambda(u)\n\\end{align}\n\\]"
  },
  {
    "objectID": "chap2.html#martingale-integral-example",
    "href": "chap2.html#martingale-integral-example",
    "title": "Applied Survival Analysis",
    "section": "Martingale Integral: Example",
    "text": "Martingale Integral: Example\n\nScore function \\[\n\\dot l(\\theta) = \\int_0^\\infty h(t;\\theta)\\dd M(t; \\theta)\n\\]\n\nInformation \\[\n\\mathcal I(\\theta) = E\\{\\dot l(\\theta)^2\\} =\n\\int_0^\\infty h(t;\\theta)^2\\pr(X\\geq t)\\dd\\Lambda(t;\\theta)\n\\]\n\nExample: exponential distribution \\(h(t;\\theta)=\\lambda^{-1}\\) \\[\n\\mathcal I(\\theta) = \\int_0^\\infty \\lambda^{-2}\\pr(X\\geq t)\\lambda\\dd t=\n\\lambda^{-1}\\int_0^\\infty\\pr(X\\geq t)\\dd t\n\\]\n\nCompare with standard one by taking negative quadrature of log-likelihood"
  },
  {
    "objectID": "chap2.html#notes",
    "href": "chap2.html#notes",
    "title": "Applied Survival Analysis",
    "section": "Notes",
    "text": "Notes\n\nMore parametric families in KP (2002) and KM (2003)\n\n(Inverse) Gamma; Log-normal/logistic; Gompertz; Generalized \\(F\\)\nNotes of textbook\n\nMartingale first introduced in survival analysis by O. O. Aalen (1975, 1978)\n\nSimplifies derivation of statistical properties\nIntegrand \\(h(u)\\) can depend on \\(\\mathcal H(u-)\\)\nLess useful with multivariate outcomes (correlated increments)\n\nCurrent risk depends on past in complex ways"
  },
  {
    "objectID": "chap2.html#summary-i",
    "href": "chap2.html#summary-i",
    "title": "Applied Survival Analysis",
    "section": "Summary (I)",
    "text": "Summary (I)\n\nNotation\n\nOutcome data: \\(T\\)\nObserved data: \\(𝑋=𝑇∧𝐶\\) (time), \\(𝛿=𝐼(𝑇≤𝐶)\\) (status)\nCounting process: \\(𝑁(𝑡)=𝐼(𝑋≤𝑡,𝛿=1)\\)\nCounting process integral \\[\\delta I(X\\leq t) h(X) = \\int_0^t h(u)\\dd N(u)\\]\n\nMartingale residual \\[\\underbrace{\\dd M(t)}_{\\mbox{residual}}\n=\\underbrace{\\dd N(t)}_{\\mbox{observed response}} - \\underbrace{I(X\\geq t)\\dd\\Lambda(t)}_{\\mbox{systematic part}}\\]"
  },
  {
    "objectID": "chap2.html#summary-ii",
    "href": "chap2.html#summary-ii",
    "title": "Applied Survival Analysis",
    "section": "Summary (II)",
    "text": "Summary (II)\n\nMartingale integral (e.g., score function) \\[\n\\int_0^t h(u)\\dd M(u)=\\int_0^t h(u)\\left\\{\\dd N(u)-I(X\\geq u)\\dd\\Lambda(u)\\right\\}\n\\]\n\nMean zero with easily computable variance"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Syllabus",
    "section": "",
    "text": "Overview\nThis course surveys modern statistical methods for analyzing censored time-to-event data in clinical, epidemiological, sociological, and engineering studies. We provide intuitive explanations of statistical theory, such as counting-process martingale, to address real-world problems and build problem-solving skills. The course combines methodological exposition with extensive case studies, primarily from health sciences research (sample R/SAS code will be provided). The focus is on the application of data analysis and study design.\n\n\nCourse Structure\nThe course consists of three parts. The first part covers methods for univariate event times, e.g., Kaplan–Meier curve, log-rank test, and Cox proportional hazards model. The second part extends to complex outcomes such as recurrent events, multivariate events, (semi-)competing risks, joint survival and longitudinal data analysis, multistate data, and composite endpoints. The third part explores cutting-edge topics, including causal inference and machine learning for censored data.\n\n\nLearning Outcomes\nStudents will:\n\nUnderstand the features of censored data and their impact on statistical inference.\nSelect appropriate non- and semi-parametric methods for various data types.\nEvaluate and verify assumptions for estimation and inference.\nApply statistical procedures to solve real-world problems using R (or SAS).\nClearly interpret and present analytical results to address substantive questions.\n\n\n\nPrerequisites\nStudents should have foundational knowledge in random variables, expectation, variance, and maximum likelihood estimation, as well as introductory courses in hypothesis testing (e.g., t-test, ANOVA) and (generalized) linear regression models. Prior experience with R or SAS is helpful but not required.\n\n\nTime and Location\nMW 2:35–3:45pm; Clinical Sciences Center (CSC) - Room G5/119\n\nNote: Classes on 1/27 and 4/28 will be held in HSLC 1220.\n\n\n\nInstructors\n\nMain Instructor\nLu Mao, PhD (https://lmaowisc.github.io)\nWARF 207A, 610 Walnut St, Madison, WI 53726\nEmail: lmao@biostat.wisc.edu\nPhone: 608-263-5674\nOffice Hours: T&Th 3–4pm, or by appointment.\nZoom link provided on Canvas.\n\n\nTeaching Assistant\nYunhong Wu\nEmail: wu292@wisc.edu\nOffice Hours: MW 1-2pm, or by appointment.\nZoom link provided on Canvas.\n\n\n\nReadings\n\n[Required] Applied Survival Analysis: From Univariate to Complex Time-to-Event Outcomes (Posted on Canvas by chapter)\n[For Methodological Insight] Kalbfleisch, J. D. & Prentice, R. L. (2002). The Statistical Analysis of Failure Time Data (2nd Ed). John Wiley & Sons.\n[For Applied Focus] Klein, J. P. & Moeschberger, M. L. (2003). Survival Analysis: Techniques for Censored and Truncated Data (2nd Ed). Springer.\n[For Theoretical Depth] Fleming, T. R. & Harrington, D. P. (1991). Counting Processes and Survival Analysis. John Wiley & Sons.\n\n\n\nCourse Schedule\n\nKickoff\n\n\n\nDate\nTopic\nNotes\n\n\n\n\n1/22\nLecture\nOverview\n\n\n\nReading\nSyllabus\n\n\n\n\n\nPart I: Univariate Events\n\n\n\n\n\n\n\n\nDate\nTopic\nNotes\n\n\n\n\n1/27\nIntroduction\nChapter 1\n\n\n1/29\nMathematical Foundations\nChapter 2\n\n\n2/3\nNonparametric Estimation of the Survival Curve\nChapter 3\n\n\n2/5\nComparing Survival Rates Between Groups\nChapter 3\n\n\n2/10\nCox Proportional Hazards Model – Assumptions and Inference\nChapter 4\n\n\n2/12\nCox Proportional Hazards Model – Residual Analysis\nChapter 4\n\n\n2/17\nCox Proportional Hazards Model – Time-Varying Covariates\nChapter 4\n\n\n2/19\nOther Non- and Semi-parametric Methods\nChapter 5\n\n\n2/24\nStudy Design and Sample Size Calculation\nChapter 6\n\n\n2/26\nLeft Truncation\nChapter 7\n\n\n3/3\nInterval Censoring\nChapter 7\n\n\n\n\n\nPart II: Complex Outcomes\n\n\n\n\n\n\n\n\nDate\nTopic\nNotes\n\n\n\n\n3/5\nMultivariate Events – Conditional (Frailty) Models\nChapter 8\n\n\n3/10\nMultivariate Event Times – Marginal Models\nChapter 8\n\n\n3/12\nRecurrent Events\nChapter 9\n\n\n3/17\nCompeting and Semi-competing Risks\nChapter 10\n\n\n3/31\nJoint Analysis of Longitudinal and Survival Data\nChapter 11\n\n\n4/2\nMultistate Models – Introduction\nChapter 12\n\n\n4/7\nMultistate Models – Cox-Type Markov and Semi-Markov Models\nChapter 12\n\n\n4/9\nComposite Endpoints – Nonparametric Estimation\nChapter 13\n\n\n4/14\nComposite Endpoints – Semiparametric Regression\nChapter 13\n\n\n\n\n\nPart III: Special Topics\n\n\n\n\n\n\n\n\nDate\nTopic\nNotes\n\n\n\n\n4/19\nCausal Inference with Censored Data – IPTW and Standardization\nChapter 14\n\n\n4/21\nCausal Inference with Censored Data – Marginal Structural Models\nChapter 14\n\n\n4/23\nMachine Learning with Censored Data – Variable Selection\nChapter 15\n\n\n4/28\nMachine Learning with Censored Data – Nonlinear Regression\nChapter 15\n\n\n4/30\nGuest Lecture or recap\n\n\n\n\n\n\n\nHomework and Exams\n\nHomework: Biweekly.\nIn-class: quizzes\nMid-term project.\nFinal data analysis project.\n\n\n\nGrading\n\n20% Attendance and in-class quizzes\n\n35% Homework\n\n20% Mid-term\n\n25% Final project"
  },
  {
    "objectID": "chap1.html#outline",
    "href": "chap1.html#outline",
    "title": "Applied Survival Analysis",
    "section": "Outline",
    "text": "Outline\n\nTime-to-event data and examples\nCensoring mechanisms and implications\nSummarizing the raw data\n\n\\[\\newcommand{\\indep}{\\perp \\!\\!\\! \\perp}\\]"
  },
  {
    "objectID": "chap1.html#what-are-time-to-event-data",
    "href": "chap1.html#what-are-time-to-event-data",
    "title": "Applied Survival Analysis",
    "section": "What are time-to-event data?",
    "text": "What are time-to-event data?\n\nCommon outcome type in medical studies\n\nStarting point: Randomization, study entry, birth, etc.\nEndpoint: Death, hospitalization, disease onset, etc.\nIn engineering: Machine failure times (reliability analysis)\n\nRight censoring\n\nEvent does not occur by study end or dropout\n\nOnly know event time \\(&gt;\\) censoring time\n\nSurvival analysis: Statistical methods for censored data"
  },
  {
    "objectID": "chap1.html#example-univariate-event-i",
    "href": "chap1.html#example-univariate-event-i",
    "title": "Applied Survival Analysis",
    "section": "Example: Univariate event (I)",
    "text": "Example: Univariate event (I)\n\nGerman Breast Cancer (GBC) Study\n\nPopulation: 686 patients with node-positive breast cancer\n\nObjective: Assess if tamoxifen + chemo reduces mortality\n\nBaseline info: Age, tumor size, hormone levels, menopausal status, etc.\n\nFollow-up: Median 44 months\n\n171 deaths \\(\\to\\) exact times known\n\n515 censored \\(\\to\\) survival time \\(&gt;\\) censoring time"
  },
  {
    "objectID": "chap1.html#example-univariate-event-ii",
    "href": "chap1.html#example-univariate-event-ii",
    "title": "Applied Survival Analysis",
    "section": "Example: Univariate event (II)",
    "text": "Example: Univariate event (II)\n\nGerman Breast Cancer (GBC) Study"
  },
  {
    "objectID": "chap1.html#example-recurrent-events-i",
    "href": "chap1.html#example-recurrent-events-i",
    "title": "Applied Survival Analysis",
    "section": "Example: Recurrent events (I)",
    "text": "Example: Recurrent events (I)\n\nChronic Granulomatous Disease (CGD) Study\n\nPopulation: 128 patients in a randomized placebo-controlled trial\n\nObjective: Assess gamma interferon effect on recurrent infections\n\nFollow-up: Median 293 days\n\nInfections: Min = 0, Max = 7\n\n\nChallenge: Correlated events within individuals\nData in “long” format (multiple records per patient)"
  },
  {
    "objectID": "chap1.html#example-recurrent-events-ii",
    "href": "chap1.html#example-recurrent-events-ii",
    "title": "Applied Survival Analysis",
    "section": "Example: Recurrent events (II)",
    "text": "Example: Recurrent events (II)\n\nChronic Granulomatous Disease (CGD) Study"
  },
  {
    "objectID": "chap1.html#example-multivariateclustered-events-i",
    "href": "chap1.html#example-multivariateclustered-events-i",
    "title": "Applied Survival Analysis",
    "section": "Example: Multivariate/Clustered Events (I)",
    "text": "Example: Multivariate/Clustered Events (I)\n\nDiabetic Retinopathy Study\n\nPopulation: 197 high-risk diabetic patients in a randomized controlled trial\nObjective: Determine if photocoagulation (a laser treatment) delays blindness onset\nDesign: One eye treated (by either xenon or argon), the other untreated (control)\nChallenge: Correlation between eyes"
  },
  {
    "objectID": "chap1.html#example-multivariateclustered-events-ii",
    "href": "chap1.html#example-multivariateclustered-events-ii",
    "title": "Applied Survival Analysis",
    "section": "Example: Multivariate/Clustered Events (II)",
    "text": "Example: Multivariate/Clustered Events (II)\n\nDiabetic Retinopathy Study"
  },
  {
    "objectID": "chap1.html#example-competing-risks-i",
    "href": "chap1.html#example-competing-risks-i",
    "title": "Applied Survival Analysis",
    "section": "Example: Competing Risks (I)",
    "text": "Example: Competing Risks (I)\n\nDefinition: Multiple types of events where one prevents the occurrence of the others\n\nNatural example: different causes of death\n\nCompeting risk vs censoring:\n\nBoth terminate follow-up\nCompeting risk: part of the outcome; inference based on its presence\nCensoring: irrelevant to outcome; inference based on its absence\n\nExample: death from prostate cancer as main outcome\n\nDeath from other (metastasized) cancers \\(\\to\\) competing risk\nDeath from traffic accidents \\(\\to\\) censoring"
  },
  {
    "objectID": "chap1.html#example-competing-risks-ii",
    "href": "chap1.html#example-competing-risks-ii",
    "title": "Applied Survival Analysis",
    "section": "Example: Competing Risks (II)",
    "text": "Example: Competing Risks (II)\n\nBone Marrow Transplant Study\n\npopulation: 864 multiple-myeloma leukemia patients undergoing allogeneic haematopoietic cell transplantation (HCT)\nObjective: Evaluate risk factors for treatment-related mortality (TRM) and relapse of leukemia\nCompeting risks: TRM defined as death in remission (i.e., before relapse); thus is precluded by relapse\nRisk factors: cohort indicator (years 1995–2000 or 2001–2005), type of donor (unrelated or identical sibling), history of a prior transplant, time from diagnosis to transplantation (&lt;24 months, or ≥ 24 months)"
  },
  {
    "objectID": "chap1.html#example-competing-risks-iii",
    "href": "chap1.html#example-competing-risks-iii",
    "title": "Applied Survival Analysis",
    "section": "Example: Competing Risks (III)",
    "text": "Example: Competing Risks (III)\n\nBone Marrow Transplant Study\n\nWhy only one record per patient?"
  },
  {
    "objectID": "chap1.html#example-more-complex-outcomes-semi-competing-risks",
    "href": "chap1.html#example-more-complex-outcomes-semi-competing-risks",
    "title": "Applied Survival Analysis",
    "section": "Example: More Complex Outcomes (Semi-competing risks)",
    "text": "Example: More Complex Outcomes (Semi-competing risks)\n\nGerman Breast Cancer (GBC) Study\n\nNonfatal event + terminal event (death)"
  },
  {
    "objectID": "chap1.html#example-more-complex-outcomes-with-longitudinal-data",
    "href": "chap1.html#example-more-complex-outcomes-with-longitudinal-data",
    "title": "Applied Survival Analysis",
    "section": "Example: More Complex Outcomes (with Longitudinal data)",
    "text": "Example: More Complex Outcomes (with Longitudinal data)\n\nAnti-Retroviral Drug Trial\n\nRepeated measures of CD4 cell count + death"
  },
  {
    "objectID": "chap1.html#example-more-complex-outcomes-multistate-process",
    "href": "chap1.html#example-more-complex-outcomes-multistate-process",
    "title": "Applied Survival Analysis",
    "section": "Example: More Complex Outcomes (Multistate process)",
    "text": "Example: More Complex Outcomes (Multistate process)\n\nBreast Cancer Life History Study\n\nRemission \\(\\to\\) relapse \\(\\to\\) metastasis \\(\\to\\) death (can skip states)"
  },
  {
    "objectID": "chap1.html#example-composite-endpointsi",
    "href": "chap1.html#example-composite-endpointsi",
    "title": "Applied Survival Analysis",
    "section": "Example: Composite Endpoints(I)",
    "text": "Example: Composite Endpoints(I)\n\nComposite endpoint: one with multiple components\n\nRecurrent/multivariate events\n(Semi-)Competing risks\nLongitudinal measurements\nMultistate processes\n\nAnalysis of complex outcomes\n\nMarginal approach: models components separately\nConditional approach: models components jointly\nComposite approach: combines components\n\nProgression/relapse-free survival (time to the earlier of progression/relapse or death)"
  },
  {
    "objectID": "chap1.html#example-composite-endpointsii",
    "href": "chap1.html#example-composite-endpointsii",
    "title": "Applied Survival Analysis",
    "section": "Example: Composite Endpoints(II)",
    "text": "Example: Composite Endpoints(II)\n\nAdvantages:\n\nConcentrates information \\(\\to\\) Statistical efficiency\nNo need for multiple testing adjustment\nA single measure of overall effect size\n\nPreferred for primary analysis of Phase-III clinical trials by\n\nUS Food and Drug Administration (FDA)\nICH (International Council for Harmonisation for pharmaceuticals)\n\nChallenges:\n\nStatistical efficiency (e.g., beyond first event)\nScientific relevance (e.g., relative importance of components)"
  },
  {
    "objectID": "chap1.html#censoring-mechanisms",
    "href": "chap1.html#censoring-mechanisms",
    "title": "Applied Survival Analysis",
    "section": "Censoring Mechanisms",
    "text": "Censoring Mechanisms\n\nTwo mechanisms\n\nStudy termination (administrative censoring)\nLoss to follow-up (LTFU, e.g., withdrawal, death from other causes)\n\n\n\n\n\n\n\n\nCaution about censoring\n\n\n\nEvent/censoring time \\(=\\) time from starting point (e.g., randomization) to event/censoring (as opposed to time on the calendar)\nLTFU may not be independent of outcome (e.g., sicker patients withdraw early)\nCollect withdrawal reasons if possible\nCensoring or competing risk? \\(\\leftarrow\\) Domain knowledge"
  },
  {
    "objectID": "chap1.html#censoring-mechanisms-illustration",
    "href": "chap1.html#censoring-mechanisms-illustration",
    "title": "Applied Survival Analysis",
    "section": "Censoring Mechanisms: Illustration",
    "text": "Censoring Mechanisms: Illustration\n\nCalendar time vs time synchronized by starting point"
  },
  {
    "objectID": "chap1.html#statistical-implications-i",
    "href": "chap1.html#statistical-implications-i",
    "title": "Applied Survival Analysis",
    "section": "Statistical Implications (I)",
    "text": "Statistical Implications (I)\n\nCensored observation\n\nNot completely missing!\nPartial information: event time \\(&gt;\\) censoring time\nIgnoring partial information \\(\\to\\) Bias in inference\n\nNaive approaches\n\nTreat censoring as event \\(\\to\\) Underestimates time to event\nExclude censored observations \\(\\to\\) Underestimates time to event (longer event times more likely censored)"
  },
  {
    "objectID": "chap1.html#statistical-implications-ii",
    "href": "chap1.html#statistical-implications-ii",
    "title": "Applied Survival Analysis",
    "section": "Statistical Implications (II)",
    "text": "Statistical Implications (II)\n\nNotation\n\n\\(T\\): Outcome event time\n\\(C\\): Censoring time\nObserved data: \\(X=\\min(T, C)\\), \\(\\delta = I(T\\leq C)\\)\n\n(𝑋, 𝛿) = (time, status) in previous data examples\n\n\nEstimation\n\nIndependent censoring assumption\n\n\\[ C \\indep T\\]\n\nEstimand: \\(S(t)={\\rm pr}(T &gt; t)\\), i.e., probability of subject “surviving” to time \\(t\\), using a random sample of \\((X_i, \\delta_i)\\) \\((i=1,\\ldots, n)\\)"
  },
  {
    "objectID": "chap1.html#statistical-implications-iii",
    "href": "chap1.html#statistical-implications-iii",
    "title": "Applied Survival Analysis",
    "section": "Statistical Implications (III)",
    "text": "Statistical Implications (III)\n\nNaive methods\n\nEvent-imputation empirical survival function: \\[\\hat S_{\\rm imp}(t)=n^{-1}\\sum_{i=1}^n I(X_i &gt; t) \\to {\\rm pr}(X &gt; t)\\leq S(t)\\]\nComplete-case empirical survival function: \\[\\hat S_{\\rm cc}(t)=\\frac{\\sum_{i=1}^n I(X_i &gt; t, \\delta_i = 1)}{\\sum_{i=1}^n\\delta_i}\n  \\to {\\rm pr}(T &gt; t\\mid T\\leq C)\\leq S(t)\\]\nBoth naïve methods underestimate the true survival function"
  },
  {
    "objectID": "chap1.html#statistical-implications-example",
    "href": "chap1.html#statistical-implications-example",
    "title": "Applied Survival Analysis",
    "section": "Statistical Implications: Example",
    "text": "Statistical Implications: Example\n\nGerman Breast Cancer (GBC) Study"
  },
  {
    "objectID": "chap1.html#importance-of-descriptive-analysis",
    "href": "chap1.html#importance-of-descriptive-analysis",
    "title": "Applied Survival Analysis",
    "section": "Importance of Descriptive Analysis",
    "text": "Importance of Descriptive Analysis\n\nStatistical models rely more or less on assumptions\nGood practice to summarize data descriptively as first step\n\nGet to know the data\nInforms subsequent analysis\nCheck balance of baseline characteristics between randomized arms\n“Table 1” in medical research papers\n\nTwo types of summary statistics\n\nSubject-level characteristics (baseline variables, number of events per subject)\nEvent rates (over aggregate length of follow-up)"
  },
  {
    "objectID": "chap1.html#how-to-calculate-event-rate-i",
    "href": "chap1.html#how-to-calculate-event-rate-i",
    "title": "Applied Survival Analysis",
    "section": "How to Calculate Event Rate (I)",
    "text": "How to Calculate Event Rate (I)\n\nLength of follow-up is event-specific\n\nIf an event is “non-recurrent”, its occurrence means patient is no longer at risk for it\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nDenominator is called person-year (or person-time) of follow-up."
  },
  {
    "objectID": "chap1.html#how-to-calculate-event-rate-ii",
    "href": "chap1.html#how-to-calculate-event-rate-ii",
    "title": "Applied Survival Analysis",
    "section": "How to Calculate Event Rate (II)",
    "text": "How to Calculate Event Rate (II)\n\nSemi-competing risks"
  },
  {
    "objectID": "chap1.html#how-to-calculate-event-rate-iii",
    "href": "chap1.html#how-to-calculate-event-rate-iii",
    "title": "Applied Survival Analysis",
    "section": "How to Calculate Event Rate (III)",
    "text": "How to Calculate Event Rate (III)\n\nRecurrent events"
  },
  {
    "objectID": "chap1.html#table-one-example",
    "href": "chap1.html#table-one-example",
    "title": "Applied Survival Analysis",
    "section": "Table One: Example",
    "text": "Table One: Example"
  },
  {
    "objectID": "chap1.html#chapter-summary",
    "href": "chap1.html#chapter-summary",
    "title": "Applied Survival Analysis",
    "section": "Chapter Summary",
    "text": "Chapter Summary\n\nTypes of time-to-event outcomes\n\nUnivariate, recurrent, multivariate/clustered, (semi-)competing risks, repeated measures, multistate processes, and everything in between…\n\nCommon feature: censoring\n\nArises if study ends or patient drops out prior to event\nMust be handled with care to avoid false conclusion\n\nImportance of descriptive analysis\n\nEvent rate \\(\\to\\) attention to denominator"
  },
  {
    "objectID": "chap1.html#hw1-due-feb-5",
    "href": "chap1.html#hw1-due-feb-5",
    "title": "Applied Survival Analysis",
    "section": "HW1 (Due Feb 5)",
    "text": "HW1 (Due Feb 5)\n\nChoose one\n\nProblem 1.1 (Recommended for PhD in Stats/BDS)\nProblem 1.2\n\nProblem 1.8 (Attach you annotated code)\n(Extra credit) Problem 1.3"
  },
  {
    "objectID": "chap1.html#guidelines-for-hw",
    "href": "chap1.html#guidelines-for-hw",
    "title": "Applied Survival Analysis",
    "section": "Guidelines for HW",
    "text": "Guidelines for HW\n\nPresent a readable and coherent text to report your methods and results\n\nInclude numerical/graphical results only if they contribute to your narrative\nAll tables and figures should be properly titled/captioned, with informative labels/legends\nUse full names instead of abbreviations/acronyms\n\nE.g., “meno” \\(\\to\\) “Menopause (yes v no)”; “est” \\(\\to\\) “Estrogen (fmol/mg)”\n\nSpecify the unit of variable, e.g., “Age (years)”\nSee Table 1.11 and Fig. 1.2 for examples\n\nAppend the full code for diagnostic purposes"
  },
  {
    "objectID": "chapter1.html",
    "href": "chapter1.html",
    "title": "Chapter 1 - Introduction",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)",
    "crumbs": [
      "Home",
      "Part I - Univariate Events",
      "Chapter 1 - Introduction"
    ]
  },
  {
    "objectID": "chapter1.html#slides",
    "href": "chapter1.html#slides",
    "title": "Chapter 1 - Introduction",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)",
    "crumbs": [
      "Home",
      "Part I - Univariate Events",
      "Chapter 1 - Introduction"
    ]
  },
  {
    "objectID": "chapter1.html#chapter-summary",
    "href": "chapter1.html#chapter-summary",
    "title": "Chapter 1 - Introduction",
    "section": "Chapter Summary",
    "text": "Chapter Summary\nTime-to-event (or survival) data are collected by following subjects from a clearly defined starting point until a particular event occurs or until they are censored. The latter occurs when the subject does not experience the event by the time the study ends or they withdraw, leaving the exact event time unknown. Properly integrating the partial information contained in censored observations—rather than discarding or misclassifying them—is essential to avoid systematic bias.\n\nReal examples\nNumerous real studies illustrate the complexity of time-to-event data. In some settings, a single (univariate) endpoint—such as death—drives the analysis, as in the German Breast Cancer (GBC) Study. In others, such as the Chronic Granulomatous Disease (CGD) Study, individuals can experience recurrent events (e.g., repeated infections), leading to correlated outcomes within each subject. Meanwhile, the Diabetic Retinopathy Study (DRS) exemplifies a scenario where each subject has more than one at-risk unit (two eyes), so the events of interest (vision loss) are clustered within the same person. Still other investigations involve competing risks, as with bone marrow transplant patients whose relapse and treatment-related mortality exclude each other, or semi-competing risks, where a nonfatal event can occur only before death. Some studies collect longitudinal biomarkers (e.g., serial CD4 measurements) in conjunction with survival outcomes, and many modern trials unify multiple event types into a composite endpoint, providing a holistic view of patient experience.\n\n\nImplications of censoring\nUnderneath these variations, censoring remains the main factor complicating statistical inference. When subjects drop out early or when the study reaches its planned end date, the only information gained is that a subject’s event time exceeds the last observation time. A naive approach—such as imputing the event time at the censoring point or discarding censored subjects—typically lead to bias, as longer-living or later-failing subjects are censored more often. To address this bias, many standard methods (e.g., Kaplan–Meier, Cox regression) assume independent censoring. If this assumption does not hold and censoring depends on unobserved factors linked to the event, more advanced techniques or sensitivity analyses become necessary.\n\n\nDescriptive analysis\nA thorough descriptive analysis of the data is recommended before applying any model-based approach. This generally includes an initial “Table 1” that compares baseline characteristics (such as age, sex, tumor size, or hormone status) across treatment or exposure groups, ensuring any key differences or imbalances are made explicit. It may also involve calculating event rates—defined as total events divided by total person-time at risk. Care must be taken to distinguish between overall follow-up (lasting until a terminal event or the study’s end) and event-specific follow-up (which may end sooner if the event of interest has occurred). Aligning the numerator (events) with the relevant denominator (time at risk) ensures clarity and consistency in summarizing outcomes.\n\n\nConclusion\nThese fundamental ideas—awareness of different event structures, accurate handling of censoring, and proper descriptive summaries—form the bedrock upon which future methods will build.",
    "crumbs": [
      "Home",
      "Part I - Univariate Events",
      "Chapter 1 - Introduction"
    ]
  },
  {
    "objectID": "chapter1.html#base-r-code",
    "href": "chapter1.html#base-r-code",
    "title": "Chapter 1 - Introduction",
    "section": "Base R Code",
    "text": "Base R Code\n\n\nShow the code\n###############################################################################\n# Chapter 1 R Code: Figure 1.2 and Table 1.12\n# \n# This script generates:\n#  1. Figure 1.2: Demonstration of proper (Kaplan–Meier) vs. \n#     improper (event-imputation, complete-case) survival estimates.\n#  2. Table 1.12: Baseline characteristics for the German Breast Cancer (GBC) study.\n#\n# It also computes event rates (death, composite event) for each hormone group.\n###############################################################################\n\n# -------------------------------------------------------\n# 0. Preparations\n# -------------------------------------------------------\n\n# (a) Load required packages\nlibrary(survival)\n\n# -------------------------------------------------------\n# 1. Read in the German Breast Cancer (GBC) mortality data\n# -------------------------------------------------------\n\ngbc_mort &lt;- read.table(\"Data/German Breast Cancer Study/gbc_mort.txt\", header = TRUE)\nhead(gbc_mort)\n\n# The data frame 'gbc_mort' contains:\n#  time:   time (months) to death or censoring\n#  status: event indicator (1 = death, 0 = censoring)\n#  hormone: hormone therapy group (1 = no hormone, 2 = hormone)\n#  age, meno, size, grade, nodes, prog, estrg (baseline characteristics)\n\n# -------------------------------------------------------\n# 2. Kaplan–Meier Estimates (Proper) vs. Naive Methods\n# -------------------------------------------------------\n\n# (a) Subset by hormone group\ngbc_mort_1 &lt;- subset(gbc_mort, hormone == 1)  # no hormone\ngbc_mort_2 &lt;- subset(gbc_mort, hormone == 2)  # hormone\n\n# (b) Fit group-specific Kaplan–Meier curves\nKMfit1 &lt;- survfit(Surv(time, status) ~ 1, data = gbc_mort_1)\nKMfit2 &lt;- survfit(Surv(time, status) ~ 1, data = gbc_mort_2)\n\n# (c) Define a function to calculate an \"empirical\" survival curve \n#     by treating all observations in x as if they were complete (event-imputation).\nemp.surv &lt;- function(x) {\n  n  &lt;- length(x)\n  tU &lt;- sort(unique(x))\n  m  &lt;- length(tU)\n  S  &lt;- numeric(m)\n  for (i in seq_len(m)) {\n    S[i] &lt;- sum(x &gt; tU[i]) / n\n  }\n  list(t = tU, S = S)\n}\n\n# (d) Event-imputation survival curves\nobj1_imp &lt;- emp.surv(gbc_mort_1$time)\nobj2_imp &lt;- emp.surv(gbc_mort_2$time)\n\n# (e) Complete-case survival curves (ignores censored data)\nobj1_cc &lt;- emp.surv(gbc_mort_1$time[gbc_mort_1$status == 1])\nobj2_cc &lt;- emp.surv(gbc_mort_2$time[gbc_mort_2$status == 1])\n\n# (f) Plot KM (solid), event-imputed (dashed), and complete-case (dotted) curves\npar(mfrow = c(1, 2))\n\n# No Hormone group\nplot(KMfit1, conf.int = FALSE, xlab = \"Time (months)\", ylab = \"Survival Rate\",\n     main = \"No Hormone\", lwd = 2, cex.axis = 1.5, cex.lab = 1.5, cex.main = 1.5)\nlines(obj1_imp$t, obj1_imp$S, lty = 2, lwd = 2)\nlines(obj1_cc$t, obj1_cc$S, lty = 3, lwd = 2)\n\n# Hormone group\nplot(KMfit2, conf.int = FALSE, xlab = \"Time (months)\", ylab = \"Survival Rate\",\n     main = \"Hormone\", lwd = 2, cex.axis = 1.5, cex.lab = 1.5, cex.main = 1.5)\nlines(obj2_imp$t, obj2_imp$S, lty = 2, lwd = 2)\nlines(obj2_cc$t, obj2_cc$S, lty = 3, lwd = 2)\n\n# --------------------------------------------------------\n# 3. Table 1.12: Baseline Characteristics by Hormone Group\n# --------------------------------------------------------\n\n# (a) Define helper functions for summarizing quantitative and categorical variables\n\n# This function calculates median (IQR) for a quantitative variable by a binary group\nMean.IQR.by.trt &lt;- function(y, trt, decp = 1) {\n  groups &lt;- sort(unique(trt))\n  overall_q &lt;- quantile(y, probs = c(0.25, 0.5, 0.75))\n  g1_q &lt;- quantile(y[trt == groups[1]], probs = c(0.25, 0.5, 0.75))\n  g2_q &lt;- quantile(y[trt == groups[2]], probs = c(0.25, 0.5, 0.75))\n  \n  out &lt;- matrix(NA, nrow = 1, ncol = 3)\n  colnames(out) &lt;- c(groups, \"Overall\")\n  \n  out[1, 1] &lt;- paste0(round(g1_q[2], decp), \" (\", \n                      round(g1_q[1], decp), \", \", \n                      round(g1_q[3], decp), \")\")\n  out[1, 2] &lt;- paste0(round(g2_q[2], decp), \" (\", \n                      round(g2_q[1], decp), \", \", \n                      round(g2_q[3], decp), \")\")\n  out[1, 3] &lt;- paste0(round(overall_q[2], decp), \" (\",\n                      round(overall_q[1], decp), \", \",\n                      round(overall_q[3], decp), \")\")\n  \n  out\n}\n\n# This function calculates N (%) for each level of a categorical variable by a binary group\nN.prct.by.trt &lt;- function(x, trt, decp = 1) {\n  groups &lt;- sort(unique(trt))\n  x_levels &lt;- sort(unique(x))\n  p &lt;- length(x_levels)\n  \n  n_total &lt;- length(x)\n  n1 &lt;- sum(trt == groups[1])\n  n2 &lt;- sum(trt == groups[2])\n  \n  out &lt;- matrix(NA, nrow = p, ncol = 3)\n  colnames(out) &lt;- c(groups, \"Overall\")\n  rownames(out) &lt;- x_levels\n  \n  for (i in seq_len(p)) {\n    n1i &lt;- sum(x[trt == groups[1]] == x_levels[i])\n    n2i &lt;- sum(x[trt == groups[2]] == x_levels[i])\n    ni  &lt;- sum(x == x_levels[i])\n    \n    out[i, 1] &lt;- paste0(n1i, \" (\", round(n1i / n1 * 100, decp), \"%)\")\n    out[i, 2] &lt;- paste0(n2i, \" (\", round(n2i / n2 * 100, decp), \"%)\")\n    out[i, 3] &lt;- paste0(ni, \" (\", round(ni / n_total * 100, decp), \"%)\")\n  }\n  \n  out\n}\n\n# (b) Generate the summary table\ntable1_data &lt;- rbind(\n  Mean.IQR.by.trt(y = gbc_mort$age,   trt = gbc_mort$hormone),\n  N.prct.by.trt(x = gbc_mort$meno,   trt = gbc_mort$hormone),\n  Mean.IQR.by.trt(y = gbc_mort$size,  trt = gbc_mort$hormone),\n  N.prct.by.trt(x = gbc_mort$grade,  trt = gbc_mort$hormone),\n  Mean.IQR.by.trt(y = gbc_mort$nodes, trt = gbc_mort$hormone),\n  Mean.IQR.by.trt(y = gbc_mort$prog,  trt = gbc_mort$hormone),\n  Mean.IQR.by.trt(y = gbc_mort$estrg, trt = gbc_mort$hormone)\n)\n\ncat(\"\\n=== Table 1.12: Baseline Characteristics by Hormone Group ===\\n\")\nprint(noquote(table1_data))\n\n# -------------------------------------------------------\n# 4. Calculate Event Rates (Death, Composite Endpoint)\n# -------------------------------------------------------\n\n## 4a. Death Rate\n# Numerator: total # of deaths\nnum_D &lt;- c(\n  sum(gbc_mort$status[gbc_mort$hormone == 1]),\n  sum(gbc_mort$status[gbc_mort$hormone == 2]),\n  sum(gbc_mort$status)\n)\n\n# Denominator: total length of follow-up (in years)\ndenom_D &lt;- c(\n  sum(gbc_mort$time[gbc_mort$hormone == 1]),\n  sum(gbc_mort$time[gbc_mort$hormone == 2]),\n  sum(gbc_mort$time)\n) / 12\n\n# Death rate (per year)\ndeath_rate &lt;- round(num_D / denom_D, 3)\ncat(\"\\nDeath rate (per year) by hormone group:\\n\")\nnames(death_rate) &lt;- c(\"Hormone=1\", \"Hormone=2\", \"Overall\")\nprint(death_rate)\n\n## 4b. Composite Endpoint Rate\n# The composite endpoint data file \"gbc.txt\" includes additional info \n#  on relapse. We only take the first event (relapse or death).\ngbc &lt;- read.table(\"Data/German Breast Cancer Study/gbc.txt\", header = TRUE)\n\n# Sort data by (id, time) and pick the first row per patient\ngbc &lt;- gbc[order(gbc$id, gbc$time), ]\nfirst_event &lt;- gbc[!duplicated(gbc$id), ]  # each patient's first observed record\n\n# Numerator: total # of composite events (status &gt; 0)\nnum_CE &lt;- c(\n  sum(first_event$status[first_event$hormone == 1] &gt; 0),\n  sum(first_event$status[first_event$hormone == 2] &gt; 0),\n  sum(first_event$status &gt; 0)\n)\n\n# Denominator: total length of follow-up (in years)\ndenom_CE &lt;- c(\n  sum(first_event$time[first_event$hormone == 1]),\n  sum(first_event$time[first_event$hormone == 2]),\n  sum(first_event$time)\n) / 12\n\n# Composite event rate (per year)\nCE_rate &lt;- round(num_CE / denom_CE, 3)\ncat(\"\\nComposite event rate (per year) by hormone group:\\n\")\nnames(CE_rate) &lt;- c(\"Hormone=1\", \"Hormone=2\", \"Overall\")\nprint(CE_rate)\n\ncat(\"\\n=== End of Chapter 1 Code ===\\n\")",
    "crumbs": [
      "Home",
      "Part I - Univariate Events",
      "Chapter 1 - Introduction"
    ]
  },
  {
    "objectID": "chapter1.html#tidyverse-solutions",
    "href": "chapter1.html#tidyverse-solutions",
    "title": "Chapter 1 - Introduction",
    "section": "Tidyverse Solutions",
    "text": "Tidyverse Solutions\nFirst load the required packages:\n\n# Load required libraries\nlibrary(tidyverse)\nlibrary(survival)\nlibrary(knitr) # For formatted tables\n\n\nParsing censored data\nInstead of (time, status), sometimes the observed data are stored in a single column with censored observations indicated with a “+” or “&gt;” sign.\nFor example, Table 1.1 of Klein and Moeschberger (2003) lists the times (in months) to relapse of leukemia in the treatment group (6-MP):\n\nMP &lt;- c(10, 7, \"32+\", 23, 22, 6, 16, \"34+\", \"32+\", \"25+\", \"11+\", \"20+\", \n        \"19+\", 6, \"17+\", \"35+\", 6, 13, \"9+\", \"6+\", \"10+\")\n\nTo convert the character strings to (time, status), use parse_number() to parse out the number and str_detect() to detect whether the string contains “+”:\n\n# Example data: relapse times with \"+\" indicating censoring\nMP &lt;- c(10, 7, \"32+\", 23, 22, 6, 16, \"34+\", \"32+\", \"25+\", \n        \"11+\", \"20+\", \"19+\", 6, \"17+\", \"35+\", 6, 13, \"9+\", \n        \"6+\", \"10+\")\n\n# Convert to (time, status) format\ndf &lt;- tibble(\n  MP = MP,\n  time = parse_number(MP),               # Extract numeric part\n  status = 1 - str_detect(MP, \"\\\\+\")    # Censored if \"+\" detected\n)\n\n# Display the parsed data\ndf\n\n# A tibble: 21 × 3\n#    MP     time status\n#    &lt;chr&gt; &lt;dbl&gt;  &lt;dbl&gt;\n#  1 10       10      1\n#  2 7         7      1\n#  3 32+      32      0\n#  4 23       23      1\n#  5 22       22      1\n#  6 6         6      1\n#  7 16       16      1\n#  8 34+      34      0\n#  9 32+      32      0\n# 10 25+      25      0\n# ℹ 11 more rows\n# ℹ Use `print(n = ...)` to see more rows\n\nNow feed this dataset into survfit() to estimate survival probabilities:\n\n# Kaplan-Meier fit\nkm &lt;- survfit(Surv(time, status) ~ 1, data = df)\n\n# Plot the survival curve\nplot(\n  km,\n  main = \"Relapse of Leukemia in 6-MP Group\",\n  xlab = \"Time (months)\",\n  ylab = \"Relapse-free probabilities\",\n  conf.int = FALSE,\n  frame = FALSE\n)\n\n\n\n\n\n\n\n\n\n\nFacet plotting Fig. 1.2\nHere, we use survival data from the German Breast Cancer Study (GBC). Adjust the file path as needed.\n\n# Read in the GBC mortality data\ndata &lt;- read.table(\"Data//German Breast Cancer Study//gbc_mort.txt\")\n\n# Display the first few rows\nhead(data)\n#   id      time status hormone age meno size grade nodes prog estrg\n# 1  1 74.819672      0       1  38    1   18     3     5  141   105\n# 2  2 65.770492      0       1  52    1   20     1     1   78    14\n# 3  3 47.737705      1       1  47    1   30     2     1  422    89\n# 4  4  4.852459      0       1  40    1   24     1     3   25    11\n# 5  5 61.081967      0       2  64    2   19     2     1   19     9\n# 6  6 63.377049      0       2  49    2   56     1     3  356    64\n\nThen compute the different estimates within each level of hormone. Do this by using group_by(hormone) and performing the calculations within reframe(). But first we use survfit() to get the Kaplan–Meier estimates:\n\n# Kaplan-Meier estimates\nobj &lt;- summary(survfit(Surv(time, status) ~ hormone, data = data))\n\n# Extract survival probabilities into a tibble\nkm &lt;- tibble(\n  t = obj$time,\n  surv = obj$surv,\n  hormone = parse_number(as.character(obj$strata)), # Hormone group\n  type = \"Kaplan-Meier\"\n) |&gt; \n  add_row(\n    # Add starting points at (0, 1) for each group\n    t = c(0, 0),\n    surv = c(1, 1),\n    hormone = 1:2,\n    type = \"Kaplan-Meier\"\n  )\n\nThen the event-imputation and complete-case estimates (with ecdf() for empirical distribution function):\n\n# Event-imputation estimates\nimp &lt;- data |&gt; \n  group_by(hormone) |&gt; \n  reframe(\n    t = time,\n    surv = 1 - ecdf(time)(time)  # Empirical survival function\n  ) |&gt; \n  arrange(t) |&gt; \n  mutate(type = \"Event-imputation\")\n\n# Complete-case estimates\ncc &lt;- data |&gt; \n  filter(status == 1) |&gt; \n  group_by(hormone) |&gt; \n  reframe(\n    t = time,\n    surv = 1 - ecdf(time)(time)\n  ) |&gt; \n  arrange(t) |&gt; \n  mutate(type = \"Complete-case\")\n\nNow plot the figure:\n\n# Combine estimates\nestimates &lt;- bind_rows(km, imp, cc)\n\n# Define panel labels\nhormone_labeller &lt;- c(\"1\" = \"No Hormone\", \"2\" = \"Hormone\")\n\n# Plot\nestimates |&gt; \n  mutate(type = factor(type, levels = c(\"Kaplan-Meier\", \"Event-imputation\", \"Complete-case\"))) |&gt; \n  ggplot(aes(x = t, y = surv, linetype = type)) +\n  geom_step() +\n  facet_wrap(~ hormone, labeller = labeller(hormone = hormone_labeller)) +\n  theme_bw() +\n  scale_x_continuous(name = \"Time (months)\", breaks = seq(0, 72, 12), limits = c(0, 72)) +\n  scale_y_continuous(name = \"Survival rate\", limits = c(0, 1)) +\n  scale_linetype_manual(name = \"Method\", values = 1:3) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nPrettier than Fig. 1.2?\n\n\nTable 1\nLet’s recreate Table 1.12, that is, “Table 1” for the German Breast Cancer study. Because the summary statistics are grouped by hormone status and overall, we add a replica to the original data where hormone is set to “Overall”, thereby creating three levels: “No hormone”, “Hormone”, “Overall”. Then we can use summarize() to calculate the summary statistics within each level of hormone after group_by(hormone).\nTo do so, we will define three summary functions:\n\nOne calculating median (IQR) for a quantitative variable;\nOne calculating N (%) for each level of a categorical variable;\nOne calculating event rate based on time and status.\n\nTo start, read in and clean the GBC mortality data for the subject-level statistics and death rate:\n\nlibrary(knitr) # for printing formatted table\n\n## for subject-level summary and mortality\n## read in the GBC mortality data\ndata &lt;- read.table(\"Data//German Breast Cancer Study//gbc_mort.txt\")\n\n# Clean and expand data with \"Overall\" group\ndf &lt;- data |&gt; \n  mutate(hormone = if_else(hormone == 1, \"No Hormone\", \"Hormone\")) |&gt; \n  add_row(data |&gt; mutate(hormone = \"Overall\")) |&gt; \n  mutate(\n    hormone = factor(hormone, levels = c(\"No Hormone\", \"Hormone\", \"Overall\")),\n    meno = if_else(meno == 1, \"No\", \"Yes\")\n  )\n\nNow, write a function to compute median (IQR) and use it on the quantitative variables. In the process, we use pivot_longer() and pivot_wider() to put the hormone levels on the columns rather than rows. (For details on these data transposition tools, see https://r4ds.hadley.nz/data-tidy).\n\n## Function to compute median (IQR) for x\n## rounded to the rth decimal place\nmed_iqr &lt;- function(x, r = 1){\n  qt &lt;- quantile(x, na.rm = TRUE)\n  \n  str_c(round(qt[3], r), \" (\", \n        round(qt[2], r), \", \",\n        round(qt[4], r), \")\")\n}\n\n# create summary table for quantitative variables\n# age, size, nodes, prog, estrg\ntab_quant &lt;- df |&gt; \n  group_by(hormone) |&gt; \n  summarize(\n    across(c(age, size, nodes, prog, estrg), med_iqr)\n  ) |&gt; \n  pivot_longer( # long format: value = median (IQR); name = variable names\n    !hormone,\n    values_to = \"value\",\n    names_to = \"name\"\n  ) |&gt; \n  pivot_wider( # wide format: name = variable names; hormone levels as columns\n    values_from = value,\n    names_from = hormone\n  ) |&gt; \n  mutate(\n    name = case_when( # format the variable names\n      name == \"age\" ~ \"Age (years)\",\n      name == \"size\" ~ \"Tumor size (mm)\",\n      name == \"nodes\" ~ \"# Nodes\",\n      name == \"prog\" ~ \"Progesterone (fmol/mg)\",\n      name == \"estrg\" ~ \"Estrogen (fmol/mg)\"\n    )\n  )\n\nSee what the result looks like:\n\ntab_quant\n# # A tibble: 5 × 4\n#   name                   `No Hormone` Hormone       Overall        \n#   &lt;chr&gt;                  &lt;chr&gt;        &lt;chr&gt;         &lt;chr&gt;          \n# 1 Age (years)            50 (45, 59)  58 (50, 63)   53 (46, 61)    \n# 2 Tumor size (mm)        25 (20, 35)  25 (20, 35)   25 (20, 35)    \n# 3 # Nodes                3 (1, 7)     3 (1, 7)      3 (1, 7)       \n# 4 Progesterone (fmol/mg) 32 (7, 130)  35 (7.2, 133) 32.5 (7, 131.8)\n# 5 Estrogen (fmol/mg)     32 (8, 92.2) 46 (9, 182.5) 36 (8, 114) \n\nNext we deal with categorical variables. Because the results span multiple rows due to multiple levels, it is easier to write a data frame function, one that takes the tibble data frame as an argument. For details, see https://r4ds.hadley.nz/functions#data-frame-functions.\n\n## a function that computes N (%) for each level of var\n## by group in data frame df (percent rounded to rth point)\nfreq_pct&lt;- function(df, group, var, r = 1){\n  # compute the N for each level of var by group\n  var_counts &lt;- df |&gt; \n    group_by({{ group }}, {{ var }}) |&gt; \n    summarize(\n      n = n(),\n      .groups = \"drop\"\n    ) \n  # compute N (%)\n  var_counts |&gt; \n    left_join( # compute the total number (demoninator) in each group\n               # and joint it back to the numerator\n      var_counts |&gt; group_by({{ group }}) |&gt; summarize(N = sum(n)),\n      by = join_by({{ group }})\n    ) |&gt; \n    mutate( # N (%)\n      value = str_c(n, \" (\", round(100 * n / N, r), \"%)\")\n    ) |&gt; \n    select(- c(n, N)) |&gt; \n    pivot_wider( # put group levels on columns\n      names_from = {{ group }},\n      values_from = value\n    ) |&gt; \n    rename(\n      name = {{ var }} # name = variable names \n    )\n}\n\nApply this function to meno and grade (by hormone of course):\n\n## menopausal status\nmeno &lt;- df |&gt;\n  freq_pct(hormone, meno) |&gt; \n  mutate(\n    name = str_c(\"Menopause - \", name)\n  )\n\n## tumor grade\ngrade &lt;- df |&gt; \n  freq_pct(hormone, grade) |&gt; \n  mutate(\n    name = str_c(\"Tumor grade - \", name)\n  )\n\nCombine with the quantitative variables:\n\ntabone &lt;- tab_quant |&gt; \n  add_row(meno) |&gt; \n  add_row(grade)\n\ntabone\n# # A tibble: 10 × 4\n#    name                   `No Hormone` Hormone       Overall        \n#    &lt;chr&gt;                  &lt;chr&gt;        &lt;chr&gt;         &lt;chr&gt;          \n#  1 Age (years)            50 (45, 59)  58 (50, 63)   53 (46, 61)    \n#  2 Tumor size (mm)        25 (20, 35)  25 (20, 35)   25 (20, 35)    \n#  3 # Nodes                3 (1, 7)     3 (1, 7)      3 (1, 7)       \n#  4 Progesterone (fmol/mg) 32 (7, 130)  35 (7.2, 133) 32.5 (7, 131.8)\n#  5 Estrogen (fmol/mg)     32 (8, 92.2) 46 (9, 182.5) 36 (8, 114)    \n#  6 Menopause - No         231 (52.5%)  59 (24%)      290 (42.3%)    \n#  7 Menopause - Yes        209 (47.5%)  187 (76%)     396 (57.7%)    \n#  8 Tumor grade - 1        48 (10.9%)   33 (13.4%)    81 (11.8%)     \n#  9 Tumor grade - 2        281 (63.9%)  163 (66.3%)   444 (64.7%)    \n# 10 Tumor grade - 3        111 (25.2%)  50 (20.3%)    161 (23.5%)  \n\nAs the last step, create an event rate function and apply it to df to calculate the death rate:\n\n# event rate function\n# status = 1 for event\nevent_rate &lt;- function(time, status){\n  sum(status)/sum(time) \n  # we don't use sum(x, na.rm = TRUE) because\n  # missing data should alarm us\n}\n\n# calculate death rates\ndeath_rates &lt;- df |&gt; \n  group_by(hormone) |&gt; \n  summarize(\n    death_rate = as.character(round(event_rate(time, status) * 12, 3)) # per year\n  ) |&gt; \n  pivot_wider(\n    names_from = hormone,\n    values_from = death_rate\n  ) |&gt; \n  mutate(\n    name = \"Death rate (per person-year)\",\n    .before = 1\n  )\n\ndeath_rates\n# # A tibble: 1 × 4\n#   name                         `No Hormone` Hormone Overall\n#   &lt;chr&gt;                        &lt;chr&gt;        &lt;chr&gt;   &lt;chr&gt;  \n# 1 Death rate (per person-year) 0.075        0.059   0.069  \n\nFinally, read in and clean up the complete data (relapse and death) to calculate the composite endpoint (CE; time to first) event rate.\n\n# Read in the complete data\ngbc &lt;- read.table(\"Data//German Breast Cancer Study//gbc.txt\")\n\n## get the first event (minimum time)\n## for each patient id\ngbc_ce &lt;- gbc |&gt; \n  group_by(id) |&gt; \n  slice_min(time) |&gt; # take min time\n  slice_max(status) |&gt; # if death (2) is tied with relapse (1), take death\n  ungroup()\n\n## same manipulations\ndf_ce &lt;- gbc_ce |&gt; \n  mutate(\n    hormone = if_else(hormone == 1, \"No Hormone\", \"Hormone\")\n  ) |&gt; \n  add_row(gbc_ce |&gt; mutate(hormone = \"Overall\")) |&gt; \n  mutate(\n    hormone = fct(hormone, levels = c(\"No Hormone\", \"Hormone\", \"Overall\")),\n  )\n\nApply the same event rate function to calculate the CE rate.\n\nce_rates &lt;- df_ce |&gt; \n  group_by(hormone) |&gt; \n  summarize(\n    ce_rate = as.character(round(event_rate(time, status &gt; 0) * 12, 3)) # per year\n  ) |&gt; \n  pivot_wider(\n    names_from = hormone,\n    values_from = ce_rate\n  ) |&gt; \n  mutate(\n    name = \"CE rate (per person-year)\",\n    .before = 1\n  )\n\nAdd the event rates to the table and print it out:\n\n## add event rates\ntabone &lt;- tabone |&gt; \n  add_row(\n    death_rates\n  ) |&gt; \n  add_row(\n    ce_rates\n  ) \n\n## add N to group names  \ncolnames(tabone) &lt;- c(\" \", str_c(colnames(tabone)[2:4], \" (N=\", table(df$hormone),\")\"))\n## print out the table\nkable(tabone)\n\n\n\nTable 1: Patient characteristics in the German Breast Cancer study.\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo Hormone (N=440)\nHormone (N=246)\nOverall (N=686)\n\n\n\n\nAge (years)\n50 (45, 59)\n58 (50, 63)\n53 (46, 61)\n\n\nTumor size (mm)\n25 (20, 35)\n25 (20, 35)\n25 (20, 35)\n\n\n# Nodes\n3 (1, 7)\n3 (1, 7)\n3 (1, 7)\n\n\nProgesterone (fmol/mg)\n32 (7, 130)\n35 (7.2, 133)\n32.5 (7, 131.8)\n\n\nEstrogen (fmol/mg)\n32 (8, 92.2)\n46 (9, 182.5)\n36 (8, 114)\n\n\nMenopause - No\n231 (52.5%)\n59 (24%)\n290 (42.3%)\n\n\nMenopause - Yes\n209 (47.5%)\n187 (76%)\n396 (57.7%)\n\n\nTumor grade - 1\n48 (10.9%)\n33 (13.4%)\n81 (11.8%)\n\n\nTumor grade - 2\n281 (63.9%)\n163 (66.3%)\n444 (64.7%)\n\n\nTumor grade - 3\n111 (25.2%)\n50 (20.3%)\n161 (23.5%)\n\n\nDeath rate (per person-year)\n0.075\n0.059\n0.069\n\n\nCE rate (per person-year)\n0.161\n0.113\n0.142\n\n\n\n\n\n\n\n\n\nUsing gtsummary\nThere is a simpler way to create Table 1.12 using the gtsummary package.\n\nlibrary(gtsummary) \nlibrary(labelled) # For labelling variables\n\n# Re-read data to keep it distinct (optional)\ngbc_mort &lt;- read.table(\"Data//German Breast Cancer Study//gbc_mort.txt\")\n\ndf_gts &lt;- gbc_mort |&gt; \n  mutate(\n    hormone = if_else(hormone == 1, \"No Hormone\", \"Hormone\"),\n    hormone = factor(hormone, levels = c(\"No Hormone\", \"Hormone\")),\n    meno = if_else(meno == 1, \"No\", \"Yes\") |&gt; factor(levels = c(\"No\", \"Yes\"))\n  )\n\n# Labeling variables\nvar_label(df_gts) &lt;- list(\n  time = \"Time to event (months)\",\n  status = \"Event status\",\n  hormone = \"Hormone therapy\",\n  age = \"Age (years)\",\n  meno = \"Menopausal status\",\n  size = \"Tumor size (mm)\",\n  grade = \"Tumor grade\",\n  nodes = \"Number of nodes\",\n  prog = \"Progesterone (fmol/mg)\",\n  estrg = \"Estrogen (fmol/mg)\"\n)\n\ntbl1 &lt;- df_gts |&gt;\n  tbl_summary(\n    by = hormone,\n    include = ! c(id, time, status),\n    missing = \"no\"\n  ) |&gt;\n  add_overall(last = TRUE) |&gt; # At the end\n  italicize_levels()\n\ntbl1\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\nNo Hormone, N = 4401\nHormone, N = 2461\nOverall, N = 6861\n\n\n\n\nAge (years)\n50 (45, 59)\n58 (50, 63)\n53 (46, 61)\n\n\nMenopausal status\n209 (48%)\n187 (76%)\n396 (58%)\n\n\nTumor size (mm)\n25 (20, 35)\n25 (20, 35)\n25 (20, 35)\n\n\nTumor grade\n\n\n\n\n\n\n\n\n    1\n48 (11%)\n33 (13%)\n81 (12%)\n\n\n    2\n281 (64%)\n163 (66%)\n444 (65%)\n\n\n    3\n111 (25%)\n50 (20%)\n161 (23%)\n\n\nNumber of nodes\n3 (1, 7)\n3 (1, 7)\n3 (1, 7)\n\n\nProgesterone (fmol/mg)\n32 (7, 130)\n35 (7, 133)\n33 (7, 132)\n\n\nEstrogen (fmol/mg)\n32 (8, 92)\n46 (9, 183)\n36 (8, 114)\n\n\n\n1 Median (IQR); n (%)\n\n\n\n\n\n\n\n\nHowever, we still need to “manually” calculate the event rates.",
    "crumbs": [
      "Home",
      "Part I - Univariate Events",
      "Chapter 1 - Introduction"
    ]
  },
  {
    "objectID": "chapter11.html",
    "href": "chapter11.html",
    "title": "Chapter 11 - Joint Analysis of Longitudinal and Survival Data",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter11.html#slides",
    "href": "chapter11.html#slides",
    "title": "Chapter 11 - Joint Analysis of Longitudinal and Survival Data",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter11.html#base-r-code",
    "href": "chapter11.html#base-r-code",
    "title": "Chapter 11 - Joint Analysis of Longitudinal and Survival Data",
    "section": "Base R Code",
    "text": "Base R Code\n\n\nShow the code\n##################################################################\n# This code generates all numerical results in chapter 11.      ##\n##################################################################\n\n\n############################################################\n# Analysis of the anti-retroviral drug trial\n############################################################\n\n#load required packages\nlibrary(nlme) # for linear mixed effects model\nlibrary(survival)\n\n# read in the study dataset\ndata &lt;- read.table(\"Data//Anti-retroviral Trial//aids.txt\")\nhead(data)\n\n#load the JM package\ninstall.packages(\"JM\")\nlibrary(JM)\n\n#####################################################\n# Figure 11.2 Histograms of CD4 count and square-root\n#       transformation\n#####################################################\npar(mfrow=c(1,2))\nhist(data$CD4,xlab=\"CD4 count\", main = \"\", lwd=2)\nhist(sqrt(data$CD4),xlab=\"Square root of CD4 count\",main=\"\",lwd=2)\n\n# taking square root of CD4 count\ndata$y &lt;- sqrt(data$CD4)\n\n# create a de-duplicated data for survival sub-model\ndata.surv &lt;- data[!duplicated(data$id),]\n\n# Joint model fit for the HIV/AIDS dataset\n# longitudinal sub-model\nlongit.sub &lt;- lme(y ~ obsmo + obsmo:drug + sex + hist,\n                   random = ~ obsmo|id, data = data)\n\n# survival sub-model\nsurv.sub &lt;- coxph(Surv(time, status) ~ drug + sex + hist,\n                     data = data.surv, x = TRUE)\n\n# combine the two models\n# piecewise linear baseline with six internal knots\njoint.model &lt;- jointModel(longit.sub, surv.sub,\n                            timeVar = \"obsmo\",\n                            method = \"piecewise-PH-aGH\")\n\n\njoint.model$coefficients\n\n# print out the summary\nsummary(joint.model)\n\n\n\n######################################\n# Figure 11.3\n######################################\n\n# compute the mean trajectories based on the longitudinal\n# sub-model results\n\nt &lt;- (0:180)/10\n\ng0 &lt;- 2.2123\ng1 &lt;- -0.0414\ng3 &lt;- 0.9153\ng4 &lt;- 0.0061\n\n\nddC.nonhist &lt;- (g0+g3+g1*t)^2\nddC.hist &lt;- (g0+g1*t)^2\n\n\nddI.nonhist &lt;- (g0+g3+(g1+g4)*t)^2\nddI.hist &lt;- (g0+(g1+g4)*t)^2\n\n\n#######################################################\n# Figure 11.3\n# Model-based estimates of the mean trajectories\n#  of CD4 count for female patients by treatment\n#  group and previous infection status. Solid, ddC;\n#  dotted, ddI\n######################################################\npar(mfrow=c(1,2))\n\nplot(t, ddC.nonhist,type='l',frame.plot=F,\n     main=\"No previous infection\",xlim=c(0,20),ylim=c(0,10),\n     xlab=\"Time (months)\", ylab=\"Mean CD4 cell count\", lwd=2, cex.main = 1)\nlines(t,ddI.nonhist,lty=3,lwd=2)\n\nplot(t, ddC.hist,type='l',frame.plot=F,\n     main=\"Previous infection\",xlim=c(0,20),ylim=c(0,10),\n     xlab=\"Time (months)\", ylab=\"Mean CD4 cell count\", lwd=2, cex.main = 1)\nlines(t,ddI.hist,lty=3,lwd=2)"
  },
  {
    "objectID": "chapter13.html",
    "href": "chapter13.html",
    "title": "Chapter 13 - Composite Endpoints",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter13.html#slides",
    "href": "chapter13.html#slides",
    "title": "Chapter 13 - Composite Endpoints",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter13.html#base-r-code",
    "href": "chapter13.html#base-r-code",
    "title": "Chapter 13 - Composite Endpoints",
    "section": "Base R Code",
    "text": "Base R Code\n\n\nShow the code\n#######################################################\n#  Section 13.2 RMT-IF analysis of the high-risk\n#   subgroup of the HF-ACTION study data\n#######################################################\n\n\n# install load the rmt package\ninstall.packages(\"rmt\")\nlibrary(rmt)\n##### Read in HF-ACTION DATA########\ndata(\"hfaction\")\n\ndata &lt;- hfaction\n\n# number of unique patients by treatment\n# group and overall\nuid &lt;- unique(data$patid)\nn &lt;- length(uid)\n\nuid1 &lt;- unique(data$patid[data$trt_ab==1])\nn1 &lt;- length(uid1)\n\nuid0 &lt;- unique(data$patid[data$trt_ab==0])\nn0 &lt;- length(uid0)\n\n\n## average number of hosps\nsum(data$status[data$trt_ab==1]==1)/n1\nsum(data$status[data$trt_ab==0]==1)/n0\n\n## total number of hosps\nsum(data$status==1)\n## total number of deaths\nsum(data$status==2)\n\n\n# extract variables for analysis by\n# rmtfit()\nid &lt;- data$patid\ntime &lt;- data$time\nstatus &lt;- data$status\ntrt &lt;- data$trt_ab\n\n\n\n###### Standard RMST analysis #################\nlibrary(survRM2)\n\n### create datasets for time to first event ###\ndata.TFE &lt;- data[!duplicated(data$patid),]\n\n### create datasets for overall mortality ###\n## death: status=2\ndata_death &lt;- data[data$status==2|data$status==0,]\n\n##RMST analysis for hospitalization-free survival and overall survival\nrmst2(data.TFE$time, data.TFE$status&gt;0, data.TFE$trt_ab, tau=3.97)\nrmst2(data_death$time, data_death$status&gt;0, data_death$trt_ab, tau=3.97)\n\n\n#### Kaplan-Meier (KM) curves for the hospitalization-free survival\n## (time to the first event) and overall survival by treatment group.\n\n# Fit KM curves by trt_ab\nobj.TFE &lt;- survfit(Surv(time,status&gt;0)~trt_ab,data=data.TFE)\nobj.death &lt;- survfit(Surv(time,status==2)~trt_ab,data=data_death)\n\n\n# Plot Fig 13.1\npar(mfrow=c(1,2))\nplot(obj.TFE,main=\"Hopitalization-free survival\",lty=1:2,ylab=\"Survival probabilities\",\n     xlab=\"Time (years)\", lwd=2)\nlegend(\"bottomleft\",c(\"Usual care\",\"Exercise training\"),lwd=2, lty=1:2)\nabline(v=4,lty=3,lwd=2)\n\nplot(obj.death,main=\"Overall survival\",lty=1:2,ylab=\"Survival probabilities\",\n     xlab=\"Time (years)\", lwd=2)\nlegend(\"bottomleft\",lty=1:2,c(\"Usual care\",\"Exercise training\"),lwd=2)\nabline(v=4,lty=3,lwd=2)\n\n########################\n# RMT-IF analysis\n########################\n\n\n# analyze the data using rmtfit()\nobj &lt;- rmtfit(rec(patid,time,status)~trt_ab,data=data)\n# Alternatively\n# obj=rmtfit(id,time,status,trt,type=\"recurrent\")\n\nsummary(obj, Kmax=1, tau=3.97)\n\n#############################################################\n# Graphical analysis of the HF-ACTION trial to\n# evaluate the effect of exercise training.\n###########################################################\n\npar(mfrow=c(1,2))\n# Kmax=4: to aggregate k=4,..., K\nbouquet(obj,Kmax=4,cex.group = 1.0,cex.lab=1.5,cex.axis=1.5,\n        xlab=\"Restricted mean win/loss time (years)\",\n        ylab=\"Follow-up time (years)\",group.label=F,ylim=c(0,4.2))\ntext(-0.8,4.15,paste(\"Usual care\"),cex=1.2)\ntext(0.8,4.15,paste(\"Exercise training\"),cex=1.2)\n\nplot(obj,conf=T,lwd=2, cex.lab=1.5,cex.axis=1.5,xlab=\"Follow-up time (years)\",\n     ylab=\"RMT-IF of training (years)\",main=\"\")\npar(mfrow=c(1,1))\n\n### LaTeX table ###\n\n### format to LATEX table\npval_fmt3=function(x){\n  if(x&lt;0.001){\n    return(\"$&lt;$0.001\")\n  }else{\n    return(round(x,3))\n  }\n}\n\n\nltable=NULL\n# aggregate the results for k=1,..., K\nhosp_sum=summary(obj,Kmax=1,tau=3.97)$tab\n# aggregate the results for k=4,..., K\nall_sum=summary(obj,Kmax=4,tau=3.97)$tab\n\nltable=c(\"&\",\"&\",\"&\",round(12*hosp_sum[1,1],2),\"&\",round(12*hosp_sum[1,2],2),\"&\",pval_fmt3(hosp_sum[1,4]),\"\\\\\")\n\nfor (i in 1:6){\n  tmp=c(\"&\",i,\"&&\",round(12*all_sum[i,1],2),\"&\",round(12*all_sum[i,2],2),\"&\",pval_fmt3(all_sum[i,4]),\"\\\\\")\n  ltable=rbind(ltable,tmp)\n}\n\nltable[5,2]=\"4+\"\nltable[6:7,2]=\"\"\n\nrownames(ltable)=c(\"Hopitalization\",\"\",\"\" ,\"\",\"\",\"Death\",\"Overall\")\n\nnoquote(ltable)\n\n\n\n\n\n##################################################################\n# This code is related to the numerical results in chapter 13   ##\n##################################################################\n\n\n# The real data used in Section 13.3.7 are protected by data sharing agreement.\n# Below is a similar analysis based on a subset of the data using the \"WR\" package.\n# The analysis illustrates the use of the pwreg() function for fitting Pocock's PW\n# regression model and score.proc() function for plotting standardized score processes\n\n\n# An example: HF-ACTION study\n\n# We consider a dataset from the HF-ACTION study consisting of 451 non-ischemic heart failure\n# patients. The study was conducted between April 2003 through Feb 2007 at 82 sites in the USA,\n# Canada, and France (O'Connor et al., 2009). The study objective was to assess the effect of\n# adding aerobic exercise training to usual care on the patients CV outcomes. The primary\n# endpoint was a composite of all-cause death and all-cause hospitalization.\n\n#######################################################################\n# We first load the WR package and the analysis dataset non_ischemic\n#######################################################################\n\n# If the \"WR\" hasn't been installed, need to download and install it\n# from CRAN\ninstall.packages(\"WR\")\nlibrary(WR)\n#&gt; Loading required package: survival\nhead(non_ischemic)\n#&gt;   ID time status trt_ab age sex Black.vs.White Other.vs.White   bmi\n#&gt; 1  1  221      2      0  62   1              0              0 25.18\n#&gt; 2  1  383      0      0  62   1              0              0 25.18\n#&gt; 3  2   23      2      0  75   1              1              0 22.96\n#&gt; 4  2 1400      0      0  75   1              1              0 22.96\n#&gt; 5  5    7      2      0  48   1              1              0 34.37\n#&gt; 6  5   10      1      0  48   1              1              0 34.37\n#&gt;   bipllvef hyperten COPD diabetes acei betab smokecurr\n#&gt; 1    32.24        0    0        0    0     1         1\n#&gt; 2    32.24        0    0        0    0     1         1\n#&gt; 3    21.71        1    0        0    0     1         0\n#&gt; 4    21.71        1    0        0    0     1         0\n#&gt; 5    22.97        1    0        0    0     1         0\n#&gt; 6    22.97        1    0        0    0     1         0\n\n\n# Re-label the covariates with informative names.\n\ncolnames(non_ischemic)[4:16]=c(\n  \"Training vs Usual\",\"Age (year)\",\"Male vs Female\",\"Black vs White\",\n  \"Other vs White\", \"BMI\",\"LVEF\",\"Hypertension\",\"COPD\",\"Diabetes\",\n  \"ACE Inhibitor\",\"Beta Blocker\", \"Smoker\"\n)\n\n#Compute the sample size the median length of follow-up.\n\n# sample size\nlength(unique(non_ischemic$ID))\n#&gt; [1] 451\n# median length of follow-up time\nmedian(non_ischemic$time[non_ischemic$status&lt;2])/30.5\n#&gt; [1] 31.63934\n\n#So we have n=451 unique patients with a median follow-up of 31.6 months.\n\n\n################################################################\n# Next, we use the pwreg() function to fit the PW model:\n################################################################\n\n# get the number of rows and number of covariates.\nnr &lt;- nrow(non_ischemic)\np &lt;- ncol(non_ischemic) - 3\n\n# extract ID, time, status and covariates matrix Z from the data.\n# note that: ID, time and status should be column vector.\n# covariatesZ should be (nr, p) matrix.\nID &lt;- non_ischemic[,\"ID\"]\ntime &lt;- non_ischemic[,\"time\"]\nstatus &lt;- non_ischemic[,\"status\"]\nZ &lt;- as.matrix(non_ischemic[,4:(3+p)], nr, p)\n\n\n# pass the parameters into the function\npwreg.obj &lt;- pwreg(ID=ID, time=time, status=status, Z=Z)\n\nprint(pwreg.obj)\n#&gt; Call:\n#&gt; pwreg(time = time, status = status, Z = Z, ID = ID)\n#&gt;\n#&gt; Proportional win-fractions regression models for priority-adjusted composite endpoint\n#&gt;\n#&gt;\n#&gt;\n#&gt; Total number of pairs: 101475\n#&gt; Wins-losses on death:  7644 (7.5%)\n#&gt; Wins-losses on non-fatal event:  78387 (77.2%)\n#&gt; Indeterminate pairs 15444 (15.2%)\n#&gt;\n#&gt; Newton-Raphson algorithm converged in 5 iterations.\n#&gt;\n#&gt; Overall test: chisq test with 13 degrees of freedom;\n#&gt;  Wald statistic 24.9 with p-value 0.02392931\n#&gt;\n#&gt; Estimates for Regression parameters:\n#&gt;\n#&gt;                     Estimate         se z.value p.value\n#&gt; Training vs Usual  0.1906687  0.1264658  1.5077 0.13164\n#&gt; Age (year)        -0.0128306  0.0057285 -2.2398 0.02510 *\n#&gt; Male vs Female    -0.1552923  0.1294198 -1.1999 0.23017\n#&gt; Black vs White    -0.3026335  0.1461330 -2.0709 0.03836 *\n#&gt; Other vs White    -0.3565390  0.3424360 -1.0412 0.29779\n#&gt; BMI               -0.0181310  0.0097582 -1.8580 0.06316 .\n#&gt; LVEF               0.0214905  0.0086449  2.4859 0.01292 *\n#&gt; Hypertension      -0.0318291  0.1456217 -0.2186 0.82698\n#&gt; COPD              -0.4023069  0.2066821 -1.9465 0.05159 .\n#&gt; Diabetes           0.0703990  0.1419998  0.4958 0.62006\n#&gt; ACE Inhibitor     -0.1068201  0.1571317 -0.6798 0.49662\n#&gt; Beta Blocker      -0.5344979  0.3289319 -1.6250 0.10417\n#&gt; Smoker            -0.0602350  0.1682826 -0.3579 0.72039\n#&gt; ---\n#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n#&gt;\n#&gt;\n#&gt; Point and interval estimates for for win ratios:\n#&gt;\n#&gt;                   Win Ratio 95% lower CL 95% higher CL\n#&gt; Training vs Usual 1.2100585    0.9444056     1.5504374\n#&gt; Age (year)        0.9872513    0.9762288     0.9983983\n#&gt; Male vs Female    0.8561648    0.6643471     1.1033663\n#&gt; Black vs White    0.7388699    0.5548548     0.9839127\n#&gt; Other vs White    0.7000951    0.3578286     1.3697431\n#&gt; BMI               0.9820323    0.9634287     1.0009952\n#&gt; LVEF              1.0217231    1.0045572     1.0391823\n#&gt; Hypertension      0.9686721    0.7281543     1.2886357\n#&gt; COPD              0.6687755    0.4460178     1.0027865\n#&gt; Diabetes          1.0729362    0.8122757     1.4172433\n#&gt; ACE Inhibitor     0.8986873    0.6604773     1.2228110\n#&gt; Beta Blocker      0.5859634    0.3075270     1.1164977\n#&gt; Smoker            0.9415433    0.6770144     1.3094312\n#\n# The output consists of three parts. The first part presents some descriptive statistics\n# on the proportions of win-loss status among all (n2)=101,475\n# pairs. According to the output, 7.5% of them are determined by death;\n# 77.2% by hospitalization, and the remaining 7.2% are indeterminate.\n# It also reports an overall (Wald) test with p-value 0.024, suggesting that,\n# at the conventional 0.05 level, the 13 covariates are significantly associated\n# with the composite outcome.\n#\n# The second part presents a table for the estimates and standard errors of the regression\n# coefficient, along with their corresponding p -value for testing the coefficient being\n# zero. The third part is perhaps the most informative, tabulating the estimated win ratios\n# (exponential of the regression coefficients) and their associated 95% confidence intervals.\n# We can see that a patient in exercise training is 21% more likely to have a better\n#  priority-adjusted composite outcome than one in usual care. However, this difference\n# is statistically not significant. In addition, younger age, white race, higher LVEF are\n# significantly associated with more favorable outcomes than otherwise, while the beneficial\n# effects of low BMI and absence of COPD history are border-line significant.\n#\n\n\n# To assess the effect of race on the composite outcome, we test the null hypothesis\n# H0:\\beta_4=\\beta_5=0.\n# We conduct a 2-df Chi-square Wald test based on (\\beta_4,\\beta_5)\n\n\n  #extract estimates of (\\beta_4,\\beta_5)\n  beta &lt;- matrix(pwreg.obj$beta[4:5])\n  #extract estimated covariance matrix for (\\beta_4,\\beta_5)\n  Sigma &lt;- pwreg.obj$Var[4:5,4:5]\n  #compute chisq statistic in quadratic form\n  chistats &lt;- t(beta) %*% solve(Sigma) %*% beta\n\n# compare the Wald statistic with the reference\n# distribution of chisq(2) to obtain the p-value\n1 - pchisq(chistats, df = 2)\n#&gt;           [,1]\n#&gt; [1,] 0.1016988\n\n#  The p -value is 0.102. So the overall effect of race on the composite outcome is\n# non-significant.\n\n\n#  Finally, we use the score.proc() function to plot the standardized score process\n# for each covariate:\n\n  score.obj &lt;- score.proc(pwreg.obj)\n  print(score.obj)\n#&gt; This object contains two components:\n#&gt;  't': an l-vector of times\n#&gt;  'score': a p-by-l matrix whose k'th row is the standardized score process for the k'th\n  # covariate\n#&gt;           as a function of t\n#&gt;\n#&gt; Use 'plot(object,k=k)' to plot the k'th score process.\n\noldpar &lt;- par(mfrow = par(\"mfrow\"))\npar(mfrow = c(4,4))\nfor(i in c(1:13)){\n  plot(score.obj, k = i)\n}\npar(oldpar)"
  },
  {
    "objectID": "chapter15.html",
    "href": "chapter15.html",
    "title": "Chapter 15 - Machine Learning in Survival Analysis",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter15.html#slides",
    "href": "chapter15.html#slides",
    "title": "Chapter 15 - Machine Learning in Survival Analysis",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter15.html#base-r-code",
    "href": "chapter15.html#base-r-code",
    "title": "Chapter 15 - Machine Learning in Survival Analysis",
    "section": "Base R Code",
    "text": "Base R Code\n\n\nShow the code\n##################################################################\n# This code generates all numerical results in chapter 15.     ##\n##################################################################\n\n\n# library(\"glmpath\")\nlibrary(\"glmnet\")\nlibrary(survival)\n# read in the complete data\ngbc &lt;- read.table(\"Data//German Breast Cancer Study//gbc.txt\")\n\n# subset to first event data\n# Sort the data by time within each id\no &lt;- order(gbc$id,gbc$time)\ngbc &lt;- gbc[o,]\n# get the first row for each id\ndata.CE &lt;- gbc[!duplicated(gbc$id),]\n\n#set status=1 if status==2 or 1\ndata.CE$status &lt;- (data.CE$status &gt; 0 ) + 0\n\n# create a binary variable for age&lt;=40 years\ndata.CE$age40 &lt;- (data.CE$age &lt;= 40) + 0\n\n\n\nn &lt;- nrow(data.CE)\nhead(data.CE)\n\n## select training set\n# N=400\nset.seed(1234)\nind &lt;- sample(1:n)[1:400]\ntrain &lt;- data.CE[ind,]\ntest &lt;- data.CE[-ind,]\n\n# Predictor list for Cox-lasso\npred_list &lt;- c(\"hormone\", \"age40\", \"meno\", \"size\", \"grade\",\n            \"nodes\", \"prog\", \"estrg\")\n\n# covariate matrix \nZ &lt;- as.matrix(train[,pred_list])\n\n# time and status variables\ntime &lt;- train$time\nstatus &lt;- train$status\n\n# dimension of covariate matrix\ndim(Z)\n# 400x 8\n\n# compute the covariate path as a function of lambda\n# alpha=1: L_1 penalty (lasso)\nobj &lt;- glmnet(Z,Surv(time, status), family=\"cox\", alpha = 1)\nsummary(obj)\n\n# compute 10-fold (default) cross-validation\nobj.cv &lt;- cv.glmnet(Z,Surv(time, status), family=\"cox\", alpha = 1)\n\n\n# Figure parameters\npar(mfrow = c(1,2))\n# par(cex = 1.2)\n\n# plot the covariate paths as\n# a function of log-lambda\nlibrary(plotmo) # for plot_glmnet\nplotmo::plot_glmnet(obj, lwd=2)\n\n# plot(obj,xvar=\"lambda\",lwd=2,label=TRUE)\n\n# plot the the validation error (partial-likelihood deviance)\n# as a function of log-lambda\nplot(obj.cv)\n\n# the optimal lambda\nobj.cv$lambda.min\n\nlog(obj.cv$lambda.min)\n\n# the beta at optimal lambda\nbeta &lt;- coef(obj.cv, s = \"lambda.min\")\n# the non-zero coefficients\nbeta.selected &lt;- beta[abs(beta[,1])&gt;0,]\n# print out the non-zero coefficients\nbeta.selected\n# number of non-zero coefficients\nlength(beta.selected)\n\n\n# Refit the training data using the variables selected\nselected &lt;- names(beta.selected)\nobj &lt;- coxph(Surv(train$time, train$status) ~ as.matrix(train[,selected]))\n\n###############################################################################\n## A function that takes on a coxph object obj and a (n x p) test covariate\n## matrix Z and outputs the predicted survival function\n## Output:\n### St: (n x m) matrix with the ith row the predicted survival rates for the\n###  ith subject;\n### t: m-vector of times.\n###############################################################################\npredsurv_cox &lt;- function(obj, Z){\n  beta=obj$coefficients\n  bhaz=basehaz(obj,centered=F)\n  L=bhaz$hazard\n  t=c(0, bhaz$time)\n  St=cbind(rep(1,nrow(Z)),exp(-exp(Z%*%beta)%*%t(L)))\n  return(list(St=St,t=t))\n}\n\n## Get the predicted survival rates for the test set by Cox-lasso \npred_surv &lt;- predsurv_cox(obj, Z=as.matrix(test[,selected]))\n\nSt &lt;- pred_surv$St\nt &lt;- pred_surv$t\n\n\n## Get the KM estimates for censoring distribution\nG_obj &lt;- summary(survfit(Surv(time, 1-status)~1, data=test))\ntc &lt;- c(0,G_obj$time)\nGtc &lt;- c(1,G_obj$surv)\n\n#####################################################\n# A function calculating the Brier score BS(tau)\n# Input:\n#   tau: time at which the score is evaluated\n#   (time, status): observed test outcomes\n#   St,t: predicted survival rates\n#   Gtc,tc: KM estimates for censoring distributions\n######################################################\nBSfun=function(tau,time,status,St,t,Gtc,tc){\n  \n  n=length(time)\n  BSvec=rep(NA,n)\n  \n  pos=sum(t&lt;=tau)\n  \n  for (i in 1:n){\n    X_i=time[i]\n    S_i=St[i,pos]\n    \n    G_i=ifelse(X_i&lt;=tau&&status[i]==1, \n               Gtc[sum(tc&lt;=X_i)], \n               Gtc[sum(tc&lt;=tau)])\n    \n    BSvec[i]=ifelse(X_i&lt;=tau&&status[i]==1, \n                    S_i^2/G_i, ifelse(\n                      X_i&gt;tau,(1-S_i)^2/G_i,0\n                     )\n                    )\n  \n  }\n  return(mean(BSvec,na.rm=T))\n  \n}  \n\n# Compute the Brier score at tau=12 to 60 months\n# under Cox-lasso\ntau_list &lt;- 12:60\nBS_tau &lt;- rep(NA,length(tau_list))\nfor(i in 1:length(tau_list)){\n  BS_tau[i] &lt;- BSfun(tau=tau_list[i],test$time,test$status,St,t,Gtc,tc)\n}\n\nplot(tau_list,BS_tau,type='l',lwd=2)\n\n# Full Cox model\nobj_full &lt;- coxph(Surv(train$time, train$status)~as.matrix(train[,pred_list]))\n\n# Get the predicted survival rates\npred_surv_full &lt;- predsurv_cox(obj_full, Z=as.matrix(test[,pred_list]))\nSt_full &lt;- pred_surv_full$St\nt_full &lt;- pred_surv_full$t\n\n# Compute the Brier score at tau=12 to 60 months\n# under Cox-full\nBS_tau_full &lt;- rep(NA,length(tau_list))\nfor(i in 1:length(tau_list)){\n  BS_tau_full[i] &lt;- BSfun(tau=tau_list[i],test$time,test$status,St_full,t_full,Gtc,tc)\n}\n\n  \n\n##############################\n# Survival trees             #\n##############################\n\n\nlibrary(rpart)\nlibrary(rpart.plot)\n\n\n### Build survival tree with cross-validation error ###\nset.seed(12345)\n\n# Conduct 10-fold cross-validation (xval = 10),\n# with minimum terminal node size 2 (minbucket = 2)\nobj &lt;- rpart(Surv(time, status) ~ hormone+meno+size+grade+nodes+ \n              prog+estrg+age,\n             control = rpart.control(xval = 10, minbucket = 2, cp=0),\n             data = train)\nprintcp(obj)\n\n#             CP nsplit rel.error  xerror   xstd\n# 1  0.07556835      0   1.00000 1.00411 0.046231\n# 2  0.03720019      1   0.92443 0.96817 0.047281\n# 3  0.02661914      2   0.88723 0.95124 0.046567\n# 4  0.01716925      3   0.86061 0.92745 0.046606\n# 5  0.01398306      4   0.84344 0.92976 0.047514\n# 6  0.01394869      5   0.82946 0.93941 0.048404\n# 7  0.01055028      9   0.77120 0.97722 0.052133\n# 8  0.01053135     10   0.76065 1.00140 0.054295\n\n# summary(obj)\n\n\n# cross-validation results\ncptable &lt;- obj$cptable\n# complexity parameter values\nCP &lt;- cptable[, 1]\n# obtain the optimal parameter\ncp.opt &lt;- CP[which.min(cptable[, 4])]\n# Prune the tree \nfit &lt;- prune(obj, cp = cp.opt)\n\n\n\npar(mfrow=c(1,2))\n# plot the pruned tree structure\nrpart.plot(fit)\n# plot the KM curves for the terminal nodes\nkm &lt;- survfit(Surv(time, status) ~ fit$where, train)\nplot(km, lty = 1:4, mark.time = FALSE,\n       xlab = \"Years\", ylab = \"Progression\",lwd=2,cex.lab=1.2,cex.lab=1.2)\nlegend(\"bottomleft\", paste('Node', sort(unique(fit$where))), lty = 1:4,lwd=2,cex=1.2)\n\n\n# Get the KM estimates for the outcome in each terminal node\ntmp &lt;- summary(km)\ntmp.strata &lt;- as.integer(sub(\".*=\", \"\", tmp$strata))  \ntmp.t &lt;- tmp$time\ntmp.surv &lt;- tmp$surv\n\n# Number of terminal nodes\nTN &lt;- unique(tmp.strata)\nN &lt;- length(TN)\n\n# Combine the predicted survival rates together,\n# as functions of t\nt &lt;- sort(unique(tmp.t))\nm &lt;- length(t)\nfitted_surv=matrix(NA,m,N)\nfor (j in 1:m){\n  tj &lt;- t[j]\n  for (k in 1:N){\n    tk &lt;- c(0,tmp.t[tmp.strata==TN[k]])\n    survk &lt;- c(1,tmp.surv[tmp.strata==TN[k]])\n    fitted_surv[j,k] &lt;- survk[sum(tk&lt;=tj)]\n  }\n}\n\n\n\n# Get the terminal node prediction\n# for the test data\nlibrary(treeClust)\ntest_term &lt;- rpart.predict.leaves(fit, test)\n\nn &lt;- length(test_term)\n\nSt_tree &lt;- matrix(NA, n, m)\nfor (k in 1:N){\n  ind &lt;- which(test_term==TN[k])\n  St_tree[ind,] &lt;- matrix(fitted_surv[,k], nrow=length(ind), \n                       ncol=m, byrow=TRUE)\n}\n\n\n\n## Get the KM estimates for censoring distribution\nG_obj &lt;- summary(survfit(Surv(time, 1-status)~1, data=test))\ntc &lt;- c(0,G_obj$time)\nGtc &lt;- c(1,G_obj$surv)\n\n# Compute the Brier score at tau=12 to 60 months\n# under the pruned survival tree\ntau_list &lt;- 12:60\nBS_tau_tree &lt;- rep(NA,length(tau_list))\nfor(i in 1:length(tau_list)){\n  BS_tau_tree[i] &lt;- BSfun(tau=tau_list[i],test$time,test$status,St_tree,t,Gtc,tc)\n  \n}\n\n# Plot the Bier score curves for Cox-lasso, Cox-full, and survival tree\npar(mfrow=c(1,1))\n\nplot(tau_list/12,BS_tau_tree,type='l',lwd=2,col=\"red\",cex.axis=1.2,\n     cex.lab=1.2,xlab=\"t (years)\", ylab=\"BS(t)\",ylim=c(0,0.25))\nlines(tau_list/12,BS_tau,lty=1,lwd=2,col=\"blue\")\nlines(tau_list/12,BS_tau_full,lty=1,lwd=2,col=\"black\")\nlegend(\"bottomright\",1,col=c(\"red\",\"blue\",\"black\"),lwd=2,\n       c(\"Survival Tree\",\"Cox-lasso\",\"Cox-full\"),cex=1.2)"
  },
  {
    "objectID": "chapter3.html",
    "href": "chapter3.html",
    "title": "Chapter 3 - Nonparametric Estimation and Testing",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter3.html#slides",
    "href": "chapter3.html#slides",
    "title": "Chapter 3 - Nonparametric Estimation and Testing",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter3.html#base-r-code",
    "href": "chapter3.html#base-r-code",
    "title": "Chapter 3 - Nonparametric Estimation and Testing",
    "section": "Base R Code",
    "text": "Base R Code\n\n\nShow the code\n##################################################################\n# This code generates all numerical results in  chapter 3.      ##\n##################################################################\n\n###################################################\n# Figure 3.3 and Table 3.2                 \n# Nelsen-Aalen estimator of cumulative hazard function\n# for the rat study\n###################################################\n\nlibrary(survival)\n# ##################################################\n# Description of \"rats\" dataset\n# \n# Rat treatment data from Mantel et al. Three rats were chosen from each of 100 litters, \n# one of which was treated with a drug, and then all followed for tumor incidence.\n# Usage\n# \n# \n# \n# Format\n# litter:   litter number from 1 to 100\n# rx:   treatment,(1=drug, 0=control)\n# time: time to tumor or last follow-up\n# status:   event status, 1=tumor and 0=censored\n# sex:  male or female\n# \n# N. Mantel, N. R. Bohidar and J. L. Ciminera. Mantel-Haenszel analyses of litter-matched \n# time to response data, with modifications for recovery of interlitter information. \n# Cancer Research, 37:3863-3868, 1977.\n##############################################################\n\nrats &lt;- read.table(\"Data//Rat Tumorigenicity Study//rats.txt\",header=T)\n\nhead(rats)\n\n#subset to treatment arm\nrats.rx &lt;- rats[rats$rx==1,]\n\n#X and delta\ntime &lt;- rats.rx$time\nstatus &lt;- rats.rx$status\n\n#ordered unique  event times\nts &lt;- unique(sort(time[status==1]))\nm &lt;- length(ts)\nts\n#numbers of failures at each point in ts\nds &lt;- table(time[status==1])\n##numbers at risk at each point in ts\nns &lt;- rep(NA,m)\n##Nelsen-Aalen estimator\n## for dLambda \ndL &lt;- rep(NA,m)\n## and Lambda\nL &lt;- rep(NA,m)\nfor (j in 1:m){\n  ns[j] &lt;- sum(time&gt;=ts[j])\n  dL[j] &lt;- ds[j]/ns[j]\n  L[j] &lt;- sum(dL[1:j])\n}\n\nresults &lt;- cbind(ts,ds,ns,dL,L)\n#print the table\nround(results,3)\n\n#plot the estimated cumulative hazard function\npar(mfrow=c(1,1))\nplot(stepfun(ts,c(0,L)),do.points = F,ylim=c(0,0.4),xlim=c(0,120), lwd=2, \n     frame.plot=FALSE, xlab=\"Time (days)\",ylab=\"Cumulative hazard function\",\n     main=\"\", cex.lab=1.5, cex.axis=1.5)\n\n\n\n###################################################\n# Table 3.3                 \n# Kaplan-Meier (KM) estimator of survival function\n# for the rat study\n###################################################\n\n#csurv (conditional survival): 1-d_j/n_j\ncsurv &lt;- 1-dL\n#variance of csurv by Greenwoods's formula\nvar.csurv &lt;- ds/(ns*(ns-ds))\n\n#KM estimates of survival function\nKMsurv &lt;- rep(NA,m)\n##Greenwoods formula for se\nse &lt;- rep(NA,m)\n\n# Compute the KM estimates and Greenwood's se\nfor (j in 1:m){\n  KMsurv[j] &lt;- prod(csurv[1:j])\n  se[j] &lt;- KMsurv[j]*sqrt(sum(var.csurv[1:j]))\n}\n\nresults2 &lt;- cbind(ts,ds,ns,csurv,KMsurv,se)\n#print the table\nround(results2,3)\n  \n\n\n\n###################################################\n# Figure 3.4                 \n# Kaplan-Meier (KM) estimator of survival function\n# for the rat study\n###################################################\n\nobj &lt;- survfit(Surv(time,status) ~ 1, data = rats.rx, conf.type = \"log-log\")\n\nsummary(obj)\n\n# plot the estimated survival function\nplot(obj, ylim = c(0,1), xlim = c(0, 100), lwd = 2, frame.plot = FALSE,\n     xlab = \"Time (days)\", ylab = \"Tumor-free probabilities\", main = \"\")\n\nlegend(1, 0.2, c(\"Kaplan-Meier curve\", \"95% Confidence limits\"),\n       lty = 1:2, lwd = 2)\n\n\n###################################################\n# Table 3.4\n###########################################\n# install.packages(\"gtsummary\")\nlibrary(gtsummary)\n\n# A single-group KM model\nobj &lt;- survfit(Surv(time, status) ~ 1, data = rats.rx)\n\n# 1) Summaries at specific times\ntbl_time &lt;- tbl_survfit(\n  x = obj,\n  times = seq(40, 100, by = 20),\n  label_header = \"{time} days\"\n)\n\ntbl_time\n\n# install.packages(\"ggsurvfit\")\nlibrary(ggsurvfit)\nobj &lt;- survfit(Surv(time, status) ~ 1, data = rats.rx)\n\n# Create a KM plot with confidence intervals and an at-risk table\nggsurvfit(obj) +\n  add_confidence_interval() +  # shaded 95% CI region\n  add_risktable() +  # Show risk table \n  scale_x_continuous(breaks= seq(0, 100, by = 20)) + # x-axis breaks\n  ylim(0, 1) + # y-axis limits\n  labs(\n    x = \"Time (days)\",\n    y = \"Tumor-free probabilities\"\n  ) +\n  theme_minimal()\n\nggsave(\"images//rats_KM_gg.png\", width = 7.5, height = 4)\nggsave(\"images//rats_KM_gg.eps\", device = cairo_ps, width = 7.5, height = 4)\n\n#################################################\n#   log-rank test for rat study\n#   comparing treatment and control\n#################################################\n#dataset\nhead(rats)\n\n# Log-rank test on treatment difference in tumorigenicity\nobj &lt;- survdiff(Surv(time,status)~ rx + strata(sex),\n          data = rats, rho = 0)\n# Print out test results\nobj\n#&gt; Call:\n#&gt; survdiff(formula = Surv(time, status) ~ rx + strata(sex), data = rats, \n#&gt;     rho = 0)\n#&gt; \n#&gt;        N Observed Expected (O-E)^2/E (O-E)^2/V\n#&gt; rx=0 200       21     28.9      2.16      6.99\n#&gt; rx=1 100       21     13.1      4.77      6.99\n#&gt; \n#&gt;  Chisq= 7  on 1 degrees of freedom, p= 0.008 \n \n \nobj$pvalue\n\n####\n# Tidy tools\n#\n\n# A two-group KM model\nobj &lt;- survfit(Surv(time, status) ~ rx, data = rats)\n\n# Summaries at specific times with labeled treatment groups\ntbl_surv &lt;- tbl_survfit(\n  x = obj,                         # Provide the fitted survfit object\n  times = seq(40, 100, by = 20),   # Time points for survival rates\n  label_header = \"{time} days\",    # Column label: \"xx days\"\n  label = list(rx ~ \"Treatment\")   # Rename 'rx' to 'Treatment'\n)\n\n# Print out the table\ntbl_surv\n\n## graphics\n\n# Load required packages\nlibrary(ggsurvfit)  # For Kaplan-Meier survival curves\nlibrary(ggplot2)    # For plot customization\n\n# Use survfit2 as recommended by ggsurvfit\nobj2 &lt;- survfit2(Surv(time, status) ~ rx, data = rats)\n\n\n# Create a KM plot with confidence intervals and an at-risk table\nggsurvfit(obj2, linetype_aes = TRUE, linewidth = 1) +  # Use line types instead of colors\n  add_pvalue(caption = \"Log-rank {p.value}\") +  # Add log-rank test p-value\n  add_risktable(                    \n    risktable_stats = \"n.risk\",  # Include only numbers at risk\n    theme = list(\n      theme_risktable_default(),  # Apply default risk table theme\n      scale_y_discrete(labels = c('Drug', 'Control'))  # Properly label treatment groups\n    )\n  ) +  \n  labs(\n    x = \"Time (days)\",  # Label for X-axis\n    y = \"Tumor-free probabilities\"  # Label for Y-axis\n  ) +\n  scale_linetype_manual(\n    values = c(2, 1),  # Use different line types (dashed for Control, solid for Drug)\n    labels = c(\"Control\", \"Drug\")  # Label groups in the legend\n  ) +  \n  scale_color_discrete(\n    labels = c(\"Control\", \"Drug\")  # Ensure correct labeling of groups\n  ) +  \n  # scale_x_continuous(breaks = seq(0, 100, by = 20), expand = c(0, 0.01)) +  # X-axis breaks (commented out)\n  scale_y_continuous(\n    limits = c(0, 1),  # Ensure Y-axis covers full probability range\n    breaks = seq(0, 1, by = 0.2),  # Set Y-axis tick marks at 0, 0.2, ..., 1\n    expand = c(0, 0)  # Prevent extra padding on Y-axis\n  ) +  \n  theme_classic() +\n  theme(\n    legend.position = \"top\", # Move legend to the top\n    legend.key.width = unit(1, \"cm\"), # Make legend key longer\n    panel.grid.major.y = element_line(), # Add horizontal grid lines\n    legend.text = element_text(size = 10), # Increase legend text size\n    caption = element_text(size = 10)  # Increase caption text size\n  )\n\nggsave(\"images//rats_KM_gg2.png\", width = 7, height = 5)\nggsave(\"images//rats_KM_gg2.eps\", device = cairo_ps, width = 7, height = 5)\n\n##############################################\n# GBC study: Figure 3.7 and related test results \n#############################################\n#read in the complete data\ngbc &lt;- read.table(\"Data//German Breast Cancer Study//gbc.txt\")\n\n#subset to first event data\n#Sort the data by time within each id\no &lt;- order(gbc$id,gbc$time)\ngbc &lt;- gbc[o,]\n#get the first row for each id\ndata.CE &lt;- gbc[!duplicated(gbc$id),]\n\n#set status=1 if status==2 or 1\ndata.CE$status &lt;- (data.CE$status&gt;0)+0\n\n\n\n################################################\n# Figure 3.7  Plot the KM curves by hormonal group \n# stratified by menopausal status for GBC study\n################################################\n\npar(mfrow=c(1,3))\n## overall\nobj &lt;- survfit(Surv(time,status)~hormone,data=data.CE)\nplot(obj, xlim=c(0,80),lwd=2,frame=F, lty=c(2,1),\n     xlab=\"Time (months)\",ylab=\"Relaspe-free survival probabilities\",main=\"Overall\",\n     cex.lab=1.5,cex.axis=1.5,cex.main=1.5)\nlegend(1,0.2,lty=2:1,c(\"No Hormone\",\"Hormone\"),\n       lwd=2,cex=1.5)\n\n## pre-menopausal\nobj.pre &lt;- survfit(Surv(time,status)~hormone,data=data.CE[data.CE$meno==1,])\nplot(obj.pre, xlim=c(0,80),lwd=2,frame=F, lty=c(2,1),\n     xlab=\"Time (months)\",ylab=\"Relaspe-free survival probabilities\",main=\"Pre-Menopausal\",\n     cex.lab=1.5,cex.axis=1.5,cex.main=1.5)\nlegend(1,0.2,lty=2:1,c(\"No Hormone\",\"Hormone\"),\n       lwd=2,cex=1.5)\n\n## post-menopausal\nobj.post&lt;- survfit(Surv(time,status)~hormone,data=data.CE[data.CE$meno==2,])\nplot(obj.post, xlim=c(0,80),lwd=2,frame=F, lty=c(2,1),\n     xlab=\"Time (months)\",ylab=\"Relaspe-free survival probabilities\",main=\"Post-Menopausal\",\n     cex.lab=1.5,cex.axis=1.5,cex.main=1.5)\nlegend(1,0.2,lty=2:1,c(\"No Hormone\",\"Hormone\"),\n       lwd=2,cex=1.5)\n\n\n\n## Stratified log-rank test (by menopausal status)\nsurvdiff(Surv(time, status) ~ hormone + strata(meno),\n         data = data.CE)\n## Unstratified log-rank test\nsurvdiff(Surv(time, status) ~ hormone,\n         data = data.CE)"
  },
  {
    "objectID": "chapter4.html",
    "href": "chapter4.html",
    "title": "Chapter 4 - Cox Proportional Hazards Regression",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter4.html#slides",
    "href": "chapter4.html#slides",
    "title": "Chapter 4 - Cox Proportional Hazards Regression",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter4.html#base-r-code",
    "href": "chapter4.html#base-r-code",
    "title": "Chapter 4 - Cox Proportional Hazards Regression",
    "section": "Base R Code",
    "text": "Base R Code\n\n\nShow the code\n##################################################################\n# This code generates all numerical results in chapter 4.      ##\n##################################################################\n\n\n###################################################\n# Section 4.2.6 (Figure 4.2)                \n# Cox proportional hazards model on GBC study data\n###################################################\nlibrary(survival)\n##############################################\n# GBC study\n#############################################\n# read in the complete data\ngbc &lt;- read.table(\"Data//German Breast Cancer Study//gbc.txt\")\n\n# subset to first event data\n# Sort the data by time within each id\no &lt;- order(gbc$id,gbc$time)\ngbc &lt;- gbc[o,]\n# get the first row for each id\ndata.CE &lt;- gbc[!duplicated(gbc$id),]\n\n# set status=1 if status==2 or 1\ndata.CE$status &lt;- (data.CE$status&gt;0)+0\n\n\n# fit the Cox proportional hazards model\n## preparation\n\ndata.CE$hormone &lt;- factor(data.CE$hormone)\ndata.CE$meno &lt;- factor(data.CE$meno)\ndata.CE$grade &lt;- factor(data.CE$grade)\n  \nobj &lt;- coxph(Surv(time, status)~ hormone + meno + age + size + grade\n           + prog + estrg, data = data.CE)\n\n#summarize results\nsummary(obj)\n\n# Wald test on tumor grade\n# H_0: beta_5=beta_6=0\nbeta_q &lt;- obj$coefficients[5:6]\nSigma_q &lt;- obj$var[5:6,5:6]\n\n#chisq statistic with 2 d.f.\nchisq2 &lt;- t(beta_q) %*% solve(Sigma_q) %*% beta_q\n#p-value\npval &lt;- 1 - pchisq(chisq2, 2)\n\n\n### explore forest plot\nlibrary(survminer)\nggforest(obj, data = data.CE)\n####\n\n\n### Get the Breslow estimates of baseline\n### cumulative hazard function\nLambda0 &lt;- basehaz(obj,centered = FALSE)\n#plot the baseline hazard function\npar(mfrow=c(1,1))\nplot(stepfun(Lambda0$time,c(0,Lambda0$hazard)),\n     do.points=F,xlim=c(0,100),ylim=c(0,0.8),lwd=2,frame.plot=F, \n     xlab=\"Time (months)\",ylab=\"Baseline cumulative hazard function\", \n     main=\"\")\n\n\n\n\n\n############################\n# Residual analysis\n# (Figures 4.3--4.6)\n############################\n\n\n\n#####################################\n\n## First get the Cox-Snell residuals.;\n## The default residuals of coxph in R are the martingale residuals.\n## resid(obj,type=c(\"martingale\", \"deviance\", \"score\", \"schoenfeld\",\n##                   \"dfbeta\", \"dfbetas\", \"scaledsch\",\"partial\"))\n\n\n\n## Use relationship between cox-snell and martingal\n## residuals\n\ncoxsnellres &lt;- data.CE$status-resid(obj, type=\"martingale\")\n## Then use N-A method to estimate the cumulative \n## hazard function for residuals;\nfit &lt;- survfit(Surv(coxsnellres,data.CE$status) ~ 1)\nHtilde &lt;- cumsum(fit$n.event/fit$n.risk)\nplot(log(fit$time),log(Htilde), xlab=\"log(t)\", frame.plot = FALSE,\n     ylab=\"log-cumulative hazard\", xlim = c(-8, 2), ylim = c(-8, 2))\nabline(0, 1, lty = 3, lwd = 1.5)\n\n\n# rescaled Schoelfeld residuals\nsch &lt;- cox.zph(obj) \n\n# chi-square test results for proportionality\n# of each covariate and overall\nsch$table\n\n### calculated residuals ###\nsch_time &lt;- sch$time # the X_i's (m-vector)\nsch_resids &lt;-  sch$y # rescaled residuals (m x p matrix)\n\n# Plot rescaled Schoelfeld residuals for each covariate\n# using the object sch directly\npar(mar = c(4, 4, 2, 2), mfrow=c(4,2))\nplot(sch, xlab=\"Time (months)\", lwd=2, cex.lab=1.2, cex.axis=1.2,\n     ylab = c(\"Hormone\", \"Menopause\", \"Age\", \"Tumor size\",\n               \"Tumor grade\", \"Progesterone\", \"Estrogen\"))\n\n## an alternative graphic provided in survminer package\n# ggcoxzph(sch)\n\n\n# To address non-proportionality of tumor grade\n# re-fit the Cox proportional hazards model\n# stratified by tumor grade\nobj.stra &lt;- coxph(Surv(time, status) ~ hormone + meno\n         + age + size + prog + estrg + strata(grade), data = data.CE)\n#Schoelfeld\n#produce proportionality test results\nsch.stra &lt;- cox.zph(obj.stra) \nround(sch.stra$table, 4)\n\n## residual plots for stratified model\npar(mfrow=c(3,2))\nplot(sch.stra, xlab=\"Time (months)\", lwd=2, cex.lab=1.2, cex.axis=1.2,\n     ylab = c(\"Hormone\", \"Menopause\", \"Age\", \"Tumor size\",\n              \"Progesterone\", \"Estrogen\"))\n\n\n\n## Martingale residuals\nmart_resid &lt;- resid(obj.stra,type = 'martingale')\n## Deviance residuals\ndev_resid &lt;- resid(obj.stra,type = 'deviance')\n\n\n#plot the martingale residuals against\n# the fours quantitative covariates:\n# age, tumor size, progesterone and\n# estrogen receptor levels\n\n## Age\npar(mfrow=c(2,2))\nplot(data.CE$age, mart_resid,\n     xlab=\"Age (years)\", ylab=\"Martingale residuals\",\n     main='Age',cex.lab=1.2,cex.axis=1.2)\nlines(lowess(data.CE$age, mart_resid), lwd = 2)\nabline(0,0,lty=3,lwd=2)\n\n## Tumor size\nplot(data.CE$size, mart_resid,\n     xlab=\"Tumor size (mm)\", ylab=\"Martingale residuals\",\n     main='Tumor size',cex.lab=1.2,cex.axis=1.2)\nlines(lowess(data.CE$size, mart_resid),lwd=2)\nabline(0,0,lty=3,lwd=2)\n\n## Progesterone\nplot(data.CE$prog, mart_resid,\n     xlab=\"Progesterone receptor (fmol/mg)\", ylab=\"Martingale Residuals\",\n     main='Progesterone',cex.lab=1.2,cex.axis=1.2)\nlines(lowess(data.CE$prog, mart_resid),lwd=2)\nabline(0,0,lty=3,lwd=2)\n\n\n## Estrogen\nplot(data.CE$estrg, mart_resid,\n     xlab=\"Estrogen receptor (fmol/mg)\", ylab=\"Martingale Residuals\",\n     main='Estrogen',cex.lab=1.2,cex.axis=1.2)\nlines(lowess(data.CE$estrg, mart_resid),lwd=2)\nabline(0,0,lty=3,lwd=2)\n\n\n# To address non-linear age\n# categorize age in agec\n# age&lt;=40: agec=1\n# 40&lt;age&lt;=60: agec=2\n# age&gt;60: agec=3\ndata.CE$agec &lt;- (data.CE$age&lt;=40)+2*(data.CE$age&gt;40&data.CE$age&lt;=60)+\n    3*(data.CE$age&gt;60)\ndata.CE$agec &lt;- factor(data.CE$agec)\n\n\n#re-fit the model with agec\nobj.stra.final &lt;- coxph(Surv(time,status)~ hormone + meno\n               + agec + size + prog + estrg + strata(grade), data = data.CE)\n\n\n#plot the estimated HRs for agec (Figure 4.6)\n# and confidence intervals\nfinal.sum &lt;- summary(obj.stra.final)\nfinal.sum\n\n\n# Plot the age-group-specific HR and confidence\n# intervals from the re-fitted model\nci.table=final.sum$conf.int\nhr=ci.table[3:4,1]\nhr.low=ci.table[3:4,3]\nhr.up=ci.table[3:4,4]\n\npar(mfrow=c(1,1))\nplot(1:3,c(1,hr),ylim=c(0,1.2),frame=F,xaxt='n',\n     xlab=\"Age (years)\", ylab=\"Hazard ratio\",pch=19,cex=1.5,cex.lab=1.2,\n     cex.axis=1.2)\naxis(1, at=c(1,2,3),labels=c(\"(20, 40]\",\"(40, 60]\",\"(60, 80]\"),cex.axis=1.2)\n# horizontal error bars\narrows(2:3, hr.low, 2:3, hr.up, length=0.05, angle=90, code=3,lwd=2)\nlines(1:3,c(1,hr),lty=3,lwd=2)\n\n\n\n\n###########################################\n# Illustration with time-varying covariates\n# Stanford heart study\n###########################################\nhead(heart)\n## change variable name \"year\" -&gt; \"accpt\"\ncolnames(heart)[5] &lt;- \"accpt\"\n\n#sample size\nn &lt;- length(unique(heart$id))\n\n# fit a Cox model with time-dependent \"transplant\"\nobj &lt;- coxph(Surv(start, stop, event) ~ age + accpt + surgery + transplant, data=heart)\n#summarize results\nsummary(obj)"
  },
  {
    "objectID": "chapter6.html",
    "href": "chapter6.html",
    "title": "Chapter 6 - Sample Size Calculation and Study Design",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter6.html#slides",
    "href": "chapter6.html#slides",
    "title": "Chapter 6 - Sample Size Calculation and Study Design",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter6.html#base-r-code",
    "href": "chapter6.html#base-r-code",
    "title": "Chapter 6 - Sample Size Calculation and Study Design",
    "section": "Base R Code",
    "text": "Base R Code\n\n\nShow the code\n##################################################################\n# This code generates all numerical results in chapter 6.      ##\n##################################################################\n\n\n################################################################\n# Part I. Compile functions needed for sample size calculation #\n################################################################\n\n\n###########################################\n# Compile the following code for function\n# psi_fun(lambda0,lambdaL,b, c)\n# which computes the event proportion psi\n# needed for sample size calculation for\n# Cox model\n# INPUT: lambda0 = hazard rate for T\n#        lambdaL = hazard rate for LTFU\n#        b = length of accrual\n#        c = additional length of follow-up\n##########################################\n\npsi_fun &lt;- function(lambda0, lambdaL, b, c){\n        lambda &lt;- lambda0 + lambdaL\n   psi &lt;- lambda0 / lambda * (1 - exp(- lambda * c) * (1 - exp(- lambda * b)) / (lambda * b))\n   return(psi)\n}\n\n\n\n###########################################\n# Compile the following code for function\n# zeta_fun(tau,lambda0,lambdaL,b, c)\n# which computes the RMST variance\n# needed for sample size calculation.\n# INPUT: tau = restricting time\n#       lambda0 = hazard rate for T\n#       lambdaL = hazard rate for LTFU\n#       b = length of accural\n#       c = additional length of follow-up\n##########################################\n\n## Survival function for censoring\nGfun &lt;- function(t, lambdaL, b, c){\n  Gt &lt;- ifelse(t &lt;= c, exp(- lambdaL * t),\n    ifelse(t &lt; c + b, exp(- lambdaL * t) * (b + c -t ) / b, 0))\n  return(Gt)\n}\n\n## The integrand of zeta\nzeta_integrand &lt;- function(t, tau, lambda0,lambdaL, b, c){\n  integrand &lt;- (exp(- lambda0 * t) - exp( - lambda0 * tau))^2*\n      exp(lambda0 * t)/(Gfun(t, lambdaL, b, c) * lambda0)\n  return(integrand)\n}\n\n## Use the integrate() for numerical integration\n# ?integrate\nzeta_fun &lt;- function(tau, lambda0, lambdaL, b, c){\n  f &lt;- function(t){\n   return(zeta_integrand(t, tau, lambda0, lambdaL, b, c))\n  }\n  zeta &lt;- integrate(f, lower = 0, upper = tau)\n  return(zeta$value)\n}\n\n\n\n################################################################\n# Part II. Generate the numerical results in Section 6.2.2     #\n################################################################\n\n\nzeta_fun(tau=5,lambda0=0.2,lambdaL=0.01,b=2,c=4)\n\n\n\nlibrary(survival)\n\n##############################################\n# GBC study\n#############################################\n#read in the complete data\ngbc &lt;- read.table(\"Data//German Breast Cancer Study//gbc.txt\")\n\n#subset to first event data\n#Sort the data by time within each id\no &lt;- order(gbc$id,gbc$time)\ngbc &lt;- gbc[o,]\n#get the first row for each id\ndata.CE &lt;- gbc[!duplicated(gbc$id),]\n\n#set status=1 if status==2 or 1\ndata.CE$status &lt;- (data.CE$status&gt;0)+0\n\n## restrict to the subgroup of post-menopausal\n## women with no hormonal treatment\n\npilot &lt;- data.CE[data.CE$meno==2&data.CE$hormone==1,]\nn &lt;- nrow(pilot)\n## n=209, consistent with the # in Table 1.1 of Chapter 1\n\n# calculate the event rate\n# convert time from month to year\npilot$time &lt;- pilot$time/12\nlambda0 &lt;- sum(pilot$status&gt;0)/sum(pilot$time)\n# lambda0=0.174\n\n### Design for the new study\n# Accrual period: b=2 years\n# Additional follow-up: c=3.5 years\n# LTFU rate: lambda=0.01 per year. \nlambdaL &lt;- 0.01\nb &lt;- 2\nc &lt;- 3.5 \n\n# calculate the parameters psi and zeta(tau=3, 5)\npsi &lt;- psi_fun(lambda0,lambdaL,b, c)\nzeta3 &lt;- zeta_fun(tau=3,lambda0,lambdaL,b, c)\nzeta5 &lt;- zeta_fun(tau=5,lambda0,lambdaL,b, c)\n\n\n# Hypothetical treatment group\n# A spectrum of hypothetical hazard ratios\nHR &lt;- seq(0.6,0.9,by=0.01)\n# log(HR) is the effect size for Cox model\n\n# Hazard rate in the treatment\nlambda1 &lt;- lambda0*HR\n## Function to compute the corresponding effect size in RMST\n## based on the exponential distribution\nRMST_diff &lt;- function(tau,lambda0,lambda1){\n     return(lambda1^{-1}*(1-exp(-lambda1*tau))-lambda0^{-1}*(1-exp(-lambda0*tau)))\n}\n\n## for tau=3 and 5.\ntheta3 &lt;- RMST_diff(tau=3,lambda0,lambda1)\ntheta5 &lt;- RMST_diff(tau=5,lambda0,lambda1)\n\n# Sample size calculation for q=1/2 and alpha=0.05\nq &lt;- 0.5\nza &lt;- qnorm(0.975)\n# Power=0.8, 0.9\ngamma_list &lt;- c(0.8,0.9)\n\n# For each gamma, compute the sample size needed \n# for log-rank test and RMST tests\n# as a function of HR\n\npar(mfrow=c(1,2))\n\nfor (i in 1:2){\n   gamma &lt;- gamma_list[i]\n   zg &lt;- qnorm(gamma)\n   \n   # n for log-rank, 3-RMST, and 5-RMST\n   ncox &lt;- (za+zg)^2/(q*(1-q)*psi*log(HR)^2)\n   nRMST3 &lt;- zeta3*(za+zg)^2/(q*(1-q)*theta3^2)\n   nRMST5 &lt;- zeta5*(za+zg)^2/(q*(1-q)*theta5^2)\n   \n   plot(HR,ncox,type=\"l\",lwd=2,ylim=c(0,7000),ylab=\"Sample size\",\n        xlab=\"Hazard ratio\", main=paste0(\"Power = \",gamma),\n        cex.lab=1.2,cex.axis=1.2)\n   lines(HR,nRMST5,lty=2,lwd=2)\n   lines(HR,nRMST3,lty=3,lwd=2)\n   legend(\"topleft\",lty=1:3,c(\"Log-rank\",\"5-RMST\",\"3-RMST\"),lwd=2,\n          cex=1.2)\n}\n\n## sample sizes at HR=0.8 and power=0.9\n\nncox[HR==0.8]\nnRMST3[HR==0.8]\nnRMST5[HR==0.8]"
  },
  {
    "objectID": "chapter8.html",
    "href": "chapter8.html",
    "title": "Chapter 8 - Multivariate Failure Times",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter8.html#slides",
    "href": "chapter8.html#slides",
    "title": "Chapter 8 - Multivariate Failure Times",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter8.html#base-r-code",
    "href": "chapter8.html#base-r-code",
    "title": "Chapter 8 - Multivariate Failure Times",
    "section": "Base R Code",
    "text": "Base R Code\n\n\nShow the code\n##################################################################\n# This code generates all numerical results in chapter 8.      ##\n##################################################################\n\nlibrary(\"survival\")\n\n################################\n# NCCTG lung cancer study      #\n################################\n\n## read in the NCCTG lung cancer study\n## (clustered data by institution)\ndata &lt;- read.table(\"Data//NCCTG//lung.txt\")\nhead(data)\n\n\n\n\n## Follow up plot\nlibrary(tidyverse)\nlibrary(patchwork)\n\n# function to plot follow-up by\n# institution and sex\ninst_by_sex_fu_plot &lt;- function(df){\n  \n  df |&gt; \n  ggplot(aes(y = reorder(id, time), x = time, color = factor(2 - sex))) +\n  geom_linerange(aes(xmin = 0, xmax = time)) +\n  geom_point(aes(shape = factor(status)), size = 2, fill = \"white\") +\n  geom_vline(xintercept = 0, linewidth = 1) +\n  facet_grid(inst ~ ., scales = \"free\", space = \"free\", switch = \"y\")   +\n  theme_minimal() +\n  scale_x_continuous(\"Time (months)\", limits = c(0, 36), breaks = seq(0, 36, by = 12),\n                     expand = c(0, 0.25)) +\n  scale_y_discrete(\"Patients (by institution)\") +\n  scale_shape_manual(values = c(23, 19), labels = c(\"Censoring\", \"Death\")) +\n  scale_color_brewer(palette = \"Set1\", labels = c(\"Female\", \"Male\"))+\n  theme(\n    strip.background =  element_rect(fill = \"gray90\", color = \"gray90\"),\n    axis.text.y = element_blank(),\n    axis.ticks.y = element_blank(),\n    axis.line.y = element_blank(),\n    panel.grid.major.y = element_blank(),\n    legend.title = element_blank()\n  )\n  \n}\n\np1 &lt;- inst_by_sex_fu_plot(data |&gt; filter(inst &lt;= 11))\n\np2 &lt;- inst_by_sex_fu_plot(data |&gt; filter(inst &gt; 11))\n\nmul_lung_fu &lt;- p1 + p2 + plot_layout(ncol = 2, guides = \"collect\") & theme(legend.position = \"top\")\n\n# ggsave(\"mul_lung_fu.pdf\", mul_lung_fu, width = 8, height = 10)\n# ggsave(\"mul_lung_fu.eps\", mul_lung_fu, width = 8, height = 10)\n\n\n# Fit a Cox model with institution-specific frailty\n# to account for correlation within institution\nobj &lt;- coxph(Surv(time, status) ~ age+ factor(sex) + phec + phkn + ptkn +\n        wl + frailty(inst, distribution=\"gamma\"), data = data)\n\nsummary(obj)\n\n# fit a naive Cox model without institution-specific frailty\nobj.naive &lt;- coxph(Surv(time,status)~age+factor(sex)+phec+phkn+ptkn +\n                           wl,data=data)\n\nsummary(obj.naive)\n\n\n####################################################\n#  Prediction of subject-specific survival curves\n#  \n################################################\n\n# Median age\nmed_age &lt;- median(data$age)\n# Median ph.karno\nmed_phkn &lt;- median(data$phkn,na.rm=T)\n# Median pat.karno\nmed_ptkn &lt;- median(data$ptkn,na.rm=T)\n# Median wt.loss\nmed_wl &lt;- median(data$wl,na.rm=T)\n\n# Extract the regression coefficients\nbeta &lt;- obj$coefficients\n# Extract the (only) baseline function\nbase_obj &lt;- basehaz(obj,centered=F)\neta &lt;- base_obj$hazard\nt &lt;- base_obj$time\n\n\n# Figure 8.2 Prediction of survival probabilities for a typical patient \n# of median age (63 years), with median physician-\n#         and patient-rated Karnofsky scores (each 80), and with median\n# weighted loss (7 pounds) by sex and ECOG score.\n\n# Obtain the covariate profiles.\n## Female\nzf0 &lt;- c(med_age,1,0,med_phkn,med_ptkn,med_wl)\nzf1 &lt;- c(med_age,1,1,med_phkn,med_ptkn,med_wl)                              \nzf2 &lt;- c(med_age,1,2,med_phkn,med_ptkn,med_wl) \nzf3 &lt;- c(med_age,1,3,med_phkn,med_ptkn,med_wl) \n\n## Male\nzm0 &lt;- c(med_age,0,0,med_phkn,med_ptkn,med_wl)\nzm1 &lt;- c(med_age,0,1,med_phkn,med_ptkn,med_wl)                              \nzm2 &lt;- c(med_age,0,2,med_phkn,med_ptkn,med_wl) \nzm3 &lt;- c(med_age,0,3,med_phkn,med_ptkn,med_wl) \n\n# Plot the preducted survival curves\npar(mfrow=c(1,2))\nplot(t,exp(-exp(sum(beta*zf0))*eta),type=\"s\",xlim=c(0,35),\n     ylim=c(0,1),frame=F,lty=1,main=\"Female\",\n     xlab=\"Time (months)\",ylab=\"Survival probabilities\",lwd=2,cex.lab=1.3,\n     cex.axis=1.3,cex.main=1.3)\nlines(t,exp(-exp(sum(beta*zf1))*eta),lty=2,lwd=2)\nlines(t,exp(-exp(sum(beta*zf2))*eta),lty=3,lwd=2)\nlines(t,exp(-exp(sum(beta*zf3))*eta),lty=4,lwd=2)\nlegend(\"topright\",lty=1:4,lwd=2,cex=1.2,paste(\"ECOG\",0:3))\n\nplot(t,exp(-exp(sum(beta*zm0))*eta),type=\"s\",xlim=c(0,35),\n     ylim=c(0,1),frame=F,lty=1,main=\"Male\",\n     xlab=\"Time (months)\",ylab=\"Survival probabilities\",lwd=2,cex.lab=1.3,\n     cex.axis=1.3,cex.main=1.3)\nlines(t,exp(-exp(sum(beta*zm1))*eta),lty=2,lwd=2)\nlines(t,exp(-exp(sum(beta*zm2))*eta),lty=3,lwd=2)\nlines(t,exp(-exp(sum(beta*zm3))*eta),lty=4,lwd=2)\nlegend(\"topright\",lty=1:4,lwd=2,cex=1.2,paste(\"ECOG\",0:3))\n\n\n\n################################\n# Diabetic retinopathy study   #\n################################\n\n# read in the data\ndata &lt;- read.table(\"Data//Diabetic Retinopathy Study//drs.txt\")\nhead(data)\n\n# fit a bivariate marginal Cox model\n# with treatment, diabetic type\n# risk score, and treatment*type interaction\n# as covariates\nobj &lt;- coxph(Surv(time, status) ~ trt + type + trt * type + risk\n             + cluster(id), data = data)\n\nsummary(obj)\n\n# Table 8.1 Marginal Cox model analysis of the Diabetic Retinopathy Study\n# output table\ncoeff &lt;- summary(obj)$coeff\n# beta estimate\nc1 &lt;- coeff[,1]\n# robust se and p-value\nc2 &lt;- coeff[,4]\nc3 &lt;- coeff[,6]\n# naive se and p-value\nc4 &lt;- coeff[,3]\nc5 &lt;- 1-pchisq((c1/c4)^2,1)\n\n#output the table\nnoquote(round(cbind(c1,c2,c3,c4,c5),3))\n\n\n\n# Fig. 8.4 Prediction of vision-retention probabilities \n# for patients with a median risk\n# score (10) by treatment for each diabetic type.\n\n# Lambda_0(t) and t\nLt &lt;- basehaz(obj,centered = F)\nt &lt;- Lt$time\nL &lt;- Lt$hazard\n\n# beta\nbeta &lt;- coeff[,1]\n\n# plot the predicted survival functions\n\npar(mfrow=c(1,2))\n# Compute the survival function for \n# adult and juvenile patients in control and treatment\nadult.contr &lt;- exp(-exp(sum(beta*c(0,0,10,0)))*L)\nadult.trt &lt;- exp(-exp(sum(beta*c(1,0,10,0)))*L)\njuv.contr &lt;- exp(-exp(sum(beta*c(0,1,10,0)))*L)\njuv.trt &lt;- exp(-exp(sum(beta*c(1,1,10,1)))*L)\n\n# Plot the predicted survival curves\nplot(t,adult.contr,type=\"s\",xlim=c(0,80),ylim=c(0,1),frame.plot=F,lty=3,main=\"Adult\",\n     xlab=\"Time (months)\",ylab=\"Vision-retention probabilities\",lwd=2, cex.lab=1.2,\n     cex.axis=1.2,cex.main=1.2)\nlines(t,adult.trt,lty=1,lwd=2)\n\nplot(t,juv.contr,type=\"s\",xlim=c(0,80),ylim=c(0,1),frame.plot=F,lty=3,main=\"Juvenile\",\n     xlab=\"Time (months)\",ylab=\"Vision-retention probabilities\",lwd=2,cex.lab=1.2,\n     cex.axis=1.2,cex.main=1.2)\nlines(t,juv.trt,lty=1,lwd=2)"
  },
  {
    "objectID": "chapter8.html#descriptive-analysis-of-topcat-trial",
    "href": "chapter8.html#descriptive-analysis-of-topcat-trial",
    "title": "Chapter 8 - Multivariate Failure Times",
    "section": "Descriptive analysis of TOPCAT trial",
    "text": "Descriptive analysis of TOPCAT trial\n\nlibrary(survival)\nlibrary(tidyverse)\nlibrary(knitr)\n\n##########################\n#   TOPCAT               #\n##########################\n\n# read in the data\ntopcat &lt;- read.table(\"Data//TOPCAT//topcat.txt\")\n# head(topcat)\n\n# median follow-up\ntopcat |&gt; \n  group_by(id) |&gt; \n  slice_max(time) |&gt; \n  slice_head() |&gt; \n  ungroup() |&gt; \n  summarize(\n    median(time)\n  )\n\n# A tibble: 1 × 1\n  `median(time)`\n           &lt;dbl&gt;\n1           3.55\n\n# table(topcat$drug)\n# table(topcat$race)\n\n# topcat |&gt; \n#   count(endpoint, status)\n\n\n# Descriptive analysis ----------------------------------------------------\n\n## clean up data\n\ntmp &lt;- topcat |&gt; \n  mutate( # clean up the levels of drug, gender\n    drug = if_else(drug == \"Spiro\", \"Spironolactone\", \"Placebo\"),\n    gender = if_else(gender == \"1:Male\", \"Male\", \"Female\")\n  ) \n  \n## de-duplicate\ndf &lt;- tmp |&gt; \n  pivot_wider( # flatten endpoints\n    id_cols = id,\n    # names_prefix = c(time, status),\n    names_from = endpoint,\n    values_from = c(time, status),\n  ) |&gt; # join with baseline data\n  left_join(\n    tmp |&gt; filter(endpoint == \"HF\"),\n    join_by(id)\n  )\n\n## a function to compute median (IQR) for x\n## rounded to the rth decimal place\nmed_iqr &lt;- function(x, r = 1){\n  qt &lt;- quantile(x, na.rm = TRUE)\n  \n  str_c(round(qt[3], r), \" (\", \n        round(qt[2], r), \", \",\n        round(qt[4], r), \")\")\n}\n\n# create summary table for quantitative variables\n# age, size, nodes, prog, estrg\ntab_quant &lt;- df |&gt; \n  filter(endpoint == \"HF\") |&gt; \n  group_by(drug) |&gt; \n  summarize(\n    across(c(age,  bmi, hr), med_iqr)\n  ) |&gt; \n  pivot_longer( # long format: value = median (IQR); name = variable names\n    !drug,\n    values_to = \"value\",\n    names_to = \"name\"\n  ) |&gt; \n  pivot_wider( # wide format: name = variable names; hormone levels as columns\n    values_from = value,\n    names_from = drug\n  ) |&gt; \n  mutate(\n    name = case_when( # format the variable names\n      name == \"age\" ~ \"Age (years)\",\n      name == \"bmi\" ~ \"BMI (kg/m^2)\",\n      name == \"hr\" ~ \"Heart rate (per min)\"\n    )\n  )\n\n## a function that computes N (%) for each level of var\n## by group in data frame df (percent rounded to rth point)\nfreq_pct&lt;- function(df, group, var, r = 1){\n  # compute the N for each level of var by group\n  var_counts &lt;- df |&gt; \n    group_by({{ group }}, {{ var }}) |&gt; \n    summarize(\n      n = n(),\n      .groups = \"drop\"\n    ) \n  # compute N (%)\n  var_counts |&gt; \n    left_join( # compute the total number (demoninator) in each group\n      # and joint it back to the numerator\n      var_counts |&gt; group_by({{ group }}) |&gt; summarize(N = sum(n)),\n      by = join_by({{ group }})\n    ) |&gt; \n    mutate( # N (%)\n      value = str_c(n, \" (\", round(100 * n / N, r), \"%)\")\n    ) |&gt; \n    select(- c(n, N)) |&gt; \n    pivot_wider( # put group levels on columns\n      names_from = {{ group }},\n      values_from = value\n    ) |&gt; \n    rename(\n      name = {{ var }} # name = variable names \n    )\n}\n\n## gender\ngender &lt;- df |&gt;\n  freq_pct(drug, gender) |&gt; \n  mutate(\n    name = str_c(\"Gender - \", name)\n  )\n## race\nrace &lt;- df |&gt;\n  freq_pct(drug, race) |&gt; \n  mutate(\n    name = str_c(\"Race - \", name)\n  )\n## nyha\nnyha &lt;- df |&gt;\n  freq_pct(drug, nyha) |&gt; \n  mutate(\n    name = str_c(\"NYHA - \", name)\n  ) |&gt; \n  filter(!is.na(name))\n\n\n\n\n## function to compute N (%) for binary condition\nbin_pct &lt;- function(condition, r = 1){\n  n &lt;- sum(condition, na.rm = TRUE)\n  N &lt;- n()\n  str_c(n, \" (\", round(100 * n / N, r), \"%)\")\n}\n\n## tabulate binary variables, including number of endpoints\ntabin &lt;- df |&gt; \n  group_by(drug) |&gt; \n  summarize(\n    N = n(),\n    across(c(smoke:cabg, status_HF, status_MI, status_Stroke), bin_pct)\n  ) |&gt; \n  select(!N) |&gt; \n  pivot_longer( # long format: value = median (IQR); name = variable names\n    !drug,\n    values_to = \"value\",\n    names_to = \"name\"\n  ) |&gt; \n  pivot_wider( # wide format: name = variable names; hormone levels as columns\n    values_from = value,\n    names_from = drug\n  ) |&gt; \n  mutate(\n      name = case_when( # format the variable names\n      name == \"smoke\" ~ \"Smoker\",\n      name == \"chf_hosp\" ~ \"CHF\",\n      name == \"copd\" ~ \"COPD\",\n      name == \"asthma\" ~ \"Asthma\",\n      name == \"dm\" ~ \"Diabetes\",\n      name == \"htn\" ~ \"Hypertension\",\n      name == \"cabg\" ~ \"Coronary surgery\",\n      name == \"status_HF\" ~ \"HF\",\n      name == \"status_MI\" ~ \"MI\",\n      name == \"status_Stroke\" ~ \"Stroke\"\n    )\n  )\n\n## tabulate event rates\nevent_rates &lt;- df |&gt; \n  group_by(drug) |&gt; \n  summarize(\n    `HF rate (per person-year)` = sum(status_HF) / sum(time_HF),\n    `MI rate (per person-year)` = sum(status_MI) / sum(time_MI),\n    `Stroke rate (per person-year)` = sum(status_Stroke) / sum(time_Stroke)\n  ) |&gt; \n  pivot_longer( # long format: value = median (IQR); name = variable names\n    !drug,\n    values_to = \"value\",\n    names_to = \"name\"\n  ) |&gt; \n  pivot_wider( # wide format: name = variable names; hormone levels as columns\n    values_from = value,\n    names_from = drug\n  ) |&gt; \n  mutate(\n    Placebo = as.character(round(Placebo, 4)),\n    Spironolactone = as.character(round(Spironolactone, 4))\n  )\n\n\n## combine tables\n\ntabone &lt;- bind_rows(\n  tab_quant[1, ],\n  gender,\n  race,\n  nyha,\n  tab_quant[- 1, ],\n  tabin,\n  event_rates\n)\n\n## add N to group names  \ncolnames(tabone) &lt;- c(\" \", str_c(colnames(tabone)[2:3], \" (N=\", table(df$drug),\")\"))\n## print out the table\nkable(tabone)\n\n\n\n\n\n\n\n\n\n\nPlacebo (N=1446)\nSpironolactone (N=1465)\n\n\n\n\nAge (years)\n68 (60, 74)\n68 (60, 75)\n\n\nGender - Female\n763 (52.8%)\n790 (53.9%)\n\n\nGender - Male\n683 (47.2%)\n675 (46.1%)\n\n\nRace - Caucasian\n1422 (98.3%)\n1432 (97.7%)\n\n\nRace - Other\n24 (1.7%)\n33 (2.3%)\n\n\nNYHA - 1-2\n993 (68.7%)\n1003 (68.5%)\n\n\nNYHA - 3-4\n451 (31.2%)\n461 (31.5%)\n\n\nBMI (kg/m^2)\n30.8 (27.2, 35.6)\n31.1 (27.3, 35.6)\n\n\nHeart rate (per min)\n68 (61.2, 76)\n68 (61, 75)\n\n\nSmoker\n154 (10.7%)\n146 (10%)\n\n\nCHF\n1057 (73.1%)\n1057 (72.2%)\n\n\nCOPD\n152 (10.5%)\n166 (11.3%)\n\n\nAsthma\n84 (5.8%)\n93 (6.3%)\n\n\nDiabetes\n439 (30.4%)\n456 (31.1%)\n\n\nHypertension\n1335 (92.3%)\n1336 (91.2%)\n\n\nCoronary surgery\n173 (12%)\n171 (11.7%)\n\n\nHF\n147 (10.2%)\n127 (8.7%)\n\n\nMI\n40 (2.8%)\n44 (3%)\n\n\nStroke\n36 (2.5%)\n29 (2%)\n\n\nHF rate (per person-year)\n0.0303\n0.0255\n\n\nMI rate (per person-year)\n0.0079\n0.0086\n\n\nStroke rate (per person-year)\n0.0071\n0.0056"
  },
  {
    "objectID": "chapter9.html",
    "href": "chapter9.html",
    "title": "Chapter 9 - Recurrent Events",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter9.html#slides",
    "href": "chapter9.html#slides",
    "title": "Chapter 9 - Recurrent Events",
    "section": "",
    "text": "Lecture slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter9.html#base-r-code",
    "href": "chapter9.html#base-r-code",
    "title": "Chapter 9 - Recurrent Events",
    "section": "Base R Code",
    "text": "Base R Code\n\n\nShow the code\n##################################################################\n# This code generates all numerical results in chapter 9.       ##\n##################################################################\n\n\n\nlibrary(survival)\n\n# read in the cgd dataset in counting process format\ncgd &lt;- read.table(\"Data\\\\Chronic Granulomatous Disease Study\\\\cgd_counting.txt\")\nhead(cgd)\n\n\n# Andersen-Gill model\nobj.AG &lt;- coxph(Surv(tstart, tstop, status) ~ treat + sex + age + inherit + steroids +\n                 propylac, data = cgd)\nsummary(obj.AG)\n\n# Frailty model\nobj.frail &lt;- coxph(Surv(tstart, tstop, status) ~ treat + sex + age + inherit + steroids +\n                    propylac + frailty(id, distribution = \"gamma\"), data = cgd)\n\nsummary(obj.frail)\n\n\n# proportional mean model (LWYY)\nobj.pm &lt;- coxph(Surv(tstart, tstop, status) ~ treat + sex + age + inherit + steroids +\n                 propylac + cluster(id), data = cgd)\n\nsummary(obj.pm)\n\n\n# extract the beta's from the three models\ncoeff.AG &lt;- summary(obj.AG)$coeff\ncoeff.frail &lt;- summary(obj.frail)$coeff\ncoeff.pm &lt;- summary(obj.pm)$coeff\n\n\n#########################################\n# Table 9.1. beta, se(beta), and p-vaues\n# from the three models\n#########################################\n\n## Andersen-Gill model\nc1 &lt;- coeff.AG[,1]\nc2 &lt;- coeff.AG[,3]\nc3 &lt;- coeff.AG[,5]\n\n# Frailty model\nc4 &lt;- coeff.frail[1:6,1]\nc5 &lt;- coeff.frail[1:6,2]\nc6 &lt;- coeff.frail[1:6,6]\n\n# Proportional means model\nc7 &lt;- coeff.pm[1:6,1]\nc8 &lt;- coeff.pm[1:6,4]\nc9 &lt;- coeff.pm[1:6,6]\n\n#print out Table 9.1\nnoquote(round(cbind(c1,c2,c3,c4,c5,c6,c7,c8,c9),3))\n\n\n### Figure 9.2 #############################################\n# predicted  mean functions by treatment\n# for a female/male patient of 12 years old with X-linked \n# inheritance pattern and use of both steroids and \n#  prophylactic antibiotics\n############################################################\n\n# get beta\nbeta &lt;- obj.pm$coeff\n\n# get baseline mean function mu_0(t)\n# and t\nLt &lt;- basehaz(obj.pm,centered = F)\nt &lt;- Lt$time\nmu0 &lt;- Lt$hazard\n\n# covariate vector (besides treatement) for female patient\nzf &lt;- c(0,12,1,1,1)\n# covariate vector (besides treatement) for male patient\nzm &lt;- c(1,12,1,1,1)\n\n# female in treatment and control\nmu.f.trt &lt;- exp(sum(c(1,zf)*beta))*mu0\nmu.f.contr &lt;- exp(sum(c(0,zf)*beta))*mu0\n\n# male in treatment and control\nmu.m.trt &lt;- exp(sum(c(1,zm)*beta))*mu0\nmu.m.contr &lt;- exp(sum(c(0,zm)*beta))*mu0\n\n# Plot the figure\npar(mfrow=c(1,2))\n\n# for female (left panel)\nplot(t/30.5, mu.f.trt, type=\"s\",xlim=c(0, 12), ylim=c(0,6),frame.plot =F,lty=1, main=\"Female\",\n     xlab=\"Time (months)\",ylab = \"Mean number of infections\", lwd=2)\nlines(t/30.5,mu.f.contr,lty=3,lwd=2)\n\n#for male (right panel)\nplot(t/30.5, mu.m.trt, type=\"s\", xlim=c(0, 12), ylim=c(0,6),frame.plot =F,lty=1,main=\"Male\",\n     xlab=\"Time (months)\",ylab = \"Mean number of infections\",lwd=2)\nlines(t/30.5,mu.m.contr,lty=3,lwd=2)"
  },
  {
    "objectID": "index.knit.html",
    "href": "index.knit.html",
    "title": "quarto",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2\n\n\n\ntest"
  },
  {
    "objectID": "rmtif.html",
    "href": "rmtif.html",
    "title": "Retricted mean time in favor of treatment",
    "section": "",
    "text": "This is a talk I give at the 2024 Duke Industry Statistics Symposium (DISS) on April 4th, 2024 in Durham, NC.\nTalk slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)\nAnother talk on October 22nd, 2024 in the Department of Statistics and Actuarial Science at the University of Waterloo."
  },
  {
    "objectID": "wa_estimands.html",
    "href": "wa_estimands.html",
    "title": "While-alive estimands for recurrent events in presence of death",
    "section": "",
    "text": "This is a talk I give at the 2024 Society for Clinical Trials Annual Meeting on May 21st, 2024 in Boston, MA.\nTalk slides here. (To convert html to pdf, press E \\(\\to\\) Print \\(\\to\\) Destination: Save to pdf)"
  },
  {
    "objectID": "chapter2.html#summary",
    "href": "chapter2.html#summary",
    "title": "Chapter 2 - Mathematical Foundations",
    "section": "Summary",
    "text": "Summary\nThe chapter establishes the foundations of survival analysis, focusing on the representation of time-to-event data, handling of censored observations, and development of key quantities, models, and methods.\n\nFull Outcome Data\nAn event time (T) is described as a random variable, with the survival function (S(t) = (T &gt; t)) representing the probability of surviving beyond time (t), and the hazard function ((t)) quantifying the instantaneous risk of the event at (t). The cumulative hazard function, ((t) = _0^t (u),u), relates directly to (S(t)) via ((t) = -(S(t))). These quantities describe the event-time distribution and form the basis for constructing survival models. Examples such as the exponential and Weibull distributions illustrate parametric models, where the hazard can remain constant (exponential) or vary systematically (Weibull).\n\n\nObserved Data\nRight-censored data are described by the observed time (X = (T, C)) and an event indicator (= I(T C)). The likelihood for censored data is derived under the assumption of independent censoring, where (T) and (C) are assumed to be independent. The likelihood function is expressed in terms of the hazard and survival functions, separating the contributions of event times and censored observations. This framework enables parametric inference, where the likelihood is maximized to estimate model parameters.\n\n\nParametric Families and Likelihood Construction\nParametric models define specific forms for ((t)) and (S(t)), tailoring the hazard to reflect different patterns over time. For instance, the exponential model assumes a constant hazard, while the Weibull model allows the hazard to increase or decrease, depending on the shape parameter. The likelihood for parametric models incorporates both hazard and survival components: [ L() = _{i=1}^n (X_i; )^{_i} S(X_i; ), ] where (X_i) and (_i) represent the observed data. Maximum likelihood estimation is performed by solving score equations, either analytically for simple models (e.g., exponential) or numerically for more flexible models (e.g., Weibull, using Newton–Raphson). These models also facilitate hypothesis testing and confidence interval construction through the Fisher information matrix.\n\n\nCounting Processes and Martingales\nThe counting process (N(t)) tracks event occurrences over time, with (N^*(t)) serving as the indicator of an event by time (t). Martingale theory provides a framework for decomposing (N(t)) into a predictable component (A(t)), linked to the hazard function, and a stochastic component (M(t)), which has mean zero. This decomposition simplifies derivations of key quantities, such as the Nelson–Aalen estimator for the cumulative hazard, and supports the development of test statistics, such as the log-rank test. By expressing these tools as integrals with respect to martingales, their properties can be leveraged for efficient and rigorous inference.\n\n\nStochastic Integrals\nSurvival-analysis tools, including the log-likelihood, score equations, and variance formulas, are reformulated as stochastic integrals with respect to counting processes and martingales. These integrals simplify computations and ensure that statistical methods remain grounded in rigorous large-sample theory. Martingale properties, such as uncorrelated increments and mean-zero expectations, support the derivation of asymptotic results, including the normality of estimators.\n\n\nConclusion\nThe survival and hazard functions provide the foundation for modeling time-to-event data, with censored observations incorporated through likelihood methods. Parametric families like the exponential and Weibull distributions offer flexibility in hazard modeling, while counting-process and martingale frameworks unify key tools and simplify calculations. These concepts establish a rigorous foundation for the development of advanced survival analysis methods.",
    "crumbs": [
      "Home",
      "Part I - Univariate Events",
      "Chapter 2 - Mathematical Foundations"
    ]
  },
  {
    "objectID": "chapter2.html#chapter-summary-1",
    "href": "chapter2.html#chapter-summary-1",
    "title": "Chapter 2 - Mathematical Foundations",
    "section": "Chapter Summary",
    "text": "Chapter Summary\nCensored event times require specialized methods for analysis, which are grounded in fundamental quantities like the survival function \\(S(t)\\) and the hazard function \\(\\lambda(t)\\). Some methods rely on parametric models, while others leverage counting processes and martingales to provide a robust framework for understanding and modeling time-to-event data.\n\nNotation and Basic Quantities\nAn outcome event time can be represented either as a random variable \\(T\\) or as a counting process \\(N^*(t) = I(T \\le t)\\). The survival function is defined as [ S(t) = (T &gt; t), ] while the hazard function \\(\\lambda(t)\\) quantifies the instantaneous risk of experiencing the event at time \\(t\\), conditional on survival up to that point. The cumulative hazard function is obtained by integrating \\(\\lambda(t)\\) over \\([0, t]\\): [ (t) = _0^t (u),u, ] and relates to \\(S(t)\\) via [ (t) = -(S(t)) S(t) = {-(t)}. ] This relationship is central to survival analysis, facilitating transitions between hazard-based and survival-based formulations.\n\n\nParametric Families and Likelihood\nParametric models, such as the exponential, Weibull, and gamma distributions, define specific forms for \\(\\lambda(t)\\), which in turn determine \\(S(t)\\) and the associated likelihood for censored data. The observed data, \\((X_i, \\delta_i)\\), consist of the minimum of event and censoring times and an event indicator. Under the assumption of independent censoring, the likelihood separates neatly into hazard and survival components. Inferences are then made by solving score equations, either analytically for simpler models (e.g., exponential) or numerically for more complex ones (e.g., Weibull, using Newton–Raphson).\n\n\nCounting Processes and Martingales\nThe counting-process framework offers a unified way to represent time-to-event data. The observed counting process \\(N(t)\\) tracks event occurrences over time and can be decomposed as: [ N(t) = A(t) + M(t), ] where \\(A(t)\\) is the predictable compensator, linked to \\(\\lambda(t)\\), and \\(M(t)\\) is a martingale representing the random fluctuations. This decomposition simplifies the derivation of key quantities, such as means and variances, and underpins many survival-analysis tools, including the Nelson–Aalen estimator and test statistics. Martingale properties enable straightforward calculations and inference.\n\n\nConclusion\nThis chapter provides the mathematical foundation for survival analysis, emphasizing the definition and role of \\(\\lambda(t)\\) and \\(S(t)\\), the treatment of censored data through likelihood-based methods, and the utility of counting processes and martingales. The independence of \\(T\\) and the censoring time \\(C\\) is a crucial assumption, ensuring valid inference from partially observed data. These concepts form the basis for more advanced methodologies in survival analysis.",
    "crumbs": [
      "Home",
      "Part I - Univariate Events",
      "Chapter 2 - Mathematical Foundations"
    ]
  },
  {
    "objectID": "chap2.html#outcome-event-notation-1",
    "href": "chap2.html#outcome-event-notation-1",
    "title": "Applied Survival Analysis",
    "section": "Outcome Event: Notation",
    "text": "Outcome Event: Notation\n\nTime to outcome event (latent, w.o. censoring): \\(T\\)\n\nCumulative distribution function (cdf): \\(F(t)={\\rm pr}(T\\leq t)\\)\nSurvival function: \\(S(t) = 1- F(t) = {\\rm pr}(T &gt; t)\\)\nDensity function: \\(f(t) = \\d F(t)/\\d t = - \\d S(t)/ \\d t\\)\n\nLeibniz notation\n\n\\(\\d F(t) = f(t)\\d t = \\pr(t \\leq T &lt; t + \\d t)\\): infinitesimal (marginal) event rate (i.e. incidence) over \\([t, t + \\d t)\\)"
  },
  {
    "objectID": "chap2.html#summary",
    "href": "chap2.html#summary",
    "title": "Applied Survival Analysis",
    "section": "Summary",
    "text": "Summary\n\nNotation\n\nOutcome data: \\(T\\)\nObserved data: \\(X=T\\wedge C\\) (time), \\(\\delta=I(T\\leq C)\\) (status)\nCounting process: \\(N(t)=I(X\\leq t,\\delta=1)\\)\nCounting process integral \\[\\delta I(X\\leq t) h(X) = \\int_0^t h(u)\\dd N(u)\\]\n\nMartingale residual \\[\\dd M(t) = \\dd N(t) - I(X\\geq t)\\dd\\Lambda(t)\\]"
  },
  {
    "objectID": "chapter3.html#r-code",
    "href": "chapter3.html#r-code",
    "title": "Chapter 3 - Nonparametric Estimation and Testing",
    "section": "R Code",
    "text": "R Code\n\n\nShow the code\n###############################################################################\n# Chapter 3 R Code\n#\n# This script reproduces all major numerical results in Chapter 3, including:\n#  1. The Nelson–Aalen estimator (Figures 3.3, Table 3.2)\n#  2. Kaplan–Meier (KM) analysis (Figure 3.4, Table 3.3, Table 3.5, Table 3.6)\n#  3. Log-rank tests for the rat study and the GBC study\n#  4. Additional code for generating Figures 3.7 and 3.9\n###############################################################################\n\n\n#==============================================================================\n# (A) Nelson–Aalen Estimator for the Rat Study (Figures 3.3, Table 3.2)\n#==============================================================================\nlibrary(survival)\nlibrary(tidyverse)\n\n# The 'rats' dataset records times to tumor or censoring in rats receiving a drug\n# vs. control. Each row corresponds to one rat, with variables:\n#   litter:  Litter ID, from 1 to 100 (3 rats per litter)\n#   rx:      Treatment (1 = drug, 0 = control)\n#   time:    Time to tumor or last follow-up\n#   status:  Event status (1 = tumor, 0 = censored)\n#   sex:     'male' or 'female'\n#\n# N. Mantel, N. R. Bohidar, and J. L. Ciminera. \n# \"Mantel-Haenszel analyses of litter-matched time-to-response data, with \n#  modifications for recovery of interlitter information.\" \n#  Cancer Research, 37:3863-3868, 1977.\n\n#------------------------------------------------------------------------------\n# 1. Read and inspect the dataset\n#------------------------------------------------------------------------------\nrats &lt;- read.table(\"Data//Rat Tumorigenicity Study//rats.txt\", header = TRUE)\nhead(rats)\n\n#------------------------------------------------------------------------------\n# 2. Subset to the treatment group (rx == 1)\n#------------------------------------------------------------------------------\nrats.rx &lt;- rats[rats$rx == 1, ]\n\ntime   &lt;- rats.rx$time\nstatus &lt;- rats.rx$status\n\n#------------------------------------------------------------------------------\n# 3. Extract unique sorted event times (for status == 1)\n#------------------------------------------------------------------------------\nts &lt;- unique(sort(time[status == 1])) \nm  &lt;- length(ts)\nts\n\n# Count number of failures at each event time\nds &lt;- table(time[status == 1])\n\n# Prepare vectors for risk set sizes, the dLambda increments, and cumulative Lambda\nns &lt;- rep(NA, m)   # Number at risk\ndL &lt;- rep(NA, m)   # Incremental hazard\nL  &lt;- rep(NA, m)   # Cumulative hazard\n\n#------------------------------------------------------------------------------\n# 4. Compute Nelson–Aalen estimates\n#------------------------------------------------------------------------------\nfor (j in seq_len(m)) {\n  # (a) Risk set: subjects still under observation at ts[j]\n  ns[j] &lt;- sum(time &gt;= ts[j])\n  \n  # (b) Increment for the Nelson–Aalen: dLambda = d_j / n_j\n  dL[j] &lt;- ds[j] / ns[j]\n  \n  # (c) Cumulative hazard: sum of all increments up to j\n  L[j] &lt;- sum(dL[1:j])\n}\n\n# Combine into a table for display\nresults &lt;- cbind(ts, ds, ns, dL, L)\nround(results, 3)\n\n#------------------------------------------------------------------------------\n# 5. Plot the estimated cumulative hazard function\n#------------------------------------------------------------------------------\npar(mfrow = c(1, 1))\nplot(\n  stepfun(ts, c(0, L)), \n  do.points  = FALSE, \n  ylim       = c(0, 0.4), \n  xlim       = c(0, 120), \n  lwd        = 2, \n  frame.plot = FALSE,\n  xlab       = \"Time (days)\",\n  ylab       = \"Cumulative hazard function\",\n  cex.lab    = 1.5, \n  cex.axis   = 1.5,\n  main = \"\"\n)\n\n\n#==============================================================================\n# (B) Kaplan–Meier Estimates for the Rat Study (Figure 3.4, Table 3.3)\n#==============================================================================\n# The 'dL' vector above is used for calculating incremental survival probabilities:\n#   S_{j} = S_{j-1} * (1 - d_j / n_j)\n# Greenwood's formula provides approximate variance.\n\n#------------------------------------------------------------------------------\n# 1. Define incremental survival and variance components\n#------------------------------------------------------------------------------\ncsurv        &lt;- 1 - dL               # 1 - (d_j / n_j)\nvar.csurv    &lt;- ds / (ns * (ns - ds))  # Greenwood piece: d_j / [n_j*(n_j - d_j)]\n\n# KM estimates at each event time\nKMsurv &lt;- rep(NA, m)\nse     &lt;- rep(NA, m)\n\n#------------------------------------------------------------------------------\n# 2. Compute step-by-step Kaplan–Meier survival and Greenwood SE\n#------------------------------------------------------------------------------\nfor (j in seq_len(m)) {\n  # Multiply all previous (1 - d_i/n_i)\n  KMsurv[j] &lt;- prod(csurv[1:j])\n  \n  # Greenwood's formula for variance\n  se[j] &lt;- KMsurv[j] * sqrt(sum(var.csurv[1:j]))\n}\n\n# Create a summary table\nresults2 &lt;- cbind(ts, ds, ns, csurv, KMsurv, se)\nround(results2, 3)\n\n#------------------------------------------------------------------------------\n# 3. Compare to survfit() from the survival package\n#------------------------------------------------------------------------------\nobj &lt;- survfit(Surv(time, status) ~ 1, data = rats.rx, conf.type = \"log-log\")\nsummary(obj)\n\n# Plot Kaplan–Meier curve via base R\nplot(\n  obj, \n  ylim       = c(0, 1), \n  xlim       = c(0, 100), \n  lwd        = 2, \n  frame.plot = FALSE,\n  xlab       = \"Time (days)\",\n  ylab       = \"Tumor-free probabilities\"\n)\n\nlegend(\n  1, 0.2,\n  c(\"Kaplan–Meier curve\", \"95% Confidence limits\"),\n  lty = 1:2, lwd = 2\n)\n\n\n#==============================================================================\n# (C) Summaries at Specific Times and Enhanced Tables (Table 3.4)\n#==============================================================================\nlibrary(gtsummary)\n\n#------------------------------------------------------------------------------\n# 1. Single-group KM model\n#------------------------------------------------------------------------------\nobj &lt;- survfit(Surv(time, status) ~ 1, data = rats.rx)\n\n# Summaries at specific time points (40, 60, 80, 100 days)\ntbl_time &lt;- tbl_survfit(\n  x            = obj,\n  times        = seq(40, 100, by = 20),\n  label_header = \"{time} days\"\n)\ntbl_time\n\n#------------------------------------------------------------------------------\n# 2. Example of plotting via ggsurvfit\n#------------------------------------------------------------------------------\nlibrary(ggsurvfit)\n\nggplot_obj &lt;- survfit(Surv(time, status) ~ 1, data = rats.rx)\n\nggsurvfit(ggplot_obj) +\n  add_confidence_interval() +\n  add_risktable() +\n  scale_x_continuous(breaks = seq(0, 100, by = 20)) +\n  ylim(0, 1) +\n  labs(x = \"Time (days)\", y = \"Tumor-free probabilities\") +\n  theme_minimal()\n\nggsave(\"images//rats_KM_gg.png\", width = 7.5, height = 4)\nggsave(\"images//rats_KM_gg.eps\", device = cairo_ps, width = 7.5, height = 4)\n\n\n#==============================================================================\n# (D) Log-Rank Test for Rat Study (Comparing Treatment vs. Control)\n#==============================================================================\n# Log-rank test with optional stratification by sex\n#------------------------------------------------------------------------------\nhead(rats)\n\n# Basic log-rank test on treatment group difference\nlogrank_obj &lt;- survdiff(Surv(time, status) ~ rx + strata(sex), data = rats, rho = 0)\nlogrank_obj\n\n# p-value associated with the test\nlogrank_obj$pvalue\n\n\n#------------------------------------------------------------------------------\n# 1. Tidy tools for a two-group KM\n#------------------------------------------------------------------------------\nobj2 &lt;- survfit(Surv(time, status) ~ rx, data = rats)\n\n# Summaries at time points\ntbl_surv &lt;- tbl_survfit(\n  x            = obj2,\n  times        = seq(40, 100, by = 20),\n  label_header = \"{time} days\",\n  label        = list(rx ~ \"Treatment\")\n)\ntbl_surv\n\n#------------------------------------------------------------------------------\n# 2. KM plot with multiple groups\n#------------------------------------------------------------------------------\nlibrary(ggplot2)\nobj3 &lt;- survfit2(Surv(time, status) ~ rx, data = rats)\n\nggsurvfit(obj3, linetype_aes = TRUE, linewidth = 1) +\n  add_pvalue(caption = \"Log-rank {p.value}\") +\n  add_risktable(risktable_stats = \"n.risk\") +\n  labs(x = \"Time (days)\", y = \"Tumor-free probabilities\") +\n  scale_linetype_manual(values = c(2, 1), labels = c(\"Control\", \"Drug\")) +\n  scale_color_discrete(labels = c(\"Control\", \"Drug\")) +\n  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, by = 0.2), expand = c(0, 0)) +\n  theme_classic() +\n  theme(\n    legend.position   = \"top\",\n    legend.key.width  = unit(1, \"cm\"),\n    panel.grid.major.y= element_line(),\n    legend.text       = element_text(size = 10),\n    plot.caption      = element_text(size = 10)\n  )\n\nggsave(\"images//rats_KM_gg2.png\", width = 7, height = 5)\nggsave(\"images//rats_KM_gg2.eps\", device = cairo_ps, width = 7, height = 5)\n\n\n#==============================================================================\n# (E) German Breast Cancer (GBC) Study for Figures 3.7, 3.9\n#==============================================================================\n# Detailed data contains multiple events, but we focus on first-event times.\n#------------------------------------------------------------------------------\ngbc &lt;- read.table(\"Data//German Breast Cancer Study//gbc.txt\", header = TRUE)\n\n# Sort by subject id, then time\no &lt;- order(gbc$id, gbc$time)\ngbc &lt;- gbc[o,]\n\n# Keep only first row per subject =&gt; first event\ndata.CE &lt;- gbc[!duplicated(gbc$id), ]\n\n# Convert status&gt;0 to 1 if it is either relapse or death\ndata.CE$status &lt;- ifelse(data.CE$status &gt; 0, 1, 0)\n\n\n#------------------------------------------------------------------------------\n# 1. KM curves by hormone group, possibly stratified by menopausal status\n#------------------------------------------------------------------------------\npar(mfrow = c(1, 3))\n\n# (a) Overall\nkm_overall &lt;- survfit(Surv(time, status) ~ hormone, data = data.CE)\nplot(\n  km_overall, \n  xlim  = c(0, 80), \n  lwd   = 2, \n  frame = FALSE, \n  lty   = c(2, 1),\n  xlab  = \"Time (months)\",\n  ylab  = \"Relapse-free survival probabilities\",\n  main  = \"Overall\",\n  cex.lab = 1.5, cex.axis = 1.5, cex.main = 1.5\n)\nlegend(\n  1, 0.2, \n  lty = 2:1, c(\"No Hormone\", \"Hormone\"), \n  lwd = 2, cex = 1.5\n)\n\n# (b) Pre-menopausal (meno == 1)\nkm_pre &lt;- survfit(Surv(time, status) ~ hormone, data = data.CE[data.CE$meno == 1, ])\nplot(\n  km_pre, \n  xlim  = c(0, 80), \n  lwd   = 2, \n  frame = FALSE,\n  lty   = c(2, 1),\n  xlab  = \"Time (months)\",\n  ylab  = \"Relapse-free survival probabilities\",\n  main  = \"Pre-Menopausal\",\n  cex.lab = 1.5, cex.axis = 1.5, cex.main = 1.5\n)\nlegend(\n  1, 0.2, \n  lty = 2:1, c(\"No Hormone\", \"Hormone\"), \n  lwd = 2, cex = 1.5\n)\n\n# (c) Post-menopausal (meno == 2)\nkm_post &lt;- survfit(Surv(time, status) ~ hormone, data = data.CE[data.CE$meno == 2, ])\nplot(\n  km_post, \n  xlim  = c(0, 80), \n  lwd   = 2, \n  frame = FALSE,\n  lty   = c(2, 1),\n  xlab  = \"Time (months)\",\n  ylab  = \"Relapse-free survival probabilities\",\n  main  = \"Post-Menopausal\",\n  cex.lab = 1.5, cex.axis = 1.5, cex.main = 1.5\n)\nlegend(\n  1, 0.2,\n  lty = 2:1, c(\"No Hormone\", \"Hormone\"),\n  lwd = 2, cex = 1.5\n)\n\n\n#------------------------------------------------------------------------------\n# 2. ggplot2 version (3.9) via ggsurvfit, patchwork\n#------------------------------------------------------------------------------\nlibrary(patchwork) # For combining plots\nlibrary(ggsci) # For the JAMA color style\nlibrary(ggsurvfit)\n\n# (a) Subset survival fits\npre_obj2  &lt;- survfit2(Surv(time, status) ~ hormone, data = data.CE |&gt; filter(meno == 1))\npost_obj2 &lt;- survfit2(Surv(time, status) ~ hormone, data = data.CE |&gt; filter(meno == 2))\nall_obj2  &lt;- survfit2(Surv(time, status) ~ hormone, data = data.CE)\n\n# (b) Helper function to produce KM plot\nplot_gbc_KM &lt;- function(obj, title = NULL) {\n  p &lt;- ggsurvfit(obj, linetype_aes = TRUE, linewidth = 1) +\n    add_risktable(\n      risktable_stats = \"n.risk\",\n      theme = list(\n        theme_risktable_default(),\n        scale_y_discrete(labels = c(\"Hormone\", \"No Hormone\"))\n      )\n    ) +\n    scale_y_continuous(\n      \"Relapse-free survival probabilities\", \n      limits  = c(0, 1),\n      breaks  = seq(0, 1, by = 0.2),\n      expand  = expansion(c(0, 0.005))\n    ) +\n    scale_x_continuous(\"Time (months)\", breaks = seq(0, 84, by = 12)) +\n    scale_color_jama(labels = c(\"No Hormone\", \"Hormone\")) +\n    scale_linetype_manual(values = c(2, 1), labels = c(\"No Hormone\", \"Hormone\")) +\n    theme_classic() +\n    theme(\n      plot.margin        = margin(0, 0, 0, 0),\n      legend.position    = \"top\",\n      legend.key.width   = unit(1, \"cm\"),\n      panel.grid.major.y = element_line(),\n      legend.text        = element_text(size = 10),\n      plot.caption       = element_text(size = 10),\n      plot.title         = element_text(size = 12)\n    )\n  if (!is.null(title)) p &lt;- p + ggtitle(title)\n  p\n}\n\n# Three panels by menopausal status and overall\npre_fig  &lt;- plot_gbc_KM(pre_obj2,  \"Pre-Menopausal\")\npost_fig &lt;- plot_gbc_KM(post_obj2, \"Post-Menopausal\")\nall_fig  &lt;- plot_gbc_KM(all_obj2,  \"Overall\")\n\n# Combine with patchwork\nfig_meno &lt;- wrap_plots(ggsurvfit_build(pre_fig), ggsurvfit_build(post_fig), ncol = 2)\nwrap_plots(ggsurvfit_build(all_fig), plot_spacer(), fig_meno, ncol = 1) +\n  plot_layout(heights = c(1, 0.02, 1))\n\nggsave(\"images//gbc_KM_gg.png\", width = 8, height = 9)\nggsave(\"images//gbc_KM_gg.eps\", width = 8, height = 9)\n\n#------------------------------------------------------------------------------\n# 3. Stratified log-rank test (menopausal status) and unstratified log-rank\n#------------------------------------------------------------------------------\nsurvdiff(Surv(time, status) ~ hormone + strata(meno), data = data.CE)\nsurvdiff(Surv(time, status) ~ hormone, data = data.CE)"
  },
  {
    "objectID": "chapter3.html#chapter-summary",
    "href": "chapter3.html#chapter-summary",
    "title": "Chapter 3 - Nonparametric Estimation and Testing",
    "section": "Chapter Summary",
    "text": "Chapter Summary\nConditioning on the cohort at risk at each observed event time naturally leads to discrete hazard-based approaches for analyzing time-to-event data. These approaches illuminate how nonparametric estimators, such as the Kaplan–Meier curve, and group-comparison tests, such as the log-rank statistic, arise directly from examining discrete hazards over the course of a study.\n\nThe discrete hazard\nA discrete hazard captures the probability of an event happening exactly at a specific observed time, given that the subject remains event-free up to that instant. Let \\(d_j\\) be the number of events at time \\(t_j\\) and \\(n_j\\) the size of the at-risk cohort immediately before \\(t_j\\). Then the discrete hazard at \\(t_j\\) is often estimated by \\[\n\\hat\\lambda(t_j)\n=\n\\frac{d_j}{n_j}.\n\\] As event times become dense in larger samples, the sum of these discrete hazards approximate the cumulative hazard. This perspective incorporates censoring by reducing \\(n_j\\) each time individuals drop out or experience the event. The discrete hazard thus defines a step-by-step mechanism for survival analysis, tying observed failures at each \\(t_j\\) to the relevant risk set.\nWorking with a discrete hazard emphasizes the fact that each observed event time carries information about the underlying risk. By updating \\(n_j\\) dynamically, these methods properly weight the observed data for unbiased inference under independent censoring. In practical studies where event times are not necessarily continuous, such discrete formulations provide an elegant way to handle censored observations and can be generalized to more complex sampling and trial designs.\n\n\nThe Kaplan–Meier estimator\nFrom discrete hazards, the Kaplan–Meier estimator emerges as a product-limit construction. If \\(\\hat\\lambda(t_j)\\) denotes the discrete hazard at \\(t_j\\), the survival function is estimated by \\[\n\\hat S(t)\n=\n\\prod_{t_j \\le t}\n  \\bigl(1 - \\hat\\lambda(t_j)\\bigr)\n=\n\\prod_{t_j \\le t}\n  \\Bigl(1 - \\frac{d_j}{n_j}\\Bigr).\n\\] Each factor \\(1 - d_j / n_j\\) represents the proportion of subjects who “survive” past \\(t_j\\), given that \\(n_j\\) remain at risk immediately before \\(t_j\\). Because \\(n_j\\) is updated to exclude prior failures and censored observations, the estimator remains consistent even when censoring occurs at arbitrary times. At large sample sizes, \\(\\hat S(t)\\) converges in probability to the true \\(S(t)\\), making it a cornerstone of nonparametric survival analysis.\nBeyond plotting the full curve, summary measures like the median survival time emerge by identifying \\(t\\) such that \\(\\hat S(t)\\) falls to 0.5. This approach can easily extend to other percentiles or even partial survival probabilities at fixed times of interest. The stepwise nature of the Kaplan–Meier curve also offers straightforward visualization, indicating event occurrences at each jump and seamlessly accounting for censoring up to those points.\n\n\nThe log-rank test\nGroups often require formal comparison to assess whether one experiences faster or slower rates of failure than another. The log-rank test constructs a weighted difference in group-specific event counts over time. Let \\(d_{1j}\\) and \\(n_{1j}\\) denote the observed failures and risk set in group 1 at time \\(t_j\\), with \\(d_j\\) and \\(n_j\\) as the totals across all groups. The log-rank statistic sums \\[\nd_{1j} - d_j \\frac{n_{1j}}{n_j}\n\\] over \\(t_j\\). Under a null hypothesis of no group difference, the fraction \\(n_{1j}/n_j\\) should capture group 1’s expected share of failures, so repeated departures from that share indicate differing survival experiences. In large samples, this statistic often approximates a chi-square distribution, allowing standard significance testing. The log-rank test has strong power under proportional hazards, where one group’s hazard is a constant multiple of the other’s. Nonetheless, real data may violate strict proportionality, motivating alternative weighting schemes or more flexible tests.\n\n\nExtensions of the log-rank test\nWeighted log-rank variants highlight different parts of the follow-up period. When early effects dominate, decreasing weights place emphasis on initial events. For delayed effects, increasing weights spotlight later intervals. A “max-combo test” addresses uncertainty about the exact timing of effects by calculating multiple weighted statistics and taking their maximum, adjusting for correlation to preserve correct Type I error. This approach captures a broad array of hazard patterns, albeit with more complex null distributions. Stratification extends the log-rank framework further by partitioning subjects into strata defined by confounders (e.g., menopausal status). Within each stratum, the test proceeds as usual, and these stratum-level statistics combine into a single global test. This adjustment effectively controls for measured covariates that could otherwise bias group comparisons.\n\n\nStatistical properties via martingale\nBeyond heuristic arguments, martingale theory provides rigorous large-sample derivations for Kaplan–Meier estimator and log-rank tests. This is because the estimators and test statstics can be written as stochastic integrals of martingales, which simplify the computation of variances and covariances.\n\n\nSoftware use\nNonparametric survival estimates and log-rank tests are easily performed in R via the survival package. The survfit function fits Kaplan–Meier curves from a time-to-event variable and an event indicator, while the survdiff function calculates log-rank tests (and variations such as stratified or weighted log-rank). Many standard analyses can therefore be completed with just a few lines of code, shown below:\n\nlibrary(survival)\n\n# Fit Kaplan–Meier curves for two groups\nkm_fit &lt;- survfit(Surv(time, status) ~ group, data = mydata)\n\n# Summarize survival estimates and times\nsummary(km_fit)\n\n# Perform a log-rank test to compare groups\nlr_test &lt;- survdiff(Surv(time, status) ~ group, data = mydata)\nlr_test\n\nAdditional utilities are available for generating publication-ready tables and plots. The gtsummary package, for instance, provides a tbl_survfit() function that creates neatly formatted tables of survival estimates by group or stratum, including confidence intervals and median times. The ggsurvfit package extends ggplot2 to produce enhanced Kaplan–Meier graphs with at-risk tables, confidence interval shading, and optional log-rank \\(p\\)-values annotated on the plot:\n\nlibrary(gtsummary)\nlibrary(ggsurvfit)\n\n# Summarize survival estimates in a neat table\ntbl &lt;- tbl_survfit(km_fit, times = c(12, 24, 48, 96))\ntbl\n\n# Create a KM plot with confidence intervals and at-risk tables\nggsurvfit(km_fit) +\n  add_confidence_interval() +\n  add_risktable()\n\nThese higher-level functions streamline the presentation of nonparametric survival analyses, ensuring that both the numeric results and the visual displays are clear and publication-ready.\n\n\nConclusion\nDiscrete hazard constructs offer a flexible pathway to nonparametric survival estimation and testing. By updating risk sets at each event time, they integrate censoring into hazard estimators, leading to the Kaplan–Meier survival curve. For group comparisons, the log-rank test accumulates deviations in observed vs. expected failures across time, capturing hazard differences in a simple chi-square framework. Weighted extensions and max-combo designs handle a variety of hazard patterns and timing effects, while stratification addresses possible confounders. Underlying it all, martingale theory justifies the asymptotic properties of the estimators and tests, ensuring their validity and robustness in large samples."
  },
  {
    "objectID": "chapter3.html#the-discrete-hazard",
    "href": "chapter3.html#the-discrete-hazard",
    "title": "Chapter 3 - Nonparametric Estimation and Testing",
    "section": "The Discrete Hazard",
    "text": "The Discrete Hazard\nThe discrete hazard quantifies the probability of an event happening at a specific observed time, given survival up to that time. By conditioning on the subjects still at risk, the Nelsen–Aalen estimator captures this discrete hazard as: \\[\n\\hat\\Lambda(t_j) \\;=\\;\n\\sum_{l : t_l \\le t_j}\n  \\frac{d_l}{n_l},\n\\] where (d_l) is the number of events at (t_l) and (n_l) is the number at risk just before (t_l)."
  },
  {
    "objectID": "chapter3.html#kaplanmeier-estimator",
    "href": "chapter3.html#kaplanmeier-estimator",
    "title": "Chapter 3 - Nonparametric Estimation and Testing",
    "section": "Kaplan–Meier Estimator",
    "text": "Kaplan–Meier Estimator\nThe Kaplan–Meier estimator for the survival function follows from taking the product limit of these discrete hazards: \\[\n\\hat S(t)\n\\;=\\;\n\\prod_{t_j \\le t}\\bigl(1 - \\tfrac{d_j}{n_j}\\bigr).\n\\] Because it sequentially updates the cohort size to account for censoring, this estimator remains unbiased under independent censoring and converges to the true survival function as sample size grows."
  },
  {
    "objectID": "chapter3.html#log-rank-test",
    "href": "chapter3.html#log-rank-test",
    "title": "Chapter 3 - Nonparametric Estimation and Testing",
    "section": "Log-Rank Test",
    "text": "Log-Rank Test\nTo compare survival experiences across multiple groups, the log-rank test forms a weighted difference of the group-specific hazards over time: \\[\n\\sum_{j=1}^{m} \\Bigl( d_{1j} - d_j \\tfrac{n_{1j}}{n_j} \\Bigr).\n\\] Under proportional hazards or similar assumptions, this statistic approximates a simple chi-square test that is powerful for detecting consistent hazard differences."
  },
  {
    "objectID": "chapter3.html#extensions-of-the-log-rank-test",
    "href": "chapter3.html#extensions-of-the-log-rank-test",
    "title": "Chapter 3 - Nonparametric Estimation and Testing",
    "section": "Extensions of the Log-Rank Test",
    "text": "Extensions of the Log-Rank Test\nFor more flexible patterns (e.g., early or delayed effects), the log-rank test can be weighted to emphasize particular time intervals or events. A “max-combo test” takes the maximum among multiple weighted variants, maintaining appropriate correlation adjustments to control the Type I error rate."
  },
  {
    "objectID": "chapter3.html#statistical-properties-and-martingales",
    "href": "chapter3.html#statistical-properties-and-martingales",
    "title": "Chapter 3 - Nonparametric Estimation and Testing",
    "section": "Statistical Properties and Martingales",
    "text": "Statistical Properties and Martingales\nHeuristic arguments clarify how these estimators and test statistics behave. More formally, a martingale framework decomposes observed increments into predictable and random parts: \\[\n\\mathrm{d}N(t) \\;=\\; I\\bigl(X \\ge t\\bigr)\\,\\lambda(t)\\,\\mathrm{d}t \\;+\\; \\mathrm{d}M(t),\n\\] where (M(t)) represents the martingale increment. This perspective simplifies derivations of asymptotic variances and supports rigorous large-sample inference for both estimation and testing."
  },
  {
    "objectID": "chap3.html#outline",
    "href": "chap3.html#outline",
    "title": "Applied Survival Analysis",
    "section": "Outline",
    "text": "Outline\n\n\nNelsen–Aalen estimator of cumulative hazard\n\nKaplan–Meier estimator of survival function\n\nLog-rank test and variations\n\nAnalysis of the German Breast Cancer study\n\n\n\n\\[\\newcommand{\\d}{{\\rm d}}\\] \\[\\newcommand{\\dd}{{\\rm d}}\\] \\[\\newcommand{\\pr}{{\\rm pr}}\\] \\[\\newcommand{\\var}{{\\rm var}}\\] \\[\\newcommand{\\se}{{\\rm se}}\\] \\[\\newcommand{\\indep}{\\perp \\!\\!\\! \\perp}\\]"
  },
  {
    "objectID": "chap3.html#nonparametric-approach",
    "href": "chap3.html#nonparametric-approach",
    "title": "Applied Survival Analysis",
    "section": "Nonparametric Approach",
    "text": "Nonparametric Approach\n\n\nMotivation\n\nNaive empirical distribution biased with censoring\nParametric models constrained\n\nWeibull model \\(\\to\\) monotone risk\n\n\n\n\n\n\nNonparametric inference\n\nEstimation of \\(S(t)=\\pr(T &gt;t)\\)\nComparison of survival function between groups\n\n\n\n\n\nDiscrete hazard: a useful tool"
  },
  {
    "objectID": "chap3.html#discrete-hazard-set-up",
    "href": "chap3.html#discrete-hazard-set-up",
    "title": "Applied Survival Analysis",
    "section": "Discrete Hazard: Set-up",
    "text": "Discrete Hazard: Set-up\n\n\nObserved data \\[(X_i, \\delta_i)\\,\\, (i=1,\\ldots, n)\\] \n\n\\(0&lt;t_1&lt;\\cdots&lt;t_m\\): unique observed event (failure) times (the \\(X_i\\) with \\(\\delta_i =1\\))\n\\(d_j\\): number of observed failures at \\(t_j\\)\n\\(n_j\\): number of subjects at risk \\(t_j\\) (those with \\(X_i\\geq t_j\\))\n\n\\(n_{j-1} - n_j\\): number of failures and censorings in \\([t_{j-1}, t_j)\\)"
  },
  {
    "objectID": "chap3.html#discrete-hazard-definition",
    "href": "chap3.html#discrete-hazard-definition",
    "title": "Applied Survival Analysis",
    "section": "Discrete Hazard: Definition",
    "text": "Discrete Hazard: Definition\n\n\nCounting process notation \\[d_j = \\sum_{i=1}^n \\dd N_i(t_j)\\, \\mbox{ and }\\,\\, n_j = \\sum_{i=1}^n I(X_i \\geq t_j)\\]\n\n\n\n\nDiscretize distribution at observed event times \\[t_1&lt;t_2&lt;\\cdots&lt;t_m\\]\n\nDiscrete hazard \\[\\dd\\Lambda(t_j)=\\pr(t_j \\leq T &lt; t_j+\\dd t\\mid T\\geq t_j)=\\pr(T = t_j\\mid T\\geq t_j)\\]\n\n\\(\\dd\\Lambda(t)\\equiv 0\\) otherwise"
  },
  {
    "objectID": "chap3.html#nelsenaalen-estimator-i",
    "href": "chap3.html#nelsenaalen-estimator-i",
    "title": "Applied Survival Analysis",
    "section": "Nelsen–Aalen Estimator (I)",
    "text": "Nelsen–Aalen Estimator (I)\n\n\nRecall in Chapter 2…\\[\\begin{align}\nE\\{\\dd N(t)\\mid X\\geq t\\}&=\\frac{\\pr\\{\\dd N^*(t)=1, C\\geq t\\}}{\\pr(T\\geq t, C\\geq t)}\n\\notag\\\\\n&=\\frac{\\pr\\{\\dd N^*(t)=1\\}\\pr(C\\geq t)}{\\pr(T\\geq t)\\pr(C\\geq t)}\n\\notag\\\\\n&=E\\{\\dd N^*(t)\\mid T\\geq t\\}\\notag\\\\\n&=\\dd\\Lambda(t),\n\\end{align}\\]\n\nSo \\[\\dd\\Lambda(t_j) = E\\{\\dd N(t_j)\\mid X\\geq t_j\\}=\\frac{E\\{\\dd N(t_j)\\}}{\\pr(X\\geq t_j)}\\]"
  },
  {
    "objectID": "chap3.html#nelsenaalen-estimator-ii",
    "href": "chap3.html#nelsenaalen-estimator-ii",
    "title": "Applied Survival Analysis",
    "section": "Nelsen–Aalen Estimator (II)",
    "text": "Nelsen–Aalen Estimator (II)\n\n\nMotivates empirical estimator \\[\\begin{align}\n\\dd\\hat\\Lambda(t_j) & = \\frac{d_j}{n_j} =\n\\frac{\\sum_{i=1}^n \\dd N_i(t_j)}{\\sum_{i=1}^n I(X_i\\geq t_j)}\\\\\n&=\\mbox{proportion of failures among those at risk}\n\\end{align}\\]\n\n\n\n\nCumulative hazard \\[\n\\hat\\Lambda(t)=\\sum_{j:t_j\\leq t}\\frac{d_j}{n_j} =\\int_0^t\\frac{\\sum_{i=1}^n \\dd N_i(u)}{\\sum_{i=1}^n I(X_i\\geq u)}\n\\]\n\nNelsen–Aalen estimator\nA step function (starting from 0) that jumps \\(d_j/n_j\\) at \\(t_j\\) \\((j=1,\\ldots, m)\\)"
  },
  {
    "objectID": "chap3.html#example-rat-carcinogen-study-i",
    "href": "chap3.html#example-rat-carcinogen-study-i",
    "title": "Applied Survival Analysis",
    "section": "Example: Rat Carcinogen Study (I)",
    "text": "Example: Rat Carcinogen Study (I)\n\n\nCarcinogenicity study: 100 rats treated with a drug\n\nFollowed for tumor development"
  },
  {
    "objectID": "chap3.html#example-rat-carcinogen-study-ii",
    "href": "chap3.html#example-rat-carcinogen-study-ii",
    "title": "Applied Survival Analysis",
    "section": "Example: Rat Carcinogen Study (II)",
    "text": "Example: Rat Carcinogen Study (II)\n\n\nFollow-up plot (sub-sample)"
  },
  {
    "objectID": "chap3.html#example-rat-carcinogen-study-iii",
    "href": "chap3.html#example-rat-carcinogen-study-iii",
    "title": "Applied Survival Analysis",
    "section": "Example: Rat Carcinogen Study (III)",
    "text": "Example: Rat Carcinogen Study (III)\n\n\n“Hand” calculations"
  },
  {
    "objectID": "chap3.html#example-rat-carcinogen-study-iv",
    "href": "chap3.html#example-rat-carcinogen-study-iv",
    "title": "Applied Survival Analysis",
    "section": "Example: Rat Carcinogen Study (IV)",
    "text": "Example: Rat Carcinogen Study (IV)\n\n\nVisualization"
  },
  {
    "objectID": "chap3.html#from-hazard-to-survival",
    "href": "chap3.html#from-hazard-to-survival",
    "title": "Applied Survival Analysis",
    "section": "From Hazard to Survival",
    "text": "From Hazard to Survival\n\n\nContinuous relationship \\[\n\\tilde S(t)=\\exp\\left\\{-\\hat\\Lambda(t)\\right\\}\n\\]\n\n\n\n\nDiscrete relationship (more general and intuitive)"
  },
  {
    "objectID": "chap3.html#progressive-conditioning",
    "href": "chap3.html#progressive-conditioning",
    "title": "Applied Survival Analysis",
    "section": "Progressive Conditioning",
    "text": "Progressive Conditioning\n\n\nSurviving past \\(t_j\\): step by step \\[\\begin{align*}\nS(t_j)&=\\pr(T&gt;t_j)\\\\\n&=\\pr(T&gt;t_1)\\pr(T&gt;t_2\\mid T&gt;t_1)\\cdots\\pr(T&gt;t_j\\mid T&gt;t_{j-1})\\\\\n&=\\pr(T&gt;t_1\\mid T\\geq t_1)\\pr(T&gt;t_2\\mid T\\geq t_2)\\cdots\\pr(T&gt;t_j\\mid T\\geq t_j)\\\\\n&=\\prod_{l=1}^j\\pr(T&gt;t_l\\mid T\\geq t_l),\n\\end{align*}\\]\n\n\n\n\nOverall \\[\\begin{equation*}\nS(t)=\\prod_{j:t_j\\leq t}\\pr(T&gt;t_j\\mid T\\geq t_j)\n\\end{equation*}\\]"
  },
  {
    "objectID": "chap3.html#kaplanmeier-estimator-1",
    "href": "chap3.html#kaplanmeier-estimator-1",
    "title": "Applied Survival Analysis",
    "section": "Kaplan–Meier Estimator",
    "text": "Kaplan–Meier Estimator\n\n\nEach conditional survival \\[\n\\pr(T&gt;t_j\\mid T\\geq t_j) = 1-\\pr(T=t_j\\mid T\\geq t_j) = 1-\\dd\\Lambda(t_j)\n\\]\n\n\n\n\nPlug-in Nelsen–Aalen \\[\\begin{equation}\n\\hat S(t)=\\prod_{j:t_j\\leq t}\\{1-\\dd\\hat\\Lambda(t_j)\\}=\\prod_{j:t_j\\leq t}(1-d_j/n_j)\n\\end{equation}\\]\n\nKaplan–Meier (product-limit) estimator\nReduces to empirical survival in the absence of censoring\nAdjusts for censoring by updating number at risk \\(t_j\\) over time"
  },
  {
    "objectID": "chap3.html#kaplanmeier-estimator-variance-i",
    "href": "chap3.html#kaplanmeier-estimator-variance-i",
    "title": "Applied Survival Analysis",
    "section": "Kaplan–Meier Estimator: Variance (I)",
    "text": "Kaplan–Meier Estimator: Variance (I)\n\n\n\\(\\var\\{\\hat S(t)\\}\\)?\n\nLog-transform: product \\(\\to\\) sum \\[\n\\log\\hat S(t)=\\sum_{j:t_j\\leq t}\\log(1-d_j/n_j)\n\\]\nDelta method\\(^*\\) \\[\n\\hat\\var\\{\\hat S(t)\\}=\\hat S(t)^2\\hat\\var\\{\\log\\hat S(t)\\},\n\\]\n\n\n\n\n\n\n\n\n\n\nDelta Method\n\n\nIf approximately \\(S_n \\sim N(\\mu, \\sigma^2)\\), then approximately \\(g(S_n) \\sim N\\left\\{g(\\mu), \\dot g(\\mu)^2\\sigma^2\\right\\}\\), where \\(\\dot g(\\mu)=\\dd g(\\mu)/\\dd\\mu\\)."
  },
  {
    "objectID": "chap3.html#kaplanmeier-estimator-variance-ii",
    "href": "chap3.html#kaplanmeier-estimator-variance-ii",
    "title": "Applied Survival Analysis",
    "section": "Kaplan–Meier Estimator: Variance (II)",
    "text": "Kaplan–Meier Estimator: Variance (II)\n\n\n\\(\\var\\{\\log\\hat S(t)\\}\\)?\n\nWith the \\(n_j\\) fixed, the \\(d_j\\) are independent (different subjects) \\[\\begin{align}\n\\hat{\\rm var}\\{\\log\\hat S(t)\\}&=\\sum_{j:t_j\\leq t}\\hat{\\rm var}\\left[\\log\\{1-d_j/n_j\\}\\right]\\notag\\\\\n&\\approx \\sum_{j:t_j\\leq t}\\frac{n_j^2}{(n_j-d_j)^2}\\hat{\\rm var}(d_j/n_j)\\tag{Delta method}\\\\\n&=\\sum_{j:t_j\\leq t}\\frac{d_j}{n_j(n_j-d_j)},\n\\end{align}\\]\nLast equality: variance of binomial proportion \\[\n\\hat{\\rm var}(d_j/n_j)=(d_j/n_j)(1-d_j/n_j)/n_j\n\\]"
  },
  {
    "objectID": "chap3.html#kaplanmeier-estimator-variance-iii",
    "href": "chap3.html#kaplanmeier-estimator-variance-iii",
    "title": "Applied Survival Analysis",
    "section": "Kaplan–Meier Estimator: Variance (III)",
    "text": "Kaplan–Meier Estimator: Variance (III)\n\n\nVariance of KM \\[\\begin{equation}\\label{eq:km:greenwood}\n\\hat\\var\\{\\hat S(t)\\}=\\hat S(t)^2\\sum_{j:t_j\\leq t}\\frac{d_j}{n_j(n_j-d_j)}\n\\end{equation}\\]\n\nGreenwood’s formula\n\n\n\n\n\nNaive 95% confidence interval (CI) \\[\\begin{equation}\\label{eq:km:ci_plain}\n\\left[\\hat S(t)-1.96\\hat\\se\\{\\hat S(t)\\}, \\hat S(t)+1.96\\hat\\se\\{\\hat S(t)\\}\\right]\n\\end{equation}\\] \n\nMay contain values outside \\([0, 1]\\)\nBounded quantity approximated by unbounded (normal) distribution"
  },
  {
    "objectID": "chap3.html#kaplanmeier-estimator-ci",
    "href": "chap3.html#kaplanmeier-estimator-ci",
    "title": "Applied Survival Analysis",
    "section": "Kaplan–Meier Estimator: CI",
    "text": "Kaplan–Meier Estimator: CI\n\n\nLog-log transformed CI\n\nTransform \\(\\zeta(t)=\\log\\{-\\log S(t)\\} \\in \\mathbb R\\)\nCI for \\(\\zeta(t)\\) \\[\\begin{equation}\n\\left[\\hat\\zeta(t)-1.96\\hat\\se\\{\\hat\\zeta(t)\\},\\hat\\zeta(t)+1.96\\hat\\se\\{\\hat\\zeta(t)\\}\\right]\n\\end{equation}\\]\nTransform the bounds back to \\(S(t)\\) \\[\n\\left[\\hat S(t)^{\\exp[1.96\\hat\\se\\{\\hat\\zeta(t)\\}]}, \\hat S(t)^{\\exp[-1.96\\hat\\se\\{\\hat\\zeta(t)\\}]}\\right]\n\\subset [0, 1]\n\\]\nRemains to calculate \\(\\hat\\se\\{\\hat\\zeta(t)\\}\\) by delta method (Exercise)"
  },
  {
    "objectID": "chap3.html#example-rat-carcinogen-study-v",
    "href": "chap3.html#example-rat-carcinogen-study-v",
    "title": "Applied Survival Analysis",
    "section": "Example: Rat Carcinogen Study (V)",
    "text": "Example: Rat Carcinogen Study (V)\n\n\n“Hand” calculations"
  },
  {
    "objectID": "chap3.html#software-survivalsurvfit-i",
    "href": "chap3.html#software-survivalsurvfit-i",
    "title": "Applied Survival Analysis",
    "section": "Software: survival::survfit() (I)",
    "text": "Software: survival::survfit() (I)\n\n\nBasic syntax for fitting KM curve\n\n\n\n # df: data frame; time: X; status: delta\nobj &lt;- survfit(Surv(time, status) ~ 1, data = df, \n               conf.type = \"log-log\")\n\n\n\n\n\nInput\n\nSurv(time, status) ~ 1: fit curve to a homogeneous sample\n\nSurv(time, status) ~ group: fit curve to each level of group\n\ndata = df: input data frame df\nconf.type = \"log-log\": log-log transformation for CI\n\n\"log\": default log transformation\n\"plain\": naive CI"
  },
  {
    "objectID": "chap3.html#software-survivalsurvfit-ii",
    "href": "chap3.html#software-survivalsurvfit-ii",
    "title": "Applied Survival Analysis",
    "section": "Software: survival::survfit() (II)",
    "text": "Software: survival::survfit() (II)\n\n\nOutput: a surfit object containing KM estimates\n\nCall summary() and plot()\nsummary(obj): a list containing\n\ntime: \\(t_j\\) \\((j=1,\\ldots, m)\\)\nsurv: \\(\\hat S(t_j)\\)\nn.risk: \\(n_j\\)\nn.event: \\(d_j\\)\nstd.err: \\(\\hat\\se\\{\\hat S(t_j)\\}\\)\n..."
  },
  {
    "objectID": "chap3.html#example-rat-carcinogen-study-vi",
    "href": "chap3.html#example-rat-carcinogen-study-vi",
    "title": "Applied Survival Analysis",
    "section": "Example: Rat Carcinogen Study (VI)",
    "text": "Example: Rat Carcinogen Study (VI)\n\n\nData frame: rats.rx\n\nCheck with Table 3.3\n\n\n\n\n\nobj &lt;- survfit(Surv(time, status) ~ 1, data = rats.rx, \n               conf.type = \"log-log\")\nsummary(obj)\n# Call: survfit(formula = Surv(time, status) ~ 1, data = rats.rx, \n#               conf.type = \"log-log\")\n# \n# time n.risk n.event survival std.err lower 95% CI upper 95% CI\n#   34     99       1    0.990  0.0100        0.930        0.999\n#   39     98       1    0.980  0.0141        0.922        0.995\n#   45     97       1    0.970  0.0172        0.909        0.990\n#   67     89       1    0.959  0.0202        0.894        0.984\n#   70     86       1    0.948  0.0228        0.879        0.978\n#   ..."
  },
  {
    "objectID": "chap3.html#example-rat-carcinogen-study-vii",
    "href": "chap3.html#example-rat-carcinogen-study-vii",
    "title": "Applied Survival Analysis",
    "section": "Example: Rat Carcinogen Study (VII)",
    "text": "Example: Rat Carcinogen Study (VII)\n\n\nPlot the survival function (with 95% CI)\n\nBase plot()\n\n\n\n\n\n# plot the estimated survival function\nplot(obj, ylim = c(0,1), xlim = c(0, 100), lwd = 2, frame.plot = FALSE,\n     xlab = \"Time (days)\", ylab = \"Tumor-free probabilities\", main = \"\")\n\nlegend(1, 0.2, c(\"Kaplan-Meier curve\", \"95% Confidence limits\"),\n       lty = 1:2, lwd = 2)"
  },
  {
    "objectID": "chap3.html#example-rat-carcinogen-study-viii",
    "href": "chap3.html#example-rat-carcinogen-study-viii",
    "title": "Applied Survival Analysis",
    "section": "Example: Rat Carcinogen Study (VIII)",
    "text": "Example: Rat Carcinogen Study (VIII)\n\n\nResult"
  },
  {
    "objectID": "chap3.html#comparing-survival-rates",
    "href": "chap3.html#comparing-survival-rates",
    "title": "Applied Survival Analysis",
    "section": "Comparing Survival Rates",
    "text": "Comparing Survival Rates\n\n\nMotivation: compare event rate across groups for treatment/exposure effect\n\n\n\n\nExample\n\nRat study: 100 treated (analyzed) vs 200 untreated for tumor incidence\nGBC study: hormone vs non-hormone treatments for (relapse-free) survival\n\n\n\n\n\nHypothesis \\[\\begin{equation}\\label{eq:km:null}\n    H_0: S_1(t)=S_0(t) \\mbox{ for all } t.\n\\end{equation}\\]\n\n\\(S_a(t) =\\) survival function of \\(T\\) in group \\(a\\) (\\(1\\): treatment; \\(0\\): control)"
  },
  {
    "objectID": "chap3.html#two-group-comparison-set-up",
    "href": "chap3.html#two-group-comparison-set-up",
    "title": "Applied Survival Analysis",
    "section": "Two-Group Comparison: Set-up",
    "text": "Two-Group Comparison: Set-up\n\n\nObserved data \\[\\begin{equation}\n\\{(X_{1i},\\delta_{1i}): i=1,\\ldots, N_1\\} \\mbox{ and } \\{(X_{0i},\\delta_{0i}): i=1,\\ldots, N_0\\},\n\\end{equation}\\]\n\n\\((X_{ai},\\delta_{ai})\\) \\((i=1,\\ldots, N_a)\\): a random sample of \\((X,\\delta)\\) in group \\(a\\)\n\n\\(n_{1j}\\), \\(n_{0j}\\): numbers at risk in groups 1 and 0 at \\(t_j\\) (totaling \\(n_j = n_{1j} + n_{0j}\\) at risk)\n\\(d_{1j}\\), \\(d_{0j}\\): numbers of events in groups 1 and 0 at \\(t_j\\) (totaling \\(d_j = d_{1j} + d_{0j}\\) events)"
  },
  {
    "objectID": "chap3.html#two-group-comparison-contingency",
    "href": "chap3.html#two-group-comparison-contingency",
    "title": "Applied Survival Analysis",
    "section": "Two-Group Comparison: Contingency",
    "text": "Two-Group Comparison: Contingency\n\n\nFixing \\(d_j\\) (total # uninformative of group difference)"
  },
  {
    "objectID": "chap3.html#two-group-comparison-log-rank-i",
    "href": "chap3.html#two-group-comparison-log-rank-i",
    "title": "Applied Survival Analysis",
    "section": "Two-Group Comparison: Log-rank (I)",
    "text": "Two-Group Comparison: Log-rank (I)\n\n\nContingency table \\((2\\times 2)\\)\n\n\\(H_0\\): No association between event occurence vs group affiliation\nEvent occurs in proportion to number at risk \\[\\begin{align}\nR_j&=d_{1j}-d_j\\frac{n_{1j}}{n_j}\\\\\n&=\\mbox{(Observed events)} - \\mbox{(Expected events)}\n\\end{align}\\]\n\\(R_j &gt; 0\\): higher incidence in treatment; \\(R_j &lt; 0\\): higher incidence in control\n\\(E(R_j\\mid d_j, n_{1j}, n_{0j})\\stackrel{H_0}{=}0\\)\n\\(\\var(R_j\\mid d_j, n_{1j}, n_{0j})\\stackrel{H_0}{=:} V_j\\) by hypergeometric distribution"
  },
  {
    "objectID": "chap3.html#two-group-comparison-log-rank-ii",
    "href": "chap3.html#two-group-comparison-log-rank-ii",
    "title": "Applied Survival Analysis",
    "section": "Two-Group Comparison: Log-rank (II)",
    "text": "Two-Group Comparison: Log-rank (II)\n\n\nTesting overall incidence \\[\\begin{equation}\\label{eq:km:logrank_stat}\nS_{N_1,N_0}=\\frac{(\\sum_{j=1}^m R_j)^2}{\\sum_{j=1}^m V_j}\\stackrel{H_0}{\\sim} \\chi_1^2\n\\end{equation}\\]\n\n\\(\\hat\\var(\\sum_{j=1}^m R_j)=\\sum_{j=1}^m V_j\\) by conditioning (martingale) arguments\n\nUncorrelated increments\n\nReject \\(H_0\\) if \\[S_{N_1,N_0}&gt;\\chi_1^2(1-\\alpha)\\]\n\n\\(\\chi_1^2(1-\\alpha)\\) is the \\(100(1-\\alpha)\\)th percentile of \\(\\chi_1^2\\)\n\nLog-rank test (with significance level \\(\\alpha\\))"
  },
  {
    "objectID": "chap3.html#two-group-comparison-log-rank-iii",
    "href": "chap3.html#two-group-comparison-log-rank-iii",
    "title": "Applied Survival Analysis",
    "section": "Two-Group Comparison: Log-rank (III)",
    "text": "Two-Group Comparison: Log-rank (III)\n\n\nAlternative hypothesis \\[\\begin{equation}\\label{eq:km:logrank_alter}\nH_A: \\lambda_1(t)\\leq\\lambda_0(t)\\mbox{ for all } t \\mbox{ with strict inequality for some }t\n\\end{equation}\\]\n\nOrdered hazards: treatment consistently lowers risk over time compared to control (or vice versa) \\[\\pr\\left\\{S_{N_1,N_0}&gt;\\chi_1^2(1-\\alpha)\\right\\}\\stackrel{H_A}{\\to} 1 \\mbox{ as } n\\to\\infty\\]\n\\(\\sum_{j=1}^m R_j =\\) Weighted difference of group-specific Nelsen–Aalen estimates of hazard functions (Section 3.2.2)\nCrossing hazards \\(\\to\\) weak power"
  },
  {
    "objectID": "chap3.html#log-rank-extension-multiple-groups",
    "href": "chap3.html#log-rank-extension-multiple-groups",
    "title": "Applied Survival Analysis",
    "section": "Log-Rank Extension: Multiple Groups",
    "text": "Log-Rank Extension: Multiple Groups\n\n\n\\(K\\) groups \\((k = 0, 1, \\ldots, K-1)\\) \\[\\begin{equation}\\label{eq:km:logrank_mult}\n\\gamma=\\sum_{j=1}^m\\left(d_{1j}-d_j\\frac{n_{1j}}{n_j},d_{2j}-d_j\\frac{n_{2j}}{n_j},\\ldots, d_{K-1,j}-d_j\\frac{n_{K-1,j}}{n_j}\\right)^{\\rm T}\n\\end{equation}\\]\n\n\\(t_1&lt;\\cdots&lt;t_m\\): unique event times pooled across \\(K\\) groups\n\\(d_{kj}, n_{kj}\\): numbers of failed and at-risk subjects in group \\(k\\) at \\(t_j\\)\nTest statistic \\[\n\\gamma^{\\rm T}\\var(\\gamma)^{-1}\\gamma\\stackrel{H_0}{\\sim}\\chi_{K-1}^2\n\\]\nAlternative hypothesis: exist two groups with ordered hazards"
  },
  {
    "objectID": "chap3.html#log-rank-extension-stratification",
    "href": "chap3.html#log-rank-extension-stratification",
    "title": "Applied Survival Analysis",
    "section": "Log-Rank Extension: Stratification",
    "text": "Log-Rank Extension: Stratification\n\n\nStratification: compare groups only within same stratum\n\nRace/ethnicity, sex, age group, study center\nAdjust for confounder\nStatistical efficiency\n\n\n\n\n\nTest statistic\n\nCalculate and aggregate stratum-specific \\(\\sum_{j=1}^m R_j\\)\nAlternative hypothesis: ordered hazards (same order) across strata"
  },
  {
    "objectID": "chap3.html#log-rank-extension-weighting-i",
    "href": "chap3.html#log-rank-extension-weighting-i",
    "title": "Applied Survival Analysis",
    "section": "Log-Rank Extension: Weighting (I)",
    "text": "Log-Rank Extension: Weighting (I)\n\n\nWeight \\(w_j\\) at time \\(t_j\\): \\[\\begin{equation}\\label{eq:eq:km:ej_w}\n\\frac{(\\sum_{j=1}^{m} w_jR_{j})^2}{\\sum_{j=1}^{m} w_j^2V_{j}} \\stackrel{H_0}{\\sim} \\chi_1^2\n\\end{equation}\\]\n\nLog-rank: \\(w_j\\equiv 1\\)\nGehan: \\(w_j = n_j/n\\)\nHarrington-Fleming (HF) \\(G^\\rho\\) family: \\(\\hat S(t_j-)^\\rho\\) \\((\\rho\\geq 0)\\)\n\n\\(\\hat S(t_j-)\\): KM estimate based on pooled sample\nExtended to \\(G^{\\rho,\\gamma}\\) family: \\(\\hat S(t_j-)^\\rho\\{1-\\hat S(t_j-)\\}^\\gamma\\) \\((\\rho, \\gamma \\geq 0)\\)"
  },
  {
    "objectID": "chap3.html#log-rank-extension-weighting-ii",
    "href": "chap3.html#log-rank-extension-weighting-ii",
    "title": "Applied Survival Analysis",
    "section": "Log-Rank Extension: Weighting (II)",
    "text": "Log-Rank Extension: Weighting (II)\n\n\nChoice\n\nPre-specify to avoid bias\nDecreasing weights: sensitive to early effects\nIncreasing weights: sensitive to delayed effects\nConstant weight (default): optimal for proportional hazards alternative \\[\nH_A^{\\rm PH}:\\lambda_1(t)=\\exp(\\theta)\\lambda_0(t) \\mbox{ for all } t\n\\]"
  },
  {
    "objectID": "chap3.html#software-survivalsurvdiff",
    "href": "chap3.html#software-survivalsurvdiff",
    "title": "Applied Survival Analysis",
    "section": "Software: survival::survdiff()",
    "text": "Software: survival::survdiff()\n\n\nBasic syntax for log-rank test\n\n\n\n# Log-rank test\nsurvdiff(Surv(time, status) ~ group + strata(str_var), rho)\n\n\n\n\n\nInput\n\nSurv(time, status) ~ group: test survival function between levels of variable group\nstrata(str_var): stratified by variable str_var (optional)\nrho = r: weights \\(\\hat S(t_j-)^\\rho\\) with \\(\\rho=\\) r\n\nOutput: a list containing pvalue (p-value of the test)"
  },
  {
    "objectID": "chap3.html#example-rat-carcinogen-study-ix",
    "href": "chap3.html#example-rat-carcinogen-study-ix",
    "title": "Applied Survival Analysis",
    "section": "Example: Rat Carcinogen Study (IX)",
    "text": "Example: Rat Carcinogen Study (IX)\n\nLog-rank test by rx stratified by sex\n\n\nhead(rats)\n#   litter rx time status sex\n# 1      1  1  101      0   f\n# 2      1  0   49      1   f\n# 3      1  0  104      0   f\n# ...\n\nsurvdiff(Surv(time, status) ~ rx + strata(sex), data = rats)\n# Call:\n# survdiff(formula = Surv(time, status) ~ rx + strata(sex), data = rats)\n# \n#        N Observed Expected (O-E)^2/E (O-E)^2/V\n# rx=0 200       21     28.9      2.16      6.99\n# rx=1 100       21     13.1      4.77      6.99\n# \n#  Chisq= 7  on 1 degrees of freedom, p= 0.008"
  },
  {
    "objectID": "chap3.html#baseline-characteristics",
    "href": "chap3.html#baseline-characteristics",
    "title": "Applied Survival Analysis",
    "section": "Baseline Characteristics",
    "text": "Baseline Characteristics\n\n\n686 patients with primary node positive breast cancer"
  },
  {
    "objectID": "chap3.html#relapse-free-survival",
    "href": "chap3.html#relapse-free-survival",
    "title": "Applied Survival Analysis",
    "section": "Relapse-Free Survival",
    "text": "Relapse-Free Survival\n\nEndpoint: the earlier of relapse or death"
  },
  {
    "objectID": "chap3.html#hormone-treatment-effect",
    "href": "chap3.html#hormone-treatment-effect",
    "title": "Applied Survival Analysis",
    "section": "Hormone Treatment Effect",
    "text": "Hormone Treatment Effect\n\n\nHormonal therapy\n\nStratified by menopausal status\n\n\n\n## Stratified log-rank test (by menopausal status)\nsurvdiff(Surv(time, status) ~ hormone + strata(meno),\n         data = data.CE)\n\n\n\n\nResult\n\n\\(\\chi_1^2=\\) 9.5 with p-value 0.002\n\nAdjusting for menopausal status, hormonal therapy has a highly significant beneficial effect on relapse-free survival in breast cancer patients\n\nUnadjusted test result similar"
  },
  {
    "objectID": "chap3.html#notes",
    "href": "chap3.html#notes",
    "title": "Applied Survival Analysis",
    "section": "Notes",
    "text": "Notes\n\n\nKaplan and Meier (1958)\n\n60k + citations by Feb 2025\nMost cited statistical paper of all time\n\n\n\n\n\nDerivation of log-rank\n\nMantel–Haenszel (1959) analysis of \\(2\\times 2\\) contingency tables stratified by \\(t_j\\)\n\n\n\n\n\nOther tests\n\nGehan npsm::gehan.test()\nMax-combo nph::logrank.maxtest() (maximum over multiple weighting schemes)"
  },
  {
    "objectID": "chap3.html#summary-i",
    "href": "chap3.html#summary-i",
    "title": "Applied Survival Analysis",
    "section": "Summary (I)",
    "text": "Summary (I)\n\n\nDiscrete hazard: \\(\\dd\\Lambda(t_j)= d_j/n_j\\) \n\nProportion of failures among those at risk\n\n\n\n\n\nKaplan–Meier \\[\\begin{equation}\n\\hat S(t)=\\prod_{j:t_j\\leq t}\\{1-\\dd\\hat\\Lambda(t_j)\\}=\\prod_{j:t_j\\leq t}(1-d_j/n_j)\n\\end{equation}\\]\n\nsurvival::survfit():"
  },
  {
    "objectID": "chap3.html#summary-ii",
    "href": "chap3.html#summary-ii",
    "title": "Applied Survival Analysis",
    "section": "Summary (II)",
    "text": "Summary (II)\n\n\nLog-rank test: multi-group comparison\n\n\\(K\\) groups \\(\\to\\) \\(K-1\\) degrees of freedom\nStratification: adjust for confounding\nWeighting: optimality depends on effect pattern over time\nsurvival::survdiff()\n\n\n\n\n\nEnhanced tabulation and graphics\n\ngtsummary::tbl_survfit()\nggsurvfit::ggsurvfit()"
  },
  {
    "objectID": "chap3.html#hw2-due-feb-21",
    "href": "chap3.html#hw2-due-feb-21",
    "title": "Applied Survival Analysis",
    "section": "HW2 (Due Feb 21)",
    "text": "HW2 (Due Feb 21)\n\nChoose one\n\nProblem 3.2\nProblem 3.3\n\nProblem 3.17\n(Extra credit) Problem 3.15"
  },
  {
    "objectID": "chapter3.html#software-use",
    "href": "chapter3.html#software-use",
    "title": "Chapter 3 - Nonparametric Estimation and Testing",
    "section": "Software Use",
    "text": "Software Use\nNonparametric survival estimates and log-rank tests are easily performed in R via the survival package. The survfit function fits Kaplan–Meier curves from a time-to-event variable and an event indicator, while the survdiff function calculates log-rank tests (and variations such as stratified or weighted log-rank). Many standard analyses can therefore be completed with just a few lines of code, shown below:\n\nlibrary(survival)\n\n# Fit Kaplan–Meier curves for two groups\nkm_fit &lt;- survfit(Surv(time, status) ~ group, data = mydata)\n\n# Summarize survival estimates and times\nsummary(km_fit)\n\n# Perform a log-rank test to compare groups\nlr_test &lt;- survdiff(Surv(time, status) ~ group, data = mydata)\nlr_test\n\nAdditional utilities are available for generating publication-ready tables and plots. The gtsummary package, for instance, provides a tbl_survfit() function that creates neatly formatted tables of survival estimates by group or stratum, including confidence intervals and median times. The ggsurvfit package extends ggplot2 to produce enhanced Kaplan–Meier graphs with at-risk tables, confidence interval shading, and optional log-rank \\(p\\)-values annotated on the plot:\n\nlibrary(gtsummary)\nlibrary(ggsurvfit)\n\n# Summarize survival estimates in a neat table\ntbl &lt;- tbl_survfit(km_fit, times = c(12, 24, 48, 96))\ntbl\n\n# Create a KM plot with confidence intervals and at-risk tables\nggsurvfit(km_fit) +\n  add_confidence_interval() +\n  add_risktable()\n\nThese higher-level functions streamline the presentation of nonparametric survival analyses, ensuring that both the numeric results and the visual displays are clear and publication-ready.\n\nConclusion\nDiscrete hazard constructs offer a flexible pathway to nonparametric survival estimation and testing. By updating risk sets at each event time, they integrate censoring efficiently into hazard estimators, leading to the Kaplan–Meier survival curve. For group comparisons, the log-rank test accumulates deviations in observed vs. expected failures across time, capturing hazard differences in a simple chi-square framework. Weighted extensions and max-combo designs handle a variety of hazard patterns and timing effects, while stratification addresses possible confounders. Underlying it all, martingale theory justifies the large-sample performance of these methods, ensuring that discrete hazard philosophies and counting-process constructions jointly deliver robust conclusions for a wide range of time-to-event analyses."
  },
  {
    "objectID": "chapter3.html#software-use-1",
    "href": "chapter3.html#software-use-1",
    "title": "Chapter 3 - Nonparametric Estimation and Testing",
    "section": "Software Use",
    "text": "Software Use\nNonparametric survival estimates and log-rank tests are easily performed in the environment via the package. The function fits Kaplan–Meier curves from a time-to-event variable and an event indicator, while the function calculates log-rank tests (and variations such as stratified or weighted log-rank). Many standard analyses can therefore be completed with just a few lines of code, shown below:\n\nlibrary(survival)\n\n# Fit Kaplan–Meier curves for two groups\nkm_fit &lt;- survfit(Surv(time, status) ~ group, data = mydata)\n\n# Summarize survival estimates and times\nsummary(km_fit)\n\n# Perform a log-rank test to compare groups\nlr_test &lt;- survdiff(Surv(time, status) ~ group, data = mydata)\nlr_test\n\nAdditional utilities are available for generating publication-ready tables and plots. The gtsummary package, for instance, provides a tbl_survfit() function that creates neatly formatted tables of survival estimates by group or stratum, including confidence intervals and median times. The ggsurvfit package extends ggplot2 to produce enhanced Kaplan–Meier graphs with at-risk tables, confidence interval shading, and optional log-rank \\(p\\)-values annotated on the plot:\n\nlibrary(gtsummary)\nlibrary(ggsurvfit)\n\n# Summarize survival estimates in a neat table\ntbl &lt;- tbl_survfit(km_fit, times = c(12, 24, 48, 96))\ntbl\n\n# Create a KM plot with confidence intervals and at-risk tables\nggsurvfit(km_fit) +\n  add_confidence_interval() +\n  add_risktable()\n\nThese higher-level functions streamline the presentation of nonparametric survival analyses, ensuring that both the numeric results and the visual displays are clear and publication-ready.\n\nConclusion\nDiscrete hazard constructs offer a flexible pathway to nonparametric survival estimation and testing. By updating risk sets at each event time, they integrate censoring efficiently into hazard estimators, leading to the Kaplan–Meier survival curve. For group comparisons, the log-rank test accumulates deviations in observed vs. expected failures across time, capturing hazard differences in a simple chi-square framework. Weighted extensions and max-combo designs handle a variety of hazard patterns and timing effects, while stratification addresses possible confounders. Underlying it all, martingale theory justifies the large-sample performance of these methods, ensuring that discrete hazard philosophies and counting-process constructions jointly deliver robust conclusions for a wide range of time-to-event analyses."
  },
  {
    "objectID": "chap3.html#software-gtsummary",
    "href": "chap3.html#software-gtsummary",
    "title": "Applied Survival Analysis",
    "section": "Software: gtsummary::",
    "text": "Software: gtsummary::"
  },
  {
    "objectID": "chap3.html#software-gtsummarytbl_survfit",
    "href": "chap3.html#software-gtsummarytbl_survfit",
    "title": "Applied Survival Analysis",
    "section": "Software: gtsummary::tbl_survfit()",
    "text": "Software: gtsummary::tbl_survfit()\n\n\nCustomizable, publication-ready table\n\nBased on survfit() results\n\n\n\n\n\n# install.packages(\"gtsummary\")\nlibrary(gtsummary)\n# A single-group KM model\nobj &lt;- survfit(Surv(time, status) ~ 1, data = df)\n\n# Summaries at specific times\ntbl_surv &lt;- tbl_survfit(\n  x = obj,                         # Provide the fitted survfit object\n  times = seq(40, 100, by = 20),   # Time points for survival rates\n  label_header = \"{time} days\"     # Column label: \"xx days\"\n)\n\n# Print out the table\ntbl_surv"
  },
  {
    "objectID": "chap3.html#software-ggsurvfitggsurvfit",
    "href": "chap3.html#software-ggsurvfitggsurvfit",
    "title": "Applied Survival Analysis",
    "section": "Software: ggsurvfit::ggsurvfit()",
    "text": "Software: ggsurvfit::ggsurvfit()\n\n\nEnhanced KM plot\n\nPowered by ggplot2\n\n\n\n\n\n# install.packages(\"ggsurvfit\")\nlibrary(ggsurvfit)\nobj &lt;- survfit(Surv(time, status) ~ 1, data = df)\n\n# Create a KM plot with confidence intervals and an at-risk table\nggsurvfit(obj) +\n  add_confidence_interval() + # Shaded 95% CI region\n  add_risktable() +           # Show risk table\n  scale_x_continuous(breaks = seq(0, 100, by = 20)) + # X-axis breaks\n  ylim(0, 1) +                # Y-axis limits\n  labs(\n    x = \"Time (days)\",\n    y = \"Tumor-free probabilities\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "chap3.html#software-gtsummarytbl_survfit-i",
    "href": "chap3.html#software-gtsummarytbl_survfit-i",
    "title": "Applied Survival Analysis",
    "section": "Software: gtsummary::tbl_survfit() (I)",
    "text": "Software: gtsummary::tbl_survfit() (I)\n\n\nCustomizable, publication-ready table\n\nBased on survfit() results\n\n\n\n\n\n# install.packages(\"gtsummary\")\nlibrary(gtsummary)\n# A single-group KM model\nobj &lt;- survfit(Surv(time, status) ~ 1, data = df)\n\n# Summaries at specific times\ntbl_surv &lt;- tbl_survfit(\n  x = obj,                         # Provide the fitted survfit object\n  times = seq(40, 100, by = 20),   # Time points for survival rates\n  label_header = \"{time} days\"     # Column label: \"xx days\"\n)\n\n# Print out the table\ntbl_surv"
  },
  {
    "objectID": "chap3.html#software-gtsummarytbl_survfit-1",
    "href": "chap3.html#software-gtsummarytbl_survfit-1",
    "title": "Applied Survival Analysis",
    "section": "Software: gtsummary::tbl_survfit()",
    "text": "Software: gtsummary::tbl_survfit()\n\n\nMulti-group tabulation\n\n\nlibrary(gtsummary)\n# A two-group KM model\nobj &lt;- survfit(Surv(time, status) ~ rx, data = rats)\n\n# Summaries at specific times with labeled treatment groups\ntbl_surv &lt;- tbl_survfit(\n  x = obj,                         # Provide the fitted survfit object\n  times = seq(40, 100, by = 20),   # Time points for survival rates\n  label_header = \"{time} days\",    # Column label: \"xx days\"\n  label = list(rx ~ \"Treatment\")   # Rename 'rx' to 'Treatment'\n)\n\n# Print out the table\ntbl_surv"
  },
  {
    "objectID": "chap3.html#software-ggsurvfitggsurvfit-1",
    "href": "chap3.html#software-ggsurvfitggsurvfit-1",
    "title": "Applied Survival Analysis",
    "section": "Software: ggsurvfit::ggsurvfit()",
    "text": "Software: ggsurvfit::ggsurvfit()\n\n\nMulti-group KM graphics\n\n\nlibrary(ggsurvfit)\n\n# Use survfit2 as recommended by ggsurvfit\nobj2 &lt;- survfit2(Surv(time, status) ~ rx, data = rats)\n\n# Create a group-specific KM plot with log-rank test p-value\nggsurvfit(obj, linetype_aes = TRUE, linewidth = 1) +  # Use line types \n  add_risktable(                    \n    risktable_stats = \"n.risk\",  # Include only numbers at risk\n    theme = list(\n      theme_risktable_default(),  # Default risk table theme\n      scale_y_discrete(labels = c('Drug', 'Control'))  # Group labels\n    )\n  ) +  \n  theme_classic()"
  },
  {
    "objectID": "chap3.html#relapse-free-survival-overall",
    "href": "chap3.html#relapse-free-survival-overall",
    "title": "Applied Survival Analysis",
    "section": "Relapse-Free Survival: Overall",
    "text": "Relapse-Free Survival: Overall\n\n\nEndpoint: the earlier of relapse or death"
  },
  {
    "objectID": "chap3.html#relapse-free-survival-by-menupause",
    "href": "chap3.html#relapse-free-survival-by-menupause",
    "title": "Applied Survival Analysis",
    "section": "Relapse-Free Survival: by Menupause",
    "text": "Relapse-Free Survival: by Menupause"
  },
  {
    "objectID": "chap3.html#relapse-free-survival-subgroups",
    "href": "chap3.html#relapse-free-survival-subgroups",
    "title": "Applied Survival Analysis",
    "section": "Relapse-Free Survival: Subgroups",
    "text": "Relapse-Free Survival: Subgroups\n\n\nMenopausal status: pre- vs post-menopausal"
  },
  {
    "objectID": "chap3.html#hw2-due-feb-19",
    "href": "chap3.html#hw2-due-feb-19",
    "title": "Applied Survival Analysis",
    "section": "HW2 (Due Feb 19)",
    "text": "HW2 (Due Feb 19)\n\nChoose one\n\nProblem 3.2\nProblem 3.3\n\nProblem 3.19\n(Extra credit) Choose one\n\nProblem 3.15\nProblems 3.17 and 3.18"
  }
]